{"uid":"e0bfaeaf9694d3c9","name":"[BeforeSuite]","historyId":"Worker Suite:Worker Suite#[BeforeSuite]","time":{"start":1667739621000,"stop":1667739916217,"duration":295217},"status":"passed","flaky":false,"newFailed":false,"newBroken":false,"newPassed":true,"retriesCount":0,"retriesStatusChange":false,"beforeStages":[],"testStage":{"steps":[{"name":"","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"Report Entries:","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"By Step","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"/e2e/tests/worker/setup_test.go:44","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"2022-11-06T13:00:21.566360344Z","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"&{Text:installing cert-manager Duration:0s}","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"--","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"By Step","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"/e2e/tests/worker/setup_test.go:52","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"2022-11-06T13:00:50.825621648Z","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"&{Text:installing hub Duration:0s}","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"--","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"By Step","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"/e2e/tests/worker/setup_test.go:68","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"2022-11-06T13:01:17.907311595Z","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"&{Text:Deploying Project Duration:0s}","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"--","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"By Step","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"/e2e/tests/worker/setup_test.go:72","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"2022-11-06T13:01:20.379271023Z","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"&{Text:Waiting for project reconciliation Duration:0s}","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"--","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"By Step","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"/e2e/tests/worker/setup_test.go:78","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"2022-11-06T13:01:21.408729102Z","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"&{Text:Setup Cluster CRs for workers Duration:0s}","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"--","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"By Step","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"/e2e/tests/worker/setup_test.go:90","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"2022-11-06T13:01:26.286591008Z","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"&{Text:Setup worker clusters Duration:0s}","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"--","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"By Step","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"/e2e/tests/worker/setup_test.go:116","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"2022-11-06T13:05:08.318345252Z","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"&{Text:Wait for worker clusters Duration:0s}","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false}],"attachments":[],"parameters":[],"stepsCount":36,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":true},"afterStages":[],"labels":[{"name":"resultFormat","value":"junit"},{"name":"suite","value":"Worker Suite"},{"name":"testClass","value":"Worker Suite"},{"name":"package","value":"Worker Suite"}],"parameters":[],"links":[],"hidden":false,"retry":false,"extra":{"severity":"normal","retries":[],"categories":[],"history":{"statistic":{"failed":27,"broken":0,"skipped":0,"passed":6,"unknown":0,"total":33},"items":[{"uid":"6d0dfaf5cc06294c","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc0001fa018>: {\n        Underlying: <*exec.ExitError | 0xc0001b4000>{\n            ProcessState: {\n                pid: 6251,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 4, Usec: 227405},\n                    Stime: {Sec: 0, Usec: 580232},\n                    Maxrss: 113984,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 7253,\n                    Majflt: 7,\n                    Nswap: 0,\n                    Inblock: 856,\n                    Oublock: 20192,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 48237,\n                    Nivcsw: 11040,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"install.go:192: [debug] Original chart version: \\\"0.4.6\\\"\",\n                        \"install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-worker-0.4.6.tgz\",\n                        \"\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:165: [debug] Clearing discovery cache\",\n                        \"wait.go:66: [debug] beginning wait for 4 resources with timeout of 1m0s\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 47 resource(s)\",\n                        \"wait.go:66: [debug] beginning wait for 47 resources with timeout of 5m0s\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubesli...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    install.go:192: [debug] Original chart version: \"0.4.6\"\n    install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-worker-0.4.6.tgz\n    \n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 1 resource(s)\n    install.go:165: [debug] Clearing discovery cache\n    wait.go:66: [debug] beginning wait for 4 resources with timeout of 1m0s\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 47 resource(s)\n    wait.go:66: [debug] beginning wait for 47 resources with timeout of 5m0s\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    install.go:441: [debug] Install failed and atomic is set, uninstalling release\n    uninstall.go:95: [debug] uninstall: Deleting kubeslice-worker\n    client.go:310: [debug] Starting delete for \"kubeslice-webhook-service\" Service\n    client.go:310: [debug] Starting delete for \"jaeger\" Service\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-svc\" Service\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" Service\n    client.go:310: [debug] Starting delete for \"kubeslice-operator\" Deployment\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook\" Deployment\n    client.go:310: [debug] Starting delete for \"jaeger\" Deployment\n    client.go:310: [debug] Starting delete for \"prefix-service\" Deployment\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" Deployment\n    client.go:310: [debug] Starting delete for \"kubeslice-netop\" DaemonSet\n    client.go:310: [debug] Starting delete for \"nsm-kernel-forwarder\" DaemonSet\n    client.go:310: [debug] Starting delete for \"nsmgr\" DaemonSet\n    client.go:310: [debug] Starting delete for \"kubeslice-leader-election-rolebinding\" RoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-leader-election-role\" Role\n    client.go:310: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-dns-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"nsm-role-binding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-proxy-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ClusterRole\n    client.go:310: [debug] Starting delete for \"nsm-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-metrics-reader\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-proxy-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"aggregate-network-services-view\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-dns-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"networkservices.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"networkserviceendpoints.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"networkservicemanagers.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-config\" ConfigMap\n    client.go:310: [debug] Starting delete for \"nsm-config\" ConfigMap\n    client.go:310: [debug] Starting delete for \"kubeslice-admission-webhook-certs\" Secret\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-certs\" Secret\n    client.go:310: [debug] Starting delete for \"kubeslice-hub\" Secret\n    client.go:310: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nse-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nsc-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"forward-plane-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nsmgr-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-netop\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-manager\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"vpn-gateway-client\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"vpn-gateway-server\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"slice-router\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-cfg\" MutatingWebhookConfiguration\n    client.go:310: [debug] Starting delete for \"kubeslice-mutating-webhook-configuration\" MutatingWebhookConfiguration\n    uninstall.go:148: [debug] purge requested for kubeslice-worker\n    Error: INSTALLATION FAILED: release kubeslice-worker failed, and has been uninstalled due to atomic being set: client rate limiter Wait returned an error: context deadline exceeded\n    helm.go:84: [debug] client rate limiter Wait returned an error: context deadline exceeded\n    release kubeslice-worker failed, and has been uninstalled due to atomic being set\n    helm.sh/helm/v3/pkg/action.(*Install).failRelease\n    \thelm.sh/helm/v3/pkg/action/install.go:449\n    helm.sh/helm/v3/pkg/action.(*Install).reportToRun\n    \thelm.sh/helm/v3/pkg/action/install.go:433\n    helm.sh/helm/v3/pkg/action.(*Install).performInstall\n    \thelm.sh/helm/v3/pkg/action/install.go:389\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:141\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\noccurred","time":{"start":1667738525000,"stop":1667738870883,"duration":345883}},{"uid":"c828da859f24a4b6","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc0004ae060>: {\n        Underlying: <*exec.ExitError | 0xc0004c4000>{\n            ProcessState: {\n                pid: 5888,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 6, Usec: 234086},\n                    Stime: {Sec: 0, Usec: 568300},\n                    Maxrss: 91480,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 12064,\n                    Majflt: 120,\n                    Nswap: 0,\n                    Inblock: 15480,\n                    Oublock: 15640,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 53932,\n                    Nivcsw: 17680,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"install.go:192: [debug] Original chart version: \\\"1.7.0\\\"\",\n                        \"install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/cert-manager-v1.7.0.tgz\",\n                        \"\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 45 resource(s)\",\n                        \"wait.go:66: [debug] beginning wait for 45 resources with timeout of 5m0s\",\n                        \"ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; install.go:192: [debug] Original chart version: \"1.7.0\"\n    install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/cert-manager-v1.7.0.tgz\n    \n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 45 resource(s)\n    wait.go:66: [debug] beginning wait for 45 resources with timeout of 5m0s\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-cainjector. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: cert-manager/cert-manager-webhook. 0 out of 1 expected pods are ready\n    install.go:441: [debug] Install failed and atomic is set, uninstalling release\n    uninstall.go:95: [debug] uninstall: Deleting cert-manager\n    client.go:310: [debug] Starting delete for \"cert-manager\" Service\n    client.go:310: [debug] Starting delete for \"cert-manager-webhook\" Service\n    client.go:310: [debug] Starting delete for \"cert-manager-cainjector\" Deployment\n    client.go:310: [debug] Starting delete for \"cert-manager\" Deployment\n    client.go:310: [debug] Starting delete for \"cert-manager-webhook\" Deployment\n    client.go:310: [debug] Starting delete for \"cert-manager-webhook:dynamic-serving\" RoleBinding\n    client.go:310: [debug] Starting delete for \"cert-manager-cainjector:leaderelection\" RoleBinding\n    client.go:310: [debug] Starting delete for \"cert-manager:leaderelection\" RoleBinding\n    client.go:310: [debug] Starting delete for \"cert-manager-webhook:dynamic-serving\" Role\n    client.go:310: [debug] Starting delete for \"cert-manager-cainjector:leaderelection\" Role\n    client.go:310: [debug] Starting delete for \"cert-manager:leaderelection\" Role\n    client.go:310: [debug] Starting delete for \"cert-manager-webhook:subjectaccessreviews\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"cert-manager-cainjector\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"cert-manager-controller-issuers\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"cert-manager-controller-clusterissuers\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"cert-manager-controller-certificates\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"cert-manager-controller-orders\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"cert-manager-controller-challenges\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"cert-manager-controller-ingress-shim\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"cert-manager-controller-approve:cert-manager-io\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"cert-manager-controller-certificatesigningrequests\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"cert-manager-webhook:subjectaccessreviews\" ClusterRole\n    client.go:310: [debug] Starting delete for \"cert-manager-cainjector\" ClusterRole\n    client.go:310: [debug] Starting delete for \"cert-manager-controller-issuers\" ClusterRole\n    client.go:310: [debug] Starting delete for \"cert-manager-controller-clusterissuers\" ClusterRole\n    client.go:310: [debug] Starting delete for \"cert-manager-controller-certificates\" ClusterRole\n    client.go:310: [debug] Starting delete for \"cert-manager-controller-orders\" ClusterRole\n    client.go:310: [debug] Starting delete for \"cert-manager-controller-challenges\" ClusterRole\n    client.go:310: [debug] Starting delete for \"cert-manager-controller-ingress-shim\" ClusterRole\n    client.go:310: [debug] Starting delete for \"cert-manager-view\" ClusterRole\n    client.go:310: [debug] Starting delete for \"cert-manager-edit\" ClusterRole\n    client.go:310: [debug] Starting delete for \"cert-manager-controller-approve:cert-manager-io\" ClusterRole\n    client.go:310: [debug] Starting delete for \"cert-manager-controller-certificatesigningrequests\" ClusterRole\n    client.go:310: [debug] Starting delete for \"challenges.acme.cert-manager.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"orders.acme.cert-manager.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"clusterissuers.cert-manager.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"issuers.cert-manager.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"certificates.cert-manager.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"certificaterequests.cert-manager.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"cert-manager-webhook\" ConfigMap\n    client.go:310: [debug] Starting delete for \"cert-manager-cainjector\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"cert-manager\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"cert-manager-webhook\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"cert-manager-webhook\" MutatingWebhookConfiguration\n    client.go:310: [debug] Starting delete for \"cert-manager-webhook\" ValidatingWebhookConfiguration\n    uninstall.go:148: [debug] purge requested for cert-manager\n    Error: INSTALLATION FAILED: release cert-manager failed, and has been uninstalled due to atomic being set: timed out waiting for the condition\n    helm.go:84: [debug] timed out waiting for the condition\n    release cert-manager failed, and has been uninstalled due to atomic being set\n    helm.sh/helm/v3/pkg/action.(*Install).failRelease\n    \thelm.sh/helm/v3/pkg/action/install.go:449\n    helm.sh/helm/v3/pkg/action.(*Install).reportToRun\n    \thelm.sh/helm/v3/pkg/action/install.go:433\n    helm.sh/helm/v3/pkg/action.(*Install).performInstall\n    \thelm.sh/helm/v3/pkg/action/install.go:389\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:141\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\noccurred","time":{"start":1667737440000,"stop":1667737744183,"duration":304183}},{"uid":"3030aa2f87f9e529","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc00041a108>: {\n        Underlying: <*exec.ExitError | 0xc0008fc000>{\n            ProcessState: {\n                pid: 5915,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 2, Usec: 545246},\n                    Stime: {Sec: 0, Usec: 235375},\n                    Maxrss: 110564,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 15332,\n                    Majflt: 4,\n                    Nswap: 0,\n                    Inblock: 488,\n                    Oublock: 21592,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 4876,\n                    Nivcsw: 5138,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"install.go:192: [debug] Original chart version: \\\"\\\"\",\n                        \"install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-worker-0.4.5.tgz\",\n                        \"\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:165: [debug] Clearing discovery cache\",\n                        \"wait.go:66: [debug] beginning wait for 6 resources with timeout of 1m0s\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:310: [debug] Starting delete for \\\"kubeslice-preinstall\\\" ServiceAccount\",\n                        \"client.go:339: [debug] serviceaccounts \\\"kubeslice-preinstall\\\" not found\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:310: [debug] Starting delete for \\\"kubeslice-preinstall-role\\\" ClusterRole\",\n                        \"client.go:339: [debug] clusterroles.rbac.authorization.k8s.io \\\"kubeslice-preinstall-role\\\" not found\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:310: [debug] Starting delete for \\\"kubeslice-preinstall-rolebinding\\\" ClusterRoleBinding\",\n                        \"client.go:339: [debug] clusterrolebindings.rbac.authorization.k8s.io \\\"kubeslice-preinstall-rolebinding\\\" not found\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:310: [debug] Starting delete for \\\"kubeslice-worker-preinstall-configmap\\\" ConfigMap\",\n                        \"client.go:339: [debug] configmaps \\\"kubeslice-worker-preinstall-configmap\\\" not found\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:310: [debug] Starting delete for \\\"kubeslice-worker-preinstall-job\\\" Job\",\n                        \"client.go:339: [debug] jobs.batch \\\"kubeslice-worker-preinstall-job\\\" not found\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:540: [debug] Watching for changes to Job kubeslice-worker-preinstall-job with timeout of 5m0s\",\n                        \"client.go:568: [debug] Add/Modify event for kubeslice-worker-preinstall-job: ADDED\",\n                        \"client.go:607: [debug] kubeslice-worker-preinstall-job: Jobs active: 0, jobs failed: 0, jobs succeeded: 0\",\n                        \"client.go:568: [debug] Add/Modify event for kubeslice-worker-preinstall-job: MODIFIED\",\n                        \"client.go:607: [debug] kubeslice-worker-preinstall-job: Jobs active: 1, jo...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; install.go:192: [debug] Original chart version: \"\"\n    install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-worker-0.4.5.tgz\n    \n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 1 resource(s)\n    install.go:165: [debug] Clearing discovery cache\n    wait.go:66: [debug] beginning wait for 6 resources with timeout of 1m0s\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:310: [debug] Starting delete for \"kubeslice-preinstall\" ServiceAccount\n    client.go:339: [debug] serviceaccounts \"kubeslice-preinstall\" not found\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:310: [debug] Starting delete for \"kubeslice-preinstall-role\" ClusterRole\n    client.go:339: [debug] clusterroles.rbac.authorization.k8s.io \"kubeslice-preinstall-role\" not found\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:310: [debug] Starting delete for \"kubeslice-preinstall-rolebinding\" ClusterRoleBinding\n    client.go:339: [debug] clusterrolebindings.rbac.authorization.k8s.io \"kubeslice-preinstall-rolebinding\" not found\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:310: [debug] Starting delete for \"kubeslice-worker-preinstall-configmap\" ConfigMap\n    client.go:339: [debug] configmaps \"kubeslice-worker-preinstall-configmap\" not found\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:310: [debug] Starting delete for \"kubeslice-worker-preinstall-job\" Job\n    client.go:339: [debug] jobs.batch \"kubeslice-worker-preinstall-job\" not found\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:540: [debug] Watching for changes to Job kubeslice-worker-preinstall-job with timeout of 5m0s\n    client.go:568: [debug] Add/Modify event for kubeslice-worker-preinstall-job: ADDED\n    client.go:607: [debug] kubeslice-worker-preinstall-job: Jobs active: 0, jobs failed: 0, jobs succeeded: 0\n    client.go:568: [debug] Add/Modify event for kubeslice-worker-preinstall-job: MODIFIED\n    client.go:607: [debug] kubeslice-worker-preinstall-job: Jobs active: 1, jobs failed: 0, jobs succeeded: 0\n    client.go:568: [debug] Add/Modify event for kubeslice-worker-preinstall-job: MODIFIED\n    client.go:607: [debug] kubeslice-worker-preinstall-job: Jobs active: 1, jobs failed: 1, jobs succeeded: 0\n    client.go:568: [debug] Add/Modify event for kubeslice-worker-preinstall-job: MODIFIED\n    client.go:607: [debug] kubeslice-worker-preinstall-job: Jobs active: 1, jobs failed: 2, jobs succeeded: 0\n    client.go:310: [debug] Starting delete for \"kubeslice-worker-preinstall-job\" Job\n    install.go:441: [debug] Install failed and atomic is set, uninstalling release\n    uninstall.go:95: [debug] uninstall: Deleting kubeslice-worker\n    client.go:310: [debug] Starting delete for \"jaeger\" Service\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" Service\n    client.go:310: [debug] Starting delete for \"kubeslice-webhook-service\" Service\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-svc\" Service\n    client.go:339: [debug] services \"jaeger\" not found\n    client.go:339: [debug] services \"kubeslice-dns\" not found\n    client.go:339: [debug] services \"kubeslice-webhook-service\" not found\n    client.go:339: [debug] services \"nsm-admission-webhook-svc\" not found\n    client.go:310: [debug] Starting delete for \"kubeslice-operator\" Deployment\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook\" Deployment\n    client.go:310: [debug] Starting delete for \"jaeger\" Deployment\n    client.go:310: [debug] Starting delete for \"prefix-service\" Deployment\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" Deployment\n    client.go:339: [debug] deployments.apps \"nsm-admission-webhook\" not found\n    client.go:339: [debug] deployments.apps \"kubeslice-dns\" not found\n    client.go:339: [debug] deployments.apps \"kubeslice-operator\" not found\n    client.go:339: [debug] deployments.apps \"prefix-service\" not found\n    client.go:339: [debug] deployments.apps \"jaeger\" not found\n    client.go:310: [debug] Starting delete for \"kubeslice-netop\" DaemonSet\n    client.go:310: [debug] Starting delete for \"nsm-kernel-forwarder\" DaemonSet\n    client.go:310: [debug] Starting delete for \"nsmgr\" DaemonSet\n    client.go:339: [debug] daemonsets.apps \"nsmgr\" not found\n    client.go:339: [debug] daemonsets.apps \"nsm-kernel-forwarder\" not found\n    client.go:339: [debug] daemonsets.apps \"kubeslice-netop\" not found\n    client.go:310: [debug] Starting delete for \"kubeslice-leader-election-rolebinding\" RoleBinding\n    client.go:339: [debug] rolebindings.rbac.authorization.k8s.io \"kubeslice-leader-election-rolebinding\" not found\n    client.go:310: [debug] Starting delete for \"kubeslice-leader-election-role\" Role\n    client.go:339: [debug] roles.rbac.authorization.k8s.io \"kubeslice-leader-election-role\" not found\n    client.go:310: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-dns-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"nsm-role-binding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-proxy-rolebinding\" ClusterRoleBinding\n    client.go:339: [debug] clusterrolebindings.rbac.authorization.k8s.io \"kubeslice-manager-rolebinding\" not found\n    client.go:339: [debug] clusterrolebindings.rbac.authorization.k8s.io \"kubeslice-proxy-rolebinding\" not found\n    client.go:339: [debug] clusterrolebindings.rbac.authorization.k8s.io \"nsm-role-binding\" not found\n    client.go:339: [debug] clusterrolebindings.rbac.authorization.k8s.io \"kubeslice-dns-rolebinding\" not found\n    client.go:339: [debug] clusterrolebindings.rbac.authorization.k8s.io \"kubeslice-kubernetes-dashboard\" not found\n    client.go:310: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ClusterRole\n    client.go:310: [debug] Starting delete for \"nsm-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"aggregate-network-services-view\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-proxy-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-metrics-reader\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-dns-role\" ClusterRole\n    client.go:339: [debug] clusterroles.rbac.authorization.k8s.io \"aggregate-network-services-view\" not found\n    client.go:339: [debug] clusterroles.rbac.authorization.k8s.io \"kubeslice-proxy-role\" not found\n    client.go:339: [debug] clusterroles.rbac.authorization.k8s.io \"kubeslice-metrics-reader\" not found\n    client.go:339: [debug] clusterroles.rbac.authorization.k8s.io \"kubeslice-kubernetes-dashboard\" not found\n    client.go:339: [debug] clusterroles.rbac.authorization.k8s.io \"nsm-role\" not found\n    client.go:339: [debug] clusterroles.rbac.authorization.k8s.io \"kubeslice-dns-role\" not found\n    client.go:339: [debug] clusterroles.rbac.authorization.k8s.io \"kubeslice-manager-role\" not found\n    client.go:310: [debug] Starting delete for \"networkservices.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"networkserviceendpoints.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"networkservicemanagers.networkservicemesh.io\" CustomResourceDefinition\n    client.go:339: [debug] customresourcedefinitions.apiextensions.k8s.io \"networkservices.networkservicemesh.io\" not found\n    client.go:339: [debug] customresourcedefinitions.apiextensions.k8s.io \"networkserviceendpoints.networkservicemesh.io\" not found\n    client.go:339: [debug] customresourcedefinitions.apiextensions.k8s.io \"networkservicemanagers.networkservicemesh.io\" not found\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-config\" ConfigMap\n    client.go:310: [debug] Starting delete for \"nsm-config\" ConfigMap\n    client.go:339: [debug] configmaps \"nsm-config\" not found\n    client.go:339: [debug] configmaps \"kubeslice-manager-config\" not found\n    client.go:310: [debug] Starting delete for \"kubeslice-admission-webhook-certs\" Secret\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-certs\" Secret\n    client.go:310: [debug] Starting delete for \"kubeslice-hub\" Secret\n    client.go:339: [debug] secrets \"kubeslice-admission-webhook-certs\" not found\n    client.go:339: [debug] secrets \"nsm-admission-webhook-certs\" not found\n    client.go:339: [debug] secrets \"kubeslice-hub\" not found\n    client.go:310: [debug] Starting delete for \"nse-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-manager\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nsc-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nsmgr-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"forward-plane-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"vpn-gateway-server\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-netop\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"vpn-gateway-client\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"slice-router\" ServiceAccount\n    client.go:339: [debug] serviceaccounts \"kubeslice-controller-manager\" not found\n    client.go:339: [debug] serviceaccounts \"nse-acc\" not found\n    client.go:339: [debug] serviceaccounts \"nsc-acc\" not found\n    client.go:339: [debug] serviceaccounts \"nsmgr-acc\" not found\n    client.go:339: [debug] serviceaccounts \"kubeslice-dns\" not found\n    client.go:339: [debug] serviceaccounts \"kubeslice-netop\" not found\n    client.go:339: [debug] serviceaccounts \"slice-router\" not found\n    client.go:339: [debug] serviceaccounts \"forward-plane-acc\" not found\n    client.go:339: [debug] serviceaccounts \"kubeslice-kubernetes-dashboard\" not found\n    client.go:339: [debug] serviceaccounts \"vpn-gateway-client\" not found\n    client.go:339: [debug] serviceaccounts \"vpn-gateway-server\" not found\n    client.go:310: [debug] Starting delete for \"kubeslice-mutating-webhook-configuration\" MutatingWebhookConfiguration\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-cfg\" MutatingWebhookConfiguration\n    client.go:339: [debug] mutatingwebhookconfigurations.admissionregistration.k8s.io \"nsm-admission-webhook-cfg\" not found\n    client.go:339: [debug] mutatingwebhookconfigurations.admissionregistration.k8s.io \"kubeslice-mutating-webhook-configuration\" not found\n    uninstall.go:148: [debug] purge requested for kubeslice-worker\n    Error: INSTALLATION FAILED: release kubeslice-worker failed, and has been uninstalled due to atomic being set: failed pre-install: timed out waiting for the condition\n    helm.go:84: [debug] failed pre-install: timed out waiting for the condition\n    release kubeslice-worker failed, and has been uninstalled due to atomic being set\n    helm.sh/helm/v3/pkg/action.(*Install).failRelease\n    \thelm.sh/helm/v3/pkg/action/install.go:449\n    helm.sh/helm/v3/pkg/action.(*Install).reportToRun\n    \thelm.sh/helm/v3/pkg/action/install.go:433\n    helm.sh/helm/v3/pkg/action.(*Install).performInstall\n    \thelm.sh/helm/v3/pkg/action/install.go:361\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:141\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\noccurred","time":{"start":1667651299000,"stop":1667651660171,"duration":361171}},{"uid":"bec9acd7fe46f947","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc000456078>: {\n        Underlying: <*exec.ExitError | 0xc0007be000>{\n            ProcessState: {\n                pid: 6169,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 5, Usec: 879859},\n                    Stime: {Sec: 1, Usec: 303417},\n                    Maxrss: 110680,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 15006,\n                    Majflt: 2,\n                    Nswap: 0,\n                    Inblock: 112,\n                    Oublock: 20432,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 54809,\n                    Nivcsw: 16391,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"install.go:192: [debug] Original chart version: \\\"0.4.6\\\"\",\n                        \"install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-worker-0.4.6.tgz\",\n                        \"\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:165: [debug] Clearing discovery cache\",\n                        \"wait.go:66: [debug] beginning wait for 4 resources with timeout of 1m0s\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 47 resource(s)\",\n                        \"wait.go:66: [debug] beginning wait for 47 resources with timeout of 5m0s\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n    ...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    install.go:192: [debug] Original chart version: \"0.4.6\"\n    install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-worker-0.4.6.tgz\n    \n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 1 resource(s)\n    install.go:165: [debug] Clearing discovery cache\n    wait.go:66: [debug] beginning wait for 4 resources with timeout of 1m0s\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 47 resource(s)\n    wait.go:66: [debug] beginning wait for 47 resources with timeout of 5m0s\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    install.go:441: [debug] Install failed and atomic is set, uninstalling release\n    uninstall.go:95: [debug] uninstall: Deleting kubeslice-worker\n    client.go:310: [debug] Starting delete for \"kubeslice-webhook-service\" Service\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-svc\" Service\n    client.go:310: [debug] Starting delete for \"jaeger\" Service\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" Service\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook\" Deployment\n    client.go:310: [debug] Starting delete for \"jaeger\" Deployment\n    client.go:310: [debug] Starting delete for \"prefix-service\" Deployment\n    client.go:310: [debug] Starting delete for \"kubeslice-operator\" Deployment\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" Deployment\n    client.go:310: [debug] Starting delete for \"kubeslice-netop\" DaemonSet\n    client.go:310: [debug] Starting delete for \"nsm-kernel-forwarder\" DaemonSet\n    client.go:310: [debug] Starting delete for \"nsmgr\" DaemonSet\n    client.go:310: [debug] Starting delete for \"kubeslice-leader-election-rolebinding\" RoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-leader-election-role\" Role\n    client.go:310: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"nsm-role-binding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-dns-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-proxy-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-dns-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"nsm-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"aggregate-network-services-view\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-metrics-reader\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-proxy-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ClusterRole\n    client.go:310: [debug] Starting delete for \"networkservices.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"networkserviceendpoints.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"networkservicemanagers.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-config\" ConfigMap\n    client.go:310: [debug] Starting delete for \"nsm-config\" ConfigMap\n    client.go:310: [debug] Starting delete for \"kubeslice-admission-webhook-certs\" Secret\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-certs\" Secret\n    client.go:310: [debug] Starting delete for \"kubeslice-hub\" Secret\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-manager\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"forward-plane-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nse-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nsc-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"slice-router\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nsmgr-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-netop\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"vpn-gateway-client\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"vpn-gateway-server\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-mutating-webhook-configuration\" MutatingWebhookConfiguration\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-cfg\" MutatingWebhookConfiguration\n    uninstall.go:148: [debug] purge requested for kubeslice-worker\n    Error: INSTALLATION FAILED: release kubeslice-worker failed, and has been uninstalled due to atomic being set: client rate limiter Wait returned an error: rate: Wait(n=1) would exceed context deadline\n    helm.go:84: [debug] client rate limiter Wait returned an error: rate: Wait(n=1) would exceed context deadline\n    release kubeslice-worker failed, and has been uninstalled due to atomic being set\n    helm.sh/helm/v3/pkg/action.(*Install).failRelease\n    \thelm.sh/helm/v3/pkg/action/install.go:449\n    helm.sh/helm/v3/pkg/action.(*Install).reportToRun\n    \thelm.sh/helm/v3/pkg/action/install.go:433\n    helm.sh/helm/v3/pkg/action.(*Install).performInstall\n    \thelm.sh/helm/v3/pkg/action/install.go:389\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:141\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\noccurred","time":{"start":1667595443000,"stop":1667595808921,"duration":365921}},{"uid":"34173798a534d24f","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc00093a018>: {\n        Underlying: <*exec.ExitError | 0xc000680000>{\n            ProcessState: {\n                pid: 6267,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 4, Usec: 48212},\n                    Stime: {Sec: 0, Usec: 647394},\n                    Maxrss: 104892,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 6157,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 0,\n                    Oublock: 20592,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 49457,\n                    Nivcsw: 12592,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"install.go:192: [debug] Original chart version: \\\"\\\"\",\n                        \"install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-worker-0.4.7.tgz\",\n                        \"\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:151: [debug] CRD serviceexports.networking.kubeslice.io is already present. Skipping.\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:151: [debug] CRD serviceimports.networking.kubeslice.io is already present. Skipping.\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:151: [debug] CRD slice.networking.kubeslice.io is already present. Skipping.\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:151: [debug] CRD slicegateways.networking.kubeslice.io is already present. Skipping.\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 48 resource(s)\",\n                        \"wait.go:66: [debug] beginning wait for 48 resources with timeout of 5m0s\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 2 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 2 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 2 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 2 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 2 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 2 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 2 expected pods are ready\",\n                        \"ready.go:277: [debu...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    install.go:192: [debug] Original chart version: \"\"\n    install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-worker-0.4.7.tgz\n    \n    client.go:128: [debug] creating 1 resource(s)\n    install.go:151: [debug] CRD serviceexports.networking.kubeslice.io is already present. Skipping.\n    client.go:128: [debug] creating 1 resource(s)\n    install.go:151: [debug] CRD serviceimports.networking.kubeslice.io is already present. Skipping.\n    client.go:128: [debug] creating 1 resource(s)\n    install.go:151: [debug] CRD slice.networking.kubeslice.io is already present. Skipping.\n    client.go:128: [debug] creating 1 resource(s)\n    install.go:151: [debug] CRD slicegateways.networking.kubeslice.io is already present. Skipping.\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 48 resource(s)\n    wait.go:66: [debug] beginning wait for 48 resources with timeout of 5m0s\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 2 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 2 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 2 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 2 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 2 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 2 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 2 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 2 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 2 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    install.go:441: [debug] Install failed and atomic is set, uninstalling release\n    uninstall.go:95: [debug] uninstall: Deleting kubeslice-worker\n    client.go:310: [debug] Starting delete for \"jaeger\" Service\n    client.go:310: [debug] Starting delete for \"kubeslice-webhook-service\" Service\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-svc\" Service\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" Service\n    client.go:310: [debug] Starting delete for \"kubeslice-operator\" Deployment\n    client.go:310: [debug] Starting delete for \"jaeger\" Deployment\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook\" Deployment\n    client.go:310: [debug] Starting delete for \"prefix-service\" Deployment\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" Deployment\n    client.go:310: [debug] Starting delete for \"kubeslice-netop\" DaemonSet\n    client.go:310: [debug] Starting delete for \"nsm-kernel-forwarder\" DaemonSet\n    client.go:310: [debug] Starting delete for \"nsmgr\" DaemonSet\n    client.go:310: [debug] Starting delete for \"kubeslice-leader-election-rolebinding\" RoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-leader-election-role\" Role\n    client.go:310: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"nsm-role-binding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-dns-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-proxy-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ClusterRole\n    client.go:310: [debug] Starting delete for \"nsm-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"aggregate-network-services-view\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-dns-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-metrics-reader\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-proxy-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"networkservices.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"networkserviceendpoints.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"networkservicemanagers.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-config\" ConfigMap\n    client.go:310: [debug] Starting delete for \"nsm-config\" ConfigMap\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-certs\" Secret\n    client.go:310: [debug] Starting delete for \"kubeslice-admission-webhook-certs\" Secret\n    client.go:310: [debug] Starting delete for \"kubeslice-hub\" Secret\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-manager\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nse-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nsc-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nsmgr-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"forward-plane-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-netop\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"vpn-gateway-server\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"vpn-gateway-client\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"slice-router\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-mutating-webhook-configuration\" MutatingWebhookConfiguration\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-cfg\" MutatingWebhookConfiguration\n    client.go:310: [debug] Starting delete for \"nsm-webhook-high-priority\" PriorityClass\n    uninstall.go:148: [debug] purge requested for kubeslice-worker\n    Error: INSTALLATION FAILED: release kubeslice-worker failed, and has been uninstalled due to atomic being set: client rate limiter Wait returned an error: rate: Wait(n=1) would exceed context deadline\n    helm.go:84: [debug] client rate limiter Wait returned an error: rate: Wait(n=1) would exceed context deadline\n    release kubeslice-worker failed, and has been uninstalled due to atomic being set\n    helm.sh/helm/v3/pkg/action.(*Install).failRelease\n    \thelm.sh/helm/v3/pkg/action/install.go:449\n    helm.sh/helm/v3/pkg/action.(*Install).reportToRun\n    \thelm.sh/helm/v3/pkg/action/install.go:433\n    helm.sh/helm/v3/pkg/action.(*Install).performInstall\n    \thelm.sh/helm/v3/pkg/action/install.go:389\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:141\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\noccurred","time":{"start":1667537247000,"stop":1667537663848,"duration":416848}},{"uid":"9309e461adca2c29","status":"passed","time":{"start":1667458785000,"stop":1667459039258,"duration":254258}},{"uid":"9f73749105a056a3","status":"passed","time":{"start":1667389661000,"stop":1667389899306,"duration":238306}},{"uid":"423312bd8ae88391","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc00000e0c0>: {\n        Underlying: <*exec.ExitError | 0xc000716000>{\n            ProcessState: {\n                pid: 5870,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 1, Usec: 980811},\n                    Stime: {Sec: 0, Usec: 302292},\n                    Maxrss: 97976,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 21324,\n                    Majflt: 3,\n                    Nswap: 0,\n                    Inblock: 512,\n                    Oublock: 20872,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 4459,\n                    Nivcsw: 5062,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"install.go:192: [debug] Original chart version: \\\"\\\"\",\n                        \"install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-worker-0.4.4.tgz\",\n                        \"\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:165: [debug] Clearing discovery cache\",\n                        \"wait.go:66: [debug] beginning wait for 7 resources with timeout of 1m0s\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:310: [debug] Starting delete for \\\"kubeslice-preinstall\\\" ServiceAccount\",\n                        \"client.go:339: [debug] serviceaccounts \\\"kubeslice-preinstall\\\" not found\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:310: [debug] Starting delete for \\\"kubeslice-preinstall-role\\\" ClusterRole\",\n                        \"client.go:339: [debug] clusterroles.rbac.authorization.k8s.io \\\"kubeslice-preinstall-role\\\" not found\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:310: [debug] Starting delete for \\\"kubeslice-preinstall-rolebinding\\\" ClusterRoleBinding\",\n                        \"client.go:339: [debug] clusterrolebindings.rbac.authorization.k8s.io \\\"kubeslice-preinstall-rolebinding\\\" not found\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:310: [debug] Starting delete for \\\"kubeslice-worker-preinstall-configmap\\\" ConfigMap\",\n                        \"client.go:339: [debug] configmaps \\\"kubeslice-worker-preinstall-configmap\\\" not found\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:310: [debug] Starting delete for \\\"kubeslice-worker-preinstall-job\\\" Job\",\n                        \"client.go:339: [debug] jobs.batch \\\"kubeslice-worker-preinstall-job\\\" not found\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:540: [debug] Watching for changes to Job kubeslice-worker-preinstall-job with timeout of 5m0s\",\n                        \"client.go:568: [debug] Add/Modify event for kubeslice-worker-preinstall-job: ADDED\",\n                        \"client.go:607: [debug] kubeslice-worker-preinstall-job: Jobs active: 0, jobs failed: 0, jobs succeeded: 0\",\n                        \"client.go:568: [debug] Add/Modify event for kubeslice-worker-preinstall-job: MODIFIED\",\n                        \"cl...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; install.go:192: [debug] Original chart version: \"\"\n    install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-worker-0.4.4.tgz\n    \n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 1 resource(s)\n    install.go:165: [debug] Clearing discovery cache\n    wait.go:66: [debug] beginning wait for 7 resources with timeout of 1m0s\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:310: [debug] Starting delete for \"kubeslice-preinstall\" ServiceAccount\n    client.go:339: [debug] serviceaccounts \"kubeslice-preinstall\" not found\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:310: [debug] Starting delete for \"kubeslice-preinstall-role\" ClusterRole\n    client.go:339: [debug] clusterroles.rbac.authorization.k8s.io \"kubeslice-preinstall-role\" not found\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:310: [debug] Starting delete for \"kubeslice-preinstall-rolebinding\" ClusterRoleBinding\n    client.go:339: [debug] clusterrolebindings.rbac.authorization.k8s.io \"kubeslice-preinstall-rolebinding\" not found\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:310: [debug] Starting delete for \"kubeslice-worker-preinstall-configmap\" ConfigMap\n    client.go:339: [debug] configmaps \"kubeslice-worker-preinstall-configmap\" not found\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:310: [debug] Starting delete for \"kubeslice-worker-preinstall-job\" Job\n    client.go:339: [debug] jobs.batch \"kubeslice-worker-preinstall-job\" not found\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:540: [debug] Watching for changes to Job kubeslice-worker-preinstall-job with timeout of 5m0s\n    client.go:568: [debug] Add/Modify event for kubeslice-worker-preinstall-job: ADDED\n    client.go:607: [debug] kubeslice-worker-preinstall-job: Jobs active: 0, jobs failed: 0, jobs succeeded: 0\n    client.go:568: [debug] Add/Modify event for kubeslice-worker-preinstall-job: MODIFIED\n    client.go:607: [debug] kubeslice-worker-preinstall-job: Jobs active: 1, jobs failed: 0, jobs succeeded: 0\n    client.go:568: [debug] Add/Modify event for kubeslice-worker-preinstall-job: MODIFIED\n    client.go:607: [debug] kubeslice-worker-preinstall-job: Jobs active: 1, jobs failed: 1, jobs succeeded: 0\n    client.go:568: [debug] Add/Modify event for kubeslice-worker-preinstall-job: MODIFIED\n    client.go:607: [debug] kubeslice-worker-preinstall-job: Jobs active: 1, jobs failed: 2, jobs succeeded: 0\n    client.go:568: [debug] Add/Modify event for kubeslice-worker-preinstall-job: MODIFIED\n    client.go:607: [debug] kubeslice-worker-preinstall-job: Jobs active: 1, jobs failed: 3, jobs succeeded: 0\n    client.go:568: [debug] Add/Modify event for kubeslice-worker-preinstall-job: MODIFIED\n    client.go:607: [debug] kubeslice-worker-preinstall-job: Jobs active: 1, jobs failed: 4, jobs succeeded: 0\n    client.go:310: [debug] Starting delete for \"kubeslice-worker-preinstall-job\" Job\n    install.go:441: [debug] Install failed and atomic is set, uninstalling release\n    uninstall.go:95: [debug] uninstall: Deleting kubeslice-worker\n    client.go:310: [debug] Starting delete for \"kubeslice-webhook-service\" Service\n    client.go:310: [debug] Starting delete for \"jaeger\" Service\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-svc\" Service\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" Service\n    client.go:339: [debug] services \"jaeger\" not found\n    client.go:339: [debug] services \"nsm-admission-webhook-svc\" not found\n    client.go:339: [debug] services \"kubeslice-dns\" not found\n    client.go:339: [debug] services \"kubeslice-webhook-service\" not found\n    client.go:310: [debug] Starting delete for \"kubeslice-operator\" Deployment\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook\" Deployment\n    client.go:310: [debug] Starting delete for \"jaeger\" Deployment\n    client.go:310: [debug] Starting delete for \"prefix-service\" Deployment\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" Deployment\n    client.go:339: [debug] deployments.apps \"kubeslice-operator\" not found\n    client.go:339: [debug] deployments.apps \"jaeger\" not found\n    client.go:339: [debug] deployments.apps \"nsm-admission-webhook\" not found\n    client.go:339: [debug] deployments.apps \"prefix-service\" not found\n    client.go:339: [debug] deployments.apps \"kubeslice-dns\" not found\n    client.go:310: [debug] Starting delete for \"kubeslice-netop\" DaemonSet\n    client.go:310: [debug] Starting delete for \"nsm-kernel-forwarder\" DaemonSet\n    client.go:310: [debug] Starting delete for \"nsmgr\" DaemonSet\n    client.go:339: [debug] daemonsets.apps \"kubeslice-netop\" not found\n    client.go:339: [debug] daemonsets.apps \"nsm-kernel-forwarder\" not found\n    client.go:339: [debug] daemonsets.apps \"nsmgr\" not found\n    client.go:310: [debug] Starting delete for \"kubeslice-leader-election-rolebinding\" RoleBinding\n    client.go:339: [debug] rolebindings.rbac.authorization.k8s.io \"kubeslice-leader-election-rolebinding\" not found\n    client.go:310: [debug] Starting delete for \"kubeslice-leader-election-role\" Role\n    client.go:339: [debug] roles.rbac.authorization.k8s.io \"kubeslice-leader-election-role\" not found\n    client.go:310: [debug] Starting delete for \"nsm-role-binding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-dns-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-proxy-rolebinding\" ClusterRoleBinding\n    client.go:339: [debug] clusterrolebindings.rbac.authorization.k8s.io \"kubeslice-dns-rolebinding\" not found\n    client.go:339: [debug] clusterrolebindings.rbac.authorization.k8s.io \"nsm-role-binding\" not found\n    client.go:339: [debug] clusterrolebindings.rbac.authorization.k8s.io \"kubeslice-manager-rolebinding\" not found\n    client.go:339: [debug] clusterrolebindings.rbac.authorization.k8s.io \"kubeslice-kubernetes-dashboard\" not found\n    client.go:339: [debug] clusterrolebindings.rbac.authorization.k8s.io \"kubeslice-proxy-rolebinding\" not found\n    client.go:310: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ClusterRole\n    client.go:310: [debug] Starting delete for \"nsm-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"aggregate-network-services-view\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-dns-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-metrics-reader\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-proxy-role\" ClusterRole\n    client.go:339: [debug] clusterroles.rbac.authorization.k8s.io \"kubeslice-proxy-role\" not found\n    client.go:339: [debug] clusterroles.rbac.authorization.k8s.io \"kubeslice-dns-role\" not found\n    client.go:339: [debug] clusterroles.rbac.authorization.k8s.io \"nsm-role\" not found\n    client.go:339: [debug] clusterroles.rbac.authorization.k8s.io \"kubeslice-kubernetes-dashboard\" not found\n    client.go:339: [debug] clusterroles.rbac.authorization.k8s.io \"kubeslice-metrics-reader\" not found\n    client.go:339: [debug] clusterroles.rbac.authorization.k8s.io \"aggregate-network-services-view\" not found\n    client.go:339: [debug] clusterroles.rbac.authorization.k8s.io \"kubeslice-manager-role\" not found\n    client.go:310: [debug] Starting delete for \"networkservices.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"networkserviceendpoints.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"networkservicemanagers.networkservicemesh.io\" CustomResourceDefinition\n    client.go:339: [debug] customresourcedefinitions.apiextensions.k8s.io \"networkservices.networkservicemesh.io\" not found\n    client.go:339: [debug] customresourcedefinitions.apiextensions.k8s.io \"networkservicemanagers.networkservicemesh.io\" not found\n    client.go:339: [debug] customresourcedefinitions.apiextensions.k8s.io \"networkserviceendpoints.networkservicemesh.io\" not found\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-config\" ConfigMap\n    client.go:310: [debug] Starting delete for \"nsm-config\" ConfigMap\n    client.go:339: [debug] configmaps \"kubeslice-manager-config\" not found\n    client.go:339: [debug] configmaps \"nsm-config\" not found\n    client.go:310: [debug] Starting delete for \"kubeslice-admission-webhook-certs\" Secret\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-certs\" Secret\n    client.go:310: [debug] Starting delete for \"kubeslice-hub\" Secret\n    client.go:310: [debug] Starting delete for \"kubeslice-image-pull-secret\" Secret\n    client.go:339: [debug] secrets \"kubeslice-admission-webhook-certs\" not found\n    client.go:339: [debug] secrets \"nsm-admission-webhook-certs\" not found\n    client.go:339: [debug] secrets \"kubeslice-image-pull-secret\" not found\n    client.go:339: [debug] secrets \"kubeslice-hub\" not found\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-manager\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nse-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nsc-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nsmgr-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"forward-plane-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-netop\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"vpn-gateway-server\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"vpn-gateway-client\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"slice-router\" ServiceAccount\n    client.go:339: [debug] serviceaccounts \"kubeslice-controller-manager\" not found\n    client.go:339: [debug] serviceaccounts \"kubeslice-kubernetes-dashboard\" not found\n    client.go:339: [debug] serviceaccounts \"nsmgr-acc\" not found\n    client.go:339: [debug] serviceaccounts \"slice-router\" not found\n    client.go:339: [debug] serviceaccounts \"vpn-gateway-server\" not found\n    client.go:339: [debug] serviceaccounts \"vpn-gateway-client\" not found\n    client.go:339: [debug] serviceaccounts \"kubeslice-dns\" not found\n    client.go:339: [debug] serviceaccounts \"nsc-acc\" not found\n    client.go:339: [debug] serviceaccounts \"forward-plane-acc\" not found\n    client.go:339: [debug] serviceaccounts \"nse-acc\" not found\n    client.go:339: [debug] serviceaccounts \"kubeslice-netop\" not found\n    client.go:310: [debug] Starting delete for \"kubeslice-mutating-webhook-configuration\" MutatingWebhookConfiguration\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-cfg\" MutatingWebhookConfiguration\n    client.go:339: [debug] mutatingwebhookconfigurations.admissionregistration.k8s.io \"kubeslice-mutating-webhook-configuration\" not found\n    client.go:339: [debug] mutatingwebhookconfigurations.admissionregistration.k8s.io \"nsm-admission-webhook-cfg\" not found\n    uninstall.go:148: [debug] purge requested for kubeslice-worker\n    Error: INSTALLATION FAILED: release kubeslice-worker failed, and has been uninstalled due to atomic being set: failed pre-install: timed out waiting for the condition\n    helm.go:84: [debug] failed pre-install: timed out waiting for the condition\n    release kubeslice-worker failed, and has been uninstalled due to atomic being set\n    helm.sh/helm/v3/pkg/action.(*Install).failRelease\n    \thelm.sh/helm/v3/pkg/action/install.go:449\n    helm.sh/helm/v3/pkg/action.(*Install).reportToRun\n    \thelm.sh/helm/v3/pkg/action/install.go:433\n    helm.sh/helm/v3/pkg/action.(*Install).performInstall\n    \thelm.sh/helm/v3/pkg/action/install.go:361\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:141\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\noccurred","time":{"start":1667387754000,"stop":1667388109973,"duration":355973}},{"uid":"e5cfe4903620e0e8","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc0004f8120>: {\n        Underlying: <*exec.ExitError | 0xc000492200>{\n            ProcessState: {\n                pid: 6234,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 0, Usec: 99789},\n                    Stime: {Sec: 0, Usec: 29105},\n                    Maxrss: 48972,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 2570,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 0,\n                    Oublock: 168,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 524,\n                    Nivcsw: 316,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"install.go:192: [debug] Original chart version: \\\"1.7.0\\\"\",\n                        \"install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/cert-manager-v1.7.0.tgz\",\n                        \"\",\n                        \"Error: INSTALLATION FAILED: cannot re-use a name that is still in use\",\n                        \"helm.go:84: [debug] cannot re-use a name that is still in use\",\n                        \"helm.sh/helm/v3/pkg/action.(*Install).availableName\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:483\",\n                        \"helm.sh/helm/v3/pkg/action.(*Install).RunWithContext\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:197\",\n                        \"main.runInstall\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:278\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:139\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:872\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:990\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:918\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:250\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1571\",\n                        \"INSTALLATION FAILED\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:141\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:872\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:990\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:918\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:250\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1571\",\n                    ],\n                },\n            },\n            stderr: {\n                Lines: [\n                    \"install.go:192: [debug] Original chart version: \\\"1.7.0\\\"\",\n                    \"install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/cert-manager-v1.7.0.tgz\",\n                    \"\",\n                    \"Error: INSTALLATION FAILED: cannot re-use a name that is still in use\",\n                    \"helm.go:84: [debug] cannot re-use a name that is still in use...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; install.go:192: [debug] Original chart version: \"1.7.0\"\n    install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/cert-manager-v1.7.0.tgz\n    \n    Error: INSTALLATION FAILED: cannot re-use a name that is still in use\n    helm.go:84: [debug] cannot re-use a name that is still in use\n    helm.sh/helm/v3/pkg/action.(*Install).availableName\n    \thelm.sh/helm/v3/pkg/action/install.go:483\n    helm.sh/helm/v3/pkg/action.(*Install).RunWithContext\n    \thelm.sh/helm/v3/pkg/action/install.go:197\n    main.runInstall\n    \thelm.sh/helm/v3/cmd/helm/install.go:278\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:139\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:141\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\noccurred","time":{"start":1667385863000,"stop":1667385863638,"duration":638}},{"uid":"55f92fa72945e284","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc0001132c0>: {\n        Underlying: <*exec.ExitError | 0xc000158080>{\n            ProcessState: {\n                pid: 6231,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 0, Usec: 87334},\n                    Stime: {Sec: 0, Usec: 26580},\n                    Maxrss: 49340,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 2140,\n                    Majflt: 1,\n                    Nswap: 0,\n                    Inblock: 0,\n                    Oublock: 160,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 637,\n                    Nivcsw: 287,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"install.go:192: [debug] Original chart version: \\\"1.7.0\\\"\",\n                        \"install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/cert-manager-v1.7.0.tgz\",\n                        \"\",\n                        \"Error: INSTALLATION FAILED: cannot re-use a name that is still in use\",\n                        \"helm.go:84: [debug] cannot re-use a name that is still in use\",\n                        \"helm.sh/helm/v3/pkg/action.(*Install).availableName\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:483\",\n                        \"helm.sh/helm/v3/pkg/action.(*Install).RunWithContext\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:197\",\n                        \"main.runInstall\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:278\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:139\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:872\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:990\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:918\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:250\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1571\",\n                        \"INSTALLATION FAILED\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:141\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:872\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:990\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:918\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:250\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1571\",\n                    ],\n                },\n            },\n            stderr: {\n                Lines: [\n                    \"install.go:192: [debug] Original chart version: \\\"1.7.0\\\"\",\n                    \"install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/cert-manager-v1.7.0.tgz\",\n                    \"\",\n                    \"Error: INSTALLATION FAILED: cannot re-use a name that is still in use\",\n                    \"helm.go:84: [debug] cannot re-use a name that is still in use...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; install.go:192: [debug] Original chart version: \"1.7.0\"\n    install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/cert-manager-v1.7.0.tgz\n    \n    Error: INSTALLATION FAILED: cannot re-use a name that is still in use\n    helm.go:84: [debug] cannot re-use a name that is still in use\n    helm.sh/helm/v3/pkg/action.(*Install).availableName\n    \thelm.sh/helm/v3/pkg/action/install.go:483\n    helm.sh/helm/v3/pkg/action.(*Install).RunWithContext\n    \thelm.sh/helm/v3/pkg/action/install.go:197\n    main.runInstall\n    \thelm.sh/helm/v3/cmd/helm/install.go:278\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:139\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:141\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\noccurred","time":{"start":1667294317000,"stop":1667294317406,"duration":406}},{"uid":"e6054492f59d7280","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc000480b88>: {\n        Underlying: <*exec.ExitError | 0xc0004965a0>{\n            ProcessState: {\n                pid: 6415,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 0, Usec: 168560},\n                    Stime: {Sec: 0, Usec: 29498},\n                    Maxrss: 51724,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 2679,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 0,\n                    Oublock: 360,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 655,\n                    Nivcsw: 377,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"install.go:192: [debug] Original chart version: \\\"v1.8.0\\\"\",\n                        \"install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/cert-manager-v1.8.0.tgz\",\n                        \"\",\n                        \"Error: INSTALLATION FAILED: cannot re-use a name that is still in use\",\n                        \"helm.go:84: [debug] cannot re-use a name that is still in use\",\n                        \"helm.sh/helm/v3/pkg/action.(*Install).availableName\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:483\",\n                        \"helm.sh/helm/v3/pkg/action.(*Install).RunWithContext\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:197\",\n                        \"main.runInstall\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:278\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:139\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:872\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:990\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:918\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:250\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1571\",\n                        \"INSTALLATION FAILED\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:141\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:872\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:990\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:918\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:250\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1571\",\n                    ],\n                },\n            },\n            stderr: {\n                Lines: [\n                    \"install.go:192: [debug] Original chart version: \\\"v1.8.0\\\"\",\n                    \"install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/cert-manager-v1.8.0.tgz\",\n                    \"\",\n                    \"Error: INSTALLATION FAILED: cannot re-use a name that is still in use\",\n                    \"helm.go:84: [debug] cannot re-use a name that is still in ...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; install.go:192: [debug] Original chart version: \"v1.8.0\"\n    install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/cert-manager-v1.8.0.tgz\n    \n    Error: INSTALLATION FAILED: cannot re-use a name that is still in use\n    helm.go:84: [debug] cannot re-use a name that is still in use\n    helm.sh/helm/v3/pkg/action.(*Install).availableName\n    \thelm.sh/helm/v3/pkg/action/install.go:483\n    helm.sh/helm/v3/pkg/action.(*Install).RunWithContext\n    \thelm.sh/helm/v3/pkg/action/install.go:197\n    main.runInstall\n    \thelm.sh/helm/v3/cmd/helm/install.go:278\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:139\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:141\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\noccurred","time":{"start":1666884621000,"stop":1666884621383,"duration":383}},{"uid":"42478527bc4f81ce","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc00047a0a8>: {\n        Underlying: <*exec.ExitError | 0xc00014c040>{\n            ProcessState: {\n                pid: 6314,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 0, Usec: 46205},\n                    Stime: {Sec: 0, Usec: 14216},\n                    Maxrss: 40728,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 1480,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 0,\n                    Oublock: 0,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 256,\n                    Nivcsw: 124,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"install.go:192: [debug] Original chart version: \\\"\\\"\",\n                        \"Error: INSTALLATION FAILED: looks like \\\"https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages\\\" is not a valid chart repository or cannot be reached: failed to fetch https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages/index.yaml : 404 Not Found\",\n                        \"helm.go:84: [debug] failed to fetch https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages/index.yaml : 404 Not Found\",\n                        \"helm.sh/helm/v3/pkg/getter.(*HTTPGetter).get\",\n                        \"\\thelm.sh/helm/v3/pkg/getter/httpgetter.go:92\",\n                        \"helm.sh/helm/v3/pkg/getter.(*HTTPGetter).Get\",\n                        \"\\thelm.sh/helm/v3/pkg/getter/httpgetter.go:45\",\n                        \"helm.sh/helm/v3/pkg/repo.(*ChartRepository).DownloadIndexFile\",\n                        \"\\thelm.sh/helm/v3/pkg/repo/chartrepo.go:128\",\n                        \"helm.sh/helm/v3/pkg/repo.FindChartInAuthAndTLSAndPassRepoURL\",\n                        \"\\thelm.sh/helm/v3/pkg/repo/chartrepo.go:252\",\n                        \"helm.sh/helm/v3/pkg/action.(*ChartPathOptions).LocateChart\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:723\",\n                        \"main.runInstall\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:204\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:139\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:872\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:990\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:918\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:250\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1571\",\n                        \"looks like \\\"https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages\\\" is not a valid chart repository or cannot be reached\",\n                        \"helm.sh/helm/v3/pkg/repo.FindChartInAuthAndTLSAndPassRepoURL\",\n                        \"\\thelm.sh/helm/v3/pkg/repo/chartrepo.go:254\",\n                        \"helm.sh/helm/v3/pkg/action.(*ChartPathOptions).LocateChart\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:723\",\n                        \"main.runInstall\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:204\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:139\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n           ...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; install.go:192: [debug] Original chart version: \"\"\n    Error: INSTALLATION FAILED: looks like \"https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages\" is not a valid chart repository or cannot be reached: failed to fetch https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages/index.yaml : 404 Not Found\n    helm.go:84: [debug] failed to fetch https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages/index.yaml : 404 Not Found\n    helm.sh/helm/v3/pkg/getter.(*HTTPGetter).get\n    \thelm.sh/helm/v3/pkg/getter/httpgetter.go:92\n    helm.sh/helm/v3/pkg/getter.(*HTTPGetter).Get\n    \thelm.sh/helm/v3/pkg/getter/httpgetter.go:45\n    helm.sh/helm/v3/pkg/repo.(*ChartRepository).DownloadIndexFile\n    \thelm.sh/helm/v3/pkg/repo/chartrepo.go:128\n    helm.sh/helm/v3/pkg/repo.FindChartInAuthAndTLSAndPassRepoURL\n    \thelm.sh/helm/v3/pkg/repo/chartrepo.go:252\n    helm.sh/helm/v3/pkg/action.(*ChartPathOptions).LocateChart\n    \thelm.sh/helm/v3/pkg/action/install.go:723\n    main.runInstall\n    \thelm.sh/helm/v3/cmd/helm/install.go:204\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:139\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\n    looks like \"https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages\" is not a valid chart repository or cannot be reached\n    helm.sh/helm/v3/pkg/repo.FindChartInAuthAndTLSAndPassRepoURL\n    \thelm.sh/helm/v3/pkg/repo/chartrepo.go:254\n    helm.sh/helm/v3/pkg/action.(*ChartPathOptions).LocateChart\n    \thelm.sh/helm/v3/pkg/action/install.go:723\n    main.runInstall\n    \thelm.sh/helm/v3/cmd/helm/install.go:204\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:139\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:141\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\noccurred","time":{"start":1666754282000,"stop":1666754357231,"duration":75231}},{"uid":"86aac3dc8de50f84","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc0000aa360>: {\n        Underlying: <*exec.ExitError | 0xc0000ae060>{\n            ProcessState: {\n                pid: 6343,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 0, Usec: 40540},\n                    Stime: {Sec: 0, Usec: 12162},\n                    Maxrss: 40580,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 1955,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 0,\n                    Oublock: 0,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 285,\n                    Nivcsw: 120,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"install.go:192: [debug] Original chart version: \\\"\\\"\",\n                        \"Error: INSTALLATION FAILED: looks like \\\"https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages/\\\" is not a valid chart repository or cannot be reached: failed to fetch https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages/index.yaml : 404 Not Found\",\n                        \"helm.go:84: [debug] failed to fetch https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages/index.yaml : 404 Not Found\",\n                        \"helm.sh/helm/v3/pkg/getter.(*HTTPGetter).get\",\n                        \"\\thelm.sh/helm/v3/pkg/getter/httpgetter.go:92\",\n                        \"helm.sh/helm/v3/pkg/getter.(*HTTPGetter).Get\",\n                        \"\\thelm.sh/helm/v3/pkg/getter/httpgetter.go:45\",\n                        \"helm.sh/helm/v3/pkg/repo.(*ChartRepository).DownloadIndexFile\",\n                        \"\\thelm.sh/helm/v3/pkg/repo/chartrepo.go:128\",\n                        \"helm.sh/helm/v3/pkg/repo.FindChartInAuthAndTLSAndPassRepoURL\",\n                        \"\\thelm.sh/helm/v3/pkg/repo/chartrepo.go:252\",\n                        \"helm.sh/helm/v3/pkg/action.(*ChartPathOptions).LocateChart\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:723\",\n                        \"main.runInstall\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:204\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:139\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:872\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:990\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:918\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:250\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1571\",\n                        \"looks like \\\"https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages/\\\" is not a valid chart repository or cannot be reached\",\n                        \"helm.sh/helm/v3/pkg/repo.FindChartInAuthAndTLSAndPassRepoURL\",\n                        \"\\thelm.sh/helm/v3/pkg/repo/chartrepo.go:254\",\n                        \"helm.sh/helm/v3/pkg/action.(*ChartPathOptions).LocateChart\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:723\",\n                        \"main.runInstall\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:204\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:139\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n         ...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; install.go:192: [debug] Original chart version: \"\"\n    Error: INSTALLATION FAILED: looks like \"https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages/\" is not a valid chart repository or cannot be reached: failed to fetch https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages/index.yaml : 404 Not Found\n    helm.go:84: [debug] failed to fetch https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages/index.yaml : 404 Not Found\n    helm.sh/helm/v3/pkg/getter.(*HTTPGetter).get\n    \thelm.sh/helm/v3/pkg/getter/httpgetter.go:92\n    helm.sh/helm/v3/pkg/getter.(*HTTPGetter).Get\n    \thelm.sh/helm/v3/pkg/getter/httpgetter.go:45\n    helm.sh/helm/v3/pkg/repo.(*ChartRepository).DownloadIndexFile\n    \thelm.sh/helm/v3/pkg/repo/chartrepo.go:128\n    helm.sh/helm/v3/pkg/repo.FindChartInAuthAndTLSAndPassRepoURL\n    \thelm.sh/helm/v3/pkg/repo/chartrepo.go:252\n    helm.sh/helm/v3/pkg/action.(*ChartPathOptions).LocateChart\n    \thelm.sh/helm/v3/pkg/action/install.go:723\n    main.runInstall\n    \thelm.sh/helm/v3/cmd/helm/install.go:204\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:139\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\n    looks like \"https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages/\" is not a valid chart repository or cannot be reached\n    helm.sh/helm/v3/pkg/repo.FindChartInAuthAndTLSAndPassRepoURL\n    \thelm.sh/helm/v3/pkg/repo/chartrepo.go:254\n    helm.sh/helm/v3/pkg/action.(*ChartPathOptions).LocateChart\n    \thelm.sh/helm/v3/pkg/action/install.go:723\n    main.runInstall\n    \thelm.sh/helm/v3/cmd/helm/install.go:204\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:139\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:141\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\noccurred","time":{"start":1666750523000,"stop":1666750614389,"duration":91389}},{"uid":"eef7da4dbff2758e","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc0000b83d8>: {\n        Underlying: <*exec.ExitError | 0xc0004c05c0>{\n            ProcessState: {\n                pid: 6363,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 0, Usec: 129403},\n                    Stime: {Sec: 0, Usec: 29578},\n                    Maxrss: 51804,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 2152,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 0,\n                    Oublock: 360,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 726,\n                    Nivcsw: 358,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"install.go:192: [debug] Original chart version: \\\"v1.8.0\\\"\",\n                        \"install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/cert-manager-v1.8.0.tgz\",\n                        \"\",\n                        \"Error: INSTALLATION FAILED: cannot re-use a name that is still in use\",\n                        \"helm.go:84: [debug] cannot re-use a name that is still in use\",\n                        \"helm.sh/helm/v3/pkg/action.(*Install).availableName\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:483\",\n                        \"helm.sh/helm/v3/pkg/action.(*Install).RunWithContext\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:197\",\n                        \"main.runInstall\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:278\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:139\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:872\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:990\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:918\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:250\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1571\",\n                        \"INSTALLATION FAILED\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:141\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:872\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:990\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:918\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:250\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1571\",\n                    ],\n                },\n            },\n            stderr: {\n                Lines: [\n                    \"install.go:192: [debug] Original chart version: \\\"v1.8.0\\\"\",\n                    \"install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/cert-manager-v1.8.0.tgz\",\n                    \"\",\n                    \"Error: INSTALLATION FAILED: cannot re-use a name that is still in use\",\n                    \"helm.go:84: [debug] cannot re-use a name that is still in ...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; install.go:192: [debug] Original chart version: \"v1.8.0\"\n    install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/cert-manager-v1.8.0.tgz\n    \n    Error: INSTALLATION FAILED: cannot re-use a name that is still in use\n    helm.go:84: [debug] cannot re-use a name that is still in use\n    helm.sh/helm/v3/pkg/action.(*Install).availableName\n    \thelm.sh/helm/v3/pkg/action/install.go:483\n    helm.sh/helm/v3/pkg/action.(*Install).RunWithContext\n    \thelm.sh/helm/v3/pkg/action/install.go:197\n    main.runInstall\n    \thelm.sh/helm/v3/cmd/helm/install.go:278\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:139\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:141\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\noccurred","time":{"start":1666748075000,"stop":1666748075368,"duration":368}},{"uid":"90e4924138da3b7c","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc00000e3c0>: {\n        Underlying: <*exec.ExitError | 0xc000474e60>{\n            ProcessState: {\n                pid: 6417,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 0, Usec: 117546},\n                    Stime: {Sec: 0, Usec: 26121},\n                    Maxrss: 51636,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 2614,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 0,\n                    Oublock: 360,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 677,\n                    Nivcsw: 254,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"install.go:192: [debug] Original chart version: \\\"v1.8.0\\\"\",\n                        \"install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/cert-manager-v1.8.0.tgz\",\n                        \"\",\n                        \"Error: INSTALLATION FAILED: cannot re-use a name that is still in use\",\n                        \"helm.go:84: [debug] cannot re-use a name that is still in use\",\n                        \"helm.sh/helm/v3/pkg/action.(*Install).availableName\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:483\",\n                        \"helm.sh/helm/v3/pkg/action.(*Install).RunWithContext\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:197\",\n                        \"main.runInstall\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:278\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:139\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:872\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:990\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:918\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:250\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1571\",\n                        \"INSTALLATION FAILED\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:141\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:872\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:990\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:918\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:250\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1571\",\n                    ],\n                },\n            },\n            stderr: {\n                Lines: [\n                    \"install.go:192: [debug] Original chart version: \\\"v1.8.0\\\"\",\n                    \"install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/cert-manager-v1.8.0.tgz\",\n                    \"\",\n                    \"Error: INSTALLATION FAILED: cannot re-use a name that is still in use\",\n                    \"helm.go:84: [debug] cannot re-use a name that is still in ...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; install.go:192: [debug] Original chart version: \"v1.8.0\"\n    install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/cert-manager-v1.8.0.tgz\n    \n    Error: INSTALLATION FAILED: cannot re-use a name that is still in use\n    helm.go:84: [debug] cannot re-use a name that is still in use\n    helm.sh/helm/v3/pkg/action.(*Install).availableName\n    \thelm.sh/helm/v3/pkg/action/install.go:483\n    helm.sh/helm/v3/pkg/action.(*Install).RunWithContext\n    \thelm.sh/helm/v3/pkg/action/install.go:197\n    main.runInstall\n    \thelm.sh/helm/v3/cmd/helm/install.go:278\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:139\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:141\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\noccurred","time":{"start":1666707346000,"stop":1666707346358,"duration":358}},{"uid":"7827bcf93de0a345","status":"passed","time":{"start":1666674621000,"stop":1666674807597,"duration":186597}},{"uid":"e2dd5779703a4c85","status":"passed","time":{"start":1666674212000,"stop":1666674379616,"duration":167616}},{"uid":"2ba107e5c0943fc8","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc0004eb728>: {\n        Underlying: <*exec.ExitError | 0xc000429200>{\n            ProcessState: {\n                pid: 6152,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 0, Usec: 124937},\n                    Stime: {Sec: 0, Usec: 50755},\n                    Maxrss: 51060,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 2646,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 536,\n                    Oublock: 152,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 964,\n                    Nivcsw: 433,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"install.go:192: [debug] Original chart version: \\\"1.7.0\\\"\",\n                        \"install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/cert-manager-v1.7.0.tgz\",\n                        \"\",\n                        \"Error: INSTALLATION FAILED: cannot re-use a name that is still in use\",\n                        \"helm.go:84: [debug] cannot re-use a name that is still in use\",\n                        \"helm.sh/helm/v3/pkg/action.(*Install).availableName\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:483\",\n                        \"helm.sh/helm/v3/pkg/action.(*Install).RunWithContext\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:197\",\n                        \"main.runInstall\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:278\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:139\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:872\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:990\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:918\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:250\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1571\",\n                        \"INSTALLATION FAILED\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:141\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:872\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:990\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:918\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:250\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1571\",\n                    ],\n                },\n            },\n            stderr: {\n                Lines: [\n                    \"install.go:192: [debug] Original chart version: \\\"1.7.0\\\"\",\n                    \"install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/cert-manager-v1.7.0.tgz\",\n                    \"\",\n                    \"Error: INSTALLATION FAILED: cannot re-use a name that is still in use\",\n                    \"helm.go:84: [debug] cannot re-use a name that is still in ...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; install.go:192: [debug] Original chart version: \"1.7.0\"\n    install.go:209: [debug] CHART PATH: /root/.cache/helm/repository/cert-manager-v1.7.0.tgz\n    \n    Error: INSTALLATION FAILED: cannot re-use a name that is still in use\n    helm.go:84: [debug] cannot re-use a name that is still in use\n    helm.sh/helm/v3/pkg/action.(*Install).availableName\n    \thelm.sh/helm/v3/pkg/action/install.go:483\n    helm.sh/helm/v3/pkg/action.(*Install).RunWithContext\n    \thelm.sh/helm/v3/pkg/action/install.go:197\n    main.runInstall\n    \thelm.sh/helm/v3/cmd/helm/install.go:278\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:139\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:141\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\noccurred","time":{"start":1666668056000,"stop":1666668056766,"duration":766}},{"uid":"68466ef777034499","status":"passed","time":{"start":1666665366000,"stop":1666665547982,"duration":181982}},{"uid":"49b373df43d85d4a","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc00000f6c8>: {\n        Underlying: <*exec.ExitError | 0xc0004b48e0>{\n            ProcessState: {\n                pid: 6265,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 0, Usec: 47955},\n                    Stime: {Sec: 0, Usec: 17438},\n                    Maxrss: 40172,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 2886,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 0,\n                    Oublock: 0,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 235,\n                    Nivcsw: 149,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"install.go:192: [debug] Original chart version: \\\"1.7.0\\\"\",\n                        \"Error: INSTALLATION FAILED: looks like \\\"https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages/\\\" is not a valid chart repository or cannot be reached: failed to fetch https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages/index.yaml : 404 Not Found\",\n                        \"helm.go:84: [debug] failed to fetch https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages/index.yaml : 404 Not Found\",\n                        \"helm.sh/helm/v3/pkg/getter.(*HTTPGetter).get\",\n                        \"\\thelm.sh/helm/v3/pkg/getter/httpgetter.go:92\",\n                        \"helm.sh/helm/v3/pkg/getter.(*HTTPGetter).Get\",\n                        \"\\thelm.sh/helm/v3/pkg/getter/httpgetter.go:45\",\n                        \"helm.sh/helm/v3/pkg/repo.(*ChartRepository).DownloadIndexFile\",\n                        \"\\thelm.sh/helm/v3/pkg/repo/chartrepo.go:128\",\n                        \"helm.sh/helm/v3/pkg/repo.FindChartInAuthAndTLSAndPassRepoURL\",\n                        \"\\thelm.sh/helm/v3/pkg/repo/chartrepo.go:252\",\n                        \"helm.sh/helm/v3/pkg/action.(*ChartPathOptions).LocateChart\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:723\",\n                        \"main.runInstall\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:204\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:139\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:872\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:990\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.5.0/command.go:918\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:250\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1571\",\n                        \"looks like \\\"https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages/\\\" is not a valid chart repository or cannot be reached\",\n                        \"helm.sh/helm/v3/pkg/repo.FindChartInAuthAndTLSAndPassRepoURL\",\n                        \"\\thelm.sh/helm/v3/pkg/repo/chartrepo.go:254\",\n                        \"helm.sh/helm/v3/pkg/action.(*ChartPathOptions).LocateChart\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:723\",\n                        \"main.runInstall\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:204\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:139\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n    ...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; install.go:192: [debug] Original chart version: \"1.7.0\"\n    Error: INSTALLATION FAILED: looks like \"https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages/\" is not a valid chart repository or cannot be reached: failed to fetch https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages/index.yaml : 404 Not Found\n    helm.go:84: [debug] failed to fetch https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages/index.yaml : 404 Not Found\n    helm.sh/helm/v3/pkg/getter.(*HTTPGetter).get\n    \thelm.sh/helm/v3/pkg/getter/httpgetter.go:92\n    helm.sh/helm/v3/pkg/getter.(*HTTPGetter).Get\n    \thelm.sh/helm/v3/pkg/getter/httpgetter.go:45\n    helm.sh/helm/v3/pkg/repo.(*ChartRepository).DownloadIndexFile\n    \thelm.sh/helm/v3/pkg/repo/chartrepo.go:128\n    helm.sh/helm/v3/pkg/repo.FindChartInAuthAndTLSAndPassRepoURL\n    \thelm.sh/helm/v3/pkg/repo/chartrepo.go:252\n    helm.sh/helm/v3/pkg/action.(*ChartPathOptions).LocateChart\n    \thelm.sh/helm/v3/pkg/action/install.go:723\n    main.runInstall\n    \thelm.sh/helm/v3/cmd/helm/install.go:204\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:139\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\n    looks like \"https://raw.githubusercontent.com/kubeslice/dev-charts-ent/gh-pages/\" is not a valid chart repository or cannot be reached\n    helm.sh/helm/v3/pkg/repo.FindChartInAuthAndTLSAndPassRepoURL\n    \thelm.sh/helm/v3/pkg/repo/chartrepo.go:254\n    helm.sh/helm/v3/pkg/action.(*ChartPathOptions).LocateChart\n    \thelm.sh/helm/v3/pkg/action/install.go:723\n    main.runInstall\n    \thelm.sh/helm/v3/cmd/helm/install.go:204\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:139\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:141\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:872\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:990\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.5.0/command.go:918\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\noccurred","time":{"start":1666664774000,"stop":1666664774170,"duration":170}}]},"tags":[]},"source":"e0bfaeaf9694d3c9.json","parameterValues":[]}