{"uid":"4b4757e66a1912dae1a509f688f20b0f","children":[{"name":"Product defects","children":[{"name":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc000924030>: {\n        Underlying: <*exec.ExitError | 0xc0007800e0>{\n            ProcessState: {\n                pid: 6409,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 0, Usec: 144373},\n                    Stime: {Sec: 0, Usec: 72186},\n                    Maxrss: 72092,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 10945,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 8,\n                    Oublock: 14104,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 869,\n                    Nivcsw: 483,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"error: resource mapping not found for name: \\\"profile4\\\" namespace: \\\"\\\" from \\\"/tmp/%20QosProfile%20tests%20QosProfile%20delete%20validation%20Delete%20qos%20profile%20-%20negative%20scenario3271559816\\\": no matches for kind \\\"SliceQoSConfig\\\" in version \\\"controller.kubeslice.io/v1alpha1\\\"\",\n                        \"ensure CRDs are installed first\",\n                    ],\n                },\n            },\n            stderr: {\n                Lines: [\n                    \"error: resource mapping not found for name: \\\"profile4\\\" namespace: \\\"\\\" from \\\"/tmp/%20QosProfile%20tests%20QosProfile%20delete%20validation%20Delete%20qos%20profile%20-%20negative%20scenario3271559816\\\": no matches for kind \\\"SliceQoSConfig\\\" in version \\\"controller.kubeslice.io/v1alpha1\\\"\",\n                    \"ensure CRDs are installed first\",\n                ],\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"error: resource mapping not found for name: \\\"profile4\\\" namespace: \\\"\\\" from \\\"/tmp/%20QosProfile%20tests%20QosProfile%20delete%20validation%20Delete%20qos%20profile%20-%20negative%20scenario3271559816\\\": no matches for kind \\\"SliceQoSConfig\\\" in version \\\"controller.kubeslice.io/v1alpha1\\\"\",\n                        \"ensure CRDs are installed first\",\n                    ],\n                },\n            },\n            merged: {\n                Mutex: {state: 0, sema: 0},\n                Lines: [\n                    \"error: resource mapping not found for name: \\\"profile4\\\" namespace: \\\"\\\" from \\\"/tmp/%20QosProfile%20tests%20QosProfile%20delete%20validation%20Delete%20qos%20profile%20-%20negative%20scenario3271559816\\\": no matches for kind \\\"SliceQoSConfig\\\" in version \\\"controller.kubeslice.io/v1alpha1\\\"\",\n                    \"ensure CRDs are installed first\",\n                ],\n            },\n        },\n    }\n    error while running command: exit status 1; error: resource mapping not found for name: \"profile4\" namespace: \"\" from \"/tmp/%20QosProfile%20tests%20QosProfile%20delete%20validation%20Delete%20qos%20profile%20-%20negative%20scenario3271559816\": no matches for kind \"SliceQoSConfig\" in version \"controller.kubeslice.io/v1alpha1\"\n    ensure CRDs are installed first\noccurred","children":[{"name":"[It]  QosProfile tests QosProfile delete validation Delete qos profile - negative scenario","uid":"2485f74210271949","parentUid":"08689632328512ca0ef026726db40089","status":"failed","time":{"start":1659946653000,"stop":1659946657595,"duration":4595},"flaky":false,"newFailed":false,"newPassed":false,"newBroken":false,"retriesCount":0,"retriesStatusChange":false,"parameters":[]}],"uid":"08689632328512ca0ef026726db40089"},{"name":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc0009241c8>: {\n        Underlying: <*exec.ExitError | 0xc00072c160>{\n            ProcessState: {\n                pid: 6390,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 0, Usec: 141919},\n                    Stime: {Sec: 0, Usec: 86728},\n                    Maxrss: 77520,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 13537,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 0,\n                    Oublock: 14104,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 1120,\n                    Nivcsw: 756,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"error: resource mapping not found for name: \\\"profile4\\\" namespace: \\\"\\\" from \\\"/tmp/%20QosProfile%20tests%20QosProfile%20Create%20validation%20Creates%20qosprofile3458889802\\\": no matches for kind \\\"SliceQoSConfig\\\" in version \\\"controller.kubeslice.io/v1alpha1\\\"\",\n                        \"ensure CRDs are installed first\",\n                    ],\n                },\n            },\n            stderr: {\n                Lines: [\n                    \"error: resource mapping not found for name: \\\"profile4\\\" namespace: \\\"\\\" from \\\"/tmp/%20QosProfile%20tests%20QosProfile%20Create%20validation%20Creates%20qosprofile3458889802\\\": no matches for kind \\\"SliceQoSConfig\\\" in version \\\"controller.kubeslice.io/v1alpha1\\\"\",\n                    \"ensure CRDs are installed first\",\n                ],\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"error: resource mapping not found for name: \\\"profile4\\\" namespace: \\\"\\\" from \\\"/tmp/%20QosProfile%20tests%20QosProfile%20Create%20validation%20Creates%20qosprofile3458889802\\\": no matches for kind \\\"SliceQoSConfig\\\" in version \\\"controller.kubeslice.io/v1alpha1\\\"\",\n                        \"ensure CRDs are installed first\",\n                    ],\n                },\n            },\n            merged: {\n                Mutex: {state: 0, sema: 0},\n                Lines: [\n                    \"error: resource mapping not found for name: \\\"profile4\\\" namespace: \\\"\\\" from \\\"/tmp/%20QosProfile%20tests%20QosProfile%20Create%20validation%20Creates%20qosprofile3458889802\\\": no matches for kind \\\"SliceQoSConfig\\\" in version \\\"controller.kubeslice.io/v1alpha1\\\"\",\n                    \"ensure CRDs are installed first\",\n                ],\n            },\n        },\n    }\n    error while running command: exit status 1; error: resource mapping not found for name: \"profile4\" namespace: \"\" from \"/tmp/%20QosProfile%20tests%20QosProfile%20Create%20validation%20Creates%20qosprofile3458889802\": no matches for kind \"SliceQoSConfig\" in version \"controller.kubeslice.io/v1alpha1\"\n    ensure CRDs are installed first\noccurred","children":[{"name":"[It]  QosProfile tests QosProfile Create validation Creates qosprofile","uid":"6e6b655c8c8f2ab3","parentUid":"135b64adb0110eef151b90d804fa48fa","status":"failed","time":{"start":1659946653000,"stop":1659946660585,"duration":7585},"flaky":false,"newFailed":false,"newPassed":false,"newBroken":false,"retriesCount":0,"retriesStatusChange":false,"parameters":[]}],"uid":"135b64adb0110eef151b90d804fa48fa"},{"name":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc0004665d0>: {\n        Underlying: <*exec.ExitError | 0xc000790000>{\n            ProcessState: {\n                pid: 6721,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 2, Usec: 735640},\n                    Stime: {Sec: 0, Usec: 303527},\n                    Maxrss: 85648,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 6276,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 0,\n                    Oublock: 14168,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 22029,\n                    Nivcsw: 4799,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"install.go:178: [debug] Original chart version: \\\"\\\"\",\n                        \"install.go:195: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-worker-0.2.0.tgz\",\n                        \"\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:151: [debug] CRD serviceexports.networking.kubeslice.io is already present. Skipping.\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:151: [debug] CRD serviceimports.networking.kubeslice.io is already present. Skipping.\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:151: [debug] CRD slice.networking.kubeslice.io is already present. Skipping.\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:151: [debug] CRD slicegateways.networking.kubeslice.io is already present. Skipping.\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 44 resource(s)\",\n                        \"wait.go:48: [debug] beginning wait for 44 resources with timeout of 2m0s\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    install.go:178: [debug] Original chart version: \"\"\n    install.go:195: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-worker-0.2.0.tgz\n    \n    client.go:128: [debug] creating 1 resource(s)\n    install.go:151: [debug] CRD serviceexports.networking.kubeslice.io is already present. Skipping.\n    client.go:128: [debug] creating 1 resource(s)\n    install.go:151: [debug] CRD serviceimports.networking.kubeslice.io is already present. Skipping.\n    client.go:128: [debug] creating 1 resource(s)\n    install.go:151: [debug] CRD slice.networking.kubeslice.io is already present. Skipping.\n    client.go:128: [debug] creating 1 resource(s)\n    install.go:151: [debug] CRD slicegateways.networking.kubeslice.io is already present. Skipping.\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 44 resource(s)\n    wait.go:48: [debug] beginning wait for 44 resources with timeout of 2m0s\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    install.go:441: [debug] Install failed and atomic is set, uninstalling release\n    uninstall.go:95: [debug] uninstall: Deleting kubeslice-worker\n    client.go:310: [debug] Starting delete for \"jaeger\" Service\n    client.go:310: [debug] Starting delete for \"kubeslice-webhook-service\" Service\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-svc\" Service\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" Service\n    client.go:310: [debug] Starting delete for \"kubeslice-operator\" Deployment\n    client.go:310: [debug] Starting delete for \"jaeger\" Deployment\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook\" Deployment\n    client.go:310: [debug] Starting delete for \"prefix-service\" Deployment\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" Deployment\n    client.go:310: [debug] Starting delete for \"kubeslice-netop\" DaemonSet\n    client.go:310: [debug] Starting delete for \"nsm-kernel-forwarder\" DaemonSet\n    client.go:310: [debug] Starting delete for \"nsmgr\" DaemonSet\n    client.go:310: [debug] Starting delete for \"kubeslice-leader-election-rolebinding\" RoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-leader-election-role\" Role\n    client.go:310: [debug] Starting delete for \"kubeslice-proxy-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"nsm-role-binding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-dns-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-proxy-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"nsm-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"aggregate-network-services-view\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-dns-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-metrics-reader\" ClusterRole\n    client.go:310: [debug] Starting delete for \"networkservices.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"networkserviceendpoints.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"networkservicemanagers.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-config\" ConfigMap\n    client.go:310: [debug] Starting delete for \"nsm-config\" ConfigMap\n    client.go:310: [debug] Starting delete for \"kubeslice-admission-webhook-certs\" Secret\n    client.go:310: [debug] Starting delete for \"kubeslice-hub\" Secret\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-certs\" Secret\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-manager\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nse-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nsc-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nsmgr-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"forward-plane-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-netop\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"vpn-gateway-server\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"vpn-gateway-client\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"slice-router\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-mutating-webhook-configuration\" MutatingWebhookConfiguration\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-cfg\" MutatingWebhookConfiguration\n    uninstall.go:144: [debug] purge requested for kubeslice-worker\n    Error: INSTALLATION FAILED: release kubeslice-worker failed, and has been uninstalled due to atomic being set: timed out waiting for the condition\n    helm.go:84: [debug] timed out waiting for the condition\n    release kubeslice-worker failed, and has been uninstalled due to atomic being set\n    helm.sh/helm/v3/pkg/action.(*Install).failRelease\n    \thelm.sh/helm/v3/pkg/action/install.go:449\n    helm.sh/helm/v3/pkg/action.(*Install).reportToRun\n    \thelm.sh/helm/v3/pkg/action/install.go:433\n    helm.sh/helm/v3/pkg/action.(*Install).performInstall\n    \thelm.sh/helm/v3/pkg/action/install.go:389\n    runtime.goexit\n    \truntime/asm_amd64.s:1581\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:127\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:856\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:974\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:902\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:255\n    runtime.goexit\n    \truntime/asm_amd64.s:1581\noccurred","children":[{"name":"[BeforeSuite]","uid":"728ca22793e14624","parentUid":"1b481955ab64d707687e01c40f36517f","status":"failed","time":{"start":1659947425000,"stop":1659947655146,"duration":230146},"flaky":true,"newFailed":true,"newPassed":false,"newBroken":false,"retriesCount":0,"retriesStatusChange":false,"parameters":[]}],"uid":"1b481955ab64d707687e01c40f36517f"}],"uid":"8fb3a91ba5aaf9de24cc8a92edc82b5d"}],"name":"categories"}