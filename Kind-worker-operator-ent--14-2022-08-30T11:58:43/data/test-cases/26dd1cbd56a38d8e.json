{"uid":"26dd1cbd56a38d8e","name":"[BeforeSuite]","historyId":"Istio Suite:Istio Suite#[BeforeSuite]","time":{"start":1661859205000,"stop":1661859409301,"duration":204301},"status":"passed","flaky":false,"newFailed":false,"newBroken":false,"newPassed":true,"retriesCount":0,"retriesStatusChange":false,"beforeStages":[],"testStage":{"steps":[{"name":"","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"Report Entries:","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"By Step","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"/e2e/tests/istio/setup_test.go:45","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"2022-08-30T11:33:25.569568646Z","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"&{Text:installing cert-manager Duration:0s}","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"--","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"By Step","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"/e2e/tests/istio/setup_test.go:53","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"2022-08-30T11:34:41.646645156Z","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"&{Text:installing hub Duration:0s}","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"--","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"By Step","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"/e2e/tests/istio/setup_test.go:67","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"2022-08-30T11:34:54.681187526Z","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"&{Text:Deploying Project Duration:0s}","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"--","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"By Step","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"/e2e/tests/istio/setup_test.go:71","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"2022-08-30T11:34:56.037442817Z","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"&{Text:Waiting for project reconciliation Duration:0s}","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"--","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"By Step","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"/e2e/tests/istio/setup_test.go:77","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"2022-08-30T11:35:01.078068652Z","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"&{Text:Setup Cluster CRs for workers Duration:0s}","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"--","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"By Step","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"/e2e/tests/istio/setup_test.go:89","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"2022-08-30T11:35:05.673083419Z","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"&{Text:Setup worker clusters Duration:0s}","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"--","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"By Step","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"/e2e/tests/istio/setup_test.go:116","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"2022-08-30T11:36:17.027192529Z","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"&{Text:Setup Istio on worker clusters Duration:0s}","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"--","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"By Step","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"/e2e/tests/istio/setup_test.go:133","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"2022-08-30T11:36:49.747356743Z","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0},{"name":"&{Text:Wait for worker clusters Duration:0s}","time":{},"steps":[],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false,"stepsCount":0}],"attachments":[],"parameters":[],"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":true,"stepsCount":41},"afterStages":[],"labels":[{"name":"resultFormat","value":"junit"},{"name":"suite","value":"Istio Suite"},{"name":"testClass","value":"Istio Suite"},{"name":"package","value":"Istio Suite"}],"parameters":[],"links":[],"hidden":false,"retry":false,"extra":{"severity":"normal","retries":[],"categories":[],"history":{"statistic":{"failed":61,"broken":0,"skipped":0,"passed":40,"unknown":0,"total":101},"items":[{"uid":"a21aa87e260fe86e","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc000132048>: {\n        Underlying: <*exec.ExitError | 0xc00072e000>{\n            ProcessState: {\n                pid: 6868,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 2, Usec: 439565},\n                    Stime: {Sec: 0, Usec: 451152},\n                    Maxrss: 82828,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 15392,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 0,\n                    Oublock: 14168,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 23440,\n                    Nivcsw: 5719,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"install.go:178: [debug] Original chart version: \\\"\\\"\",\n                        \"install.go:195: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-worker-0.2.0.tgz\",\n                        \"\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:151: [debug] CRD serviceexports.networking.kubeslice.io is already present. Skipping.\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:151: [debug] CRD serviceimports.networking.kubeslice.io is already present. Skipping.\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:151: [debug] CRD slice.networking.kubeslice.io is already present. Skipping.\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:151: [debug] CRD slicegateways.networking.kubeslice.io is already present. Skipping.\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 44 resource(s)\",\n                        \"wait.go:48: [debug] beginning wait for 44 resources with timeout of 2m0s\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debu...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    install.go:178: [debug] Original chart version: \"\"\n    install.go:195: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-worker-0.2.0.tgz\n    \n    client.go:128: [debug] creating 1 resource(s)\n    install.go:151: [debug] CRD serviceexports.networking.kubeslice.io is already present. Skipping.\n    client.go:128: [debug] creating 1 resource(s)\n    install.go:151: [debug] CRD serviceimports.networking.kubeslice.io is already present. Skipping.\n    client.go:128: [debug] creating 1 resource(s)\n    install.go:151: [debug] CRD slice.networking.kubeslice.io is already present. Skipping.\n    client.go:128: [debug] creating 1 resource(s)\n    install.go:151: [debug] CRD slicegateways.networking.kubeslice.io is already present. Skipping.\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 44 resource(s)\n    wait.go:48: [debug] beginning wait for 44 resources with timeout of 2m0s\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    install.go:441: [debug] Install failed and atomic is set, uninstalling release\n    uninstall.go:95: [debug] uninstall: Deleting kubeslice-worker\n    client.go:310: [debug] Starting delete for \"kubeslice-webhook-service\" Service\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-svc\" Service\n    client.go:310: [debug] Starting delete for \"jaeger\" Service\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" Service\n    client.go:310: [debug] Starting delete for \"kubeslice-operator\" Deployment\n    client.go:310: [debug] Starting delete for \"jaeger\" Deployment\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook\" Deployment\n    client.go:310: [debug] Starting delete for \"prefix-service\" Deployment\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" Deployment\n    client.go:310: [debug] Starting delete for \"kubeslice-netop\" DaemonSet\n    client.go:310: [debug] Starting delete for \"nsm-kernel-forwarder\" DaemonSet\n    client.go:310: [debug] Starting delete for \"nsmgr\" DaemonSet\n    client.go:310: [debug] Starting delete for \"kubeslice-leader-election-rolebinding\" RoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-leader-election-role\" Role\n    client.go:310: [debug] Starting delete for \"kubeslice-proxy-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"nsm-role-binding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-dns-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-proxy-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"nsm-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"aggregate-network-services-view\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-dns-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-metrics-reader\" ClusterRole\n    client.go:310: [debug] Starting delete for \"networkservices.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"networkserviceendpoints.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"networkservicemanagers.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-config\" ConfigMap\n    client.go:310: [debug] Starting delete for \"nsm-config\" ConfigMap\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-certs\" Secret\n    client.go:310: [debug] Starting delete for \"kubeslice-admission-webhook-certs\" Secret\n    client.go:310: [debug] Starting delete for \"kubeslice-hub\" Secret\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-manager\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"forward-plane-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nse-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nsc-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nsmgr-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"vpn-gateway-server\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-netop\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"vpn-gateway-client\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"slice-router\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-mutating-webhook-configuration\" MutatingWebhookConfiguration\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-cfg\" MutatingWebhookConfiguration\n    uninstall.go:144: [debug] purge requested for kubeslice-worker\n    Error: INSTALLATION FAILED: release kubeslice-worker failed, and has been uninstalled due to atomic being set: timed out waiting for the condition\n    helm.go:84: [debug] timed out waiting for the condition\n    release kubeslice-worker failed, and has been uninstalled due to atomic being set\n    helm.sh/helm/v3/pkg/action.(*Install).failRelease\n    \thelm.sh/helm/v3/pkg/action/install.go:449\n    helm.sh/helm/v3/pkg/action.(*Install).reportToRun\n    \thelm.sh/helm/v3/pkg/action/install.go:433\n    helm.sh/helm/v3/pkg/action.(*Install).performInstall\n    \thelm.sh/helm/v3/pkg/action/install.go:389\n    runtime.goexit\n    \truntime/asm_amd64.s:1581\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:127\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:856\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:974\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:902\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:255\n    runtime.goexit\n    \truntime/asm_amd64.s:1581\noccurred","time":{"start":1661854067000,"stop":1661854284151,"duration":217151}},{"uid":"c15d9f5150a4ac99","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc0006aa018>: {\n        Underlying: <*exec.ExitError | 0xc0008b2000>{\n            ProcessState: {\n                pid: 6850,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 2, Usec: 751788},\n                    Stime: {Sec: 0, Usec: 473339},\n                    Maxrss: 83532,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 10107,\n                    Majflt: 7,\n                    Nswap: 0,\n                    Inblock: 504,\n                    Oublock: 14168,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 23785,\n                    Nivcsw: 6231,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"install.go:178: [debug] Original chart version: \\\"\\\"\",\n                        \"install.go:195: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-worker-0.2.0.tgz\",\n                        \"\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:151: [debug] CRD serviceexports.networking.kubeslice.io is already present. Skipping.\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:151: [debug] CRD serviceimports.networking.kubeslice.io is already present. Skipping.\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:151: [debug] CRD slice.networking.kubeslice.io is already present. Skipping.\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:151: [debug] CRD slicegateways.networking.kubeslice.io is already present. Skipping.\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 44 resource(s)\",\n                        \"wait.go:48: [debug] beginning wait for 44 resources with timeout of 2m0s\",\n                        \"ready.go:291: [debug] DaemonSet is not ready: kubeslice-system/kubeslice-netop. 0 out of 1 expected pods have been scheduled\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        ...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    install.go:178: [debug] Original chart version: \"\"\n    install.go:195: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-worker-0.2.0.tgz\n    \n    client.go:128: [debug] creating 1 resource(s)\n    install.go:151: [debug] CRD serviceexports.networking.kubeslice.io is already present. Skipping.\n    client.go:128: [debug] creating 1 resource(s)\n    install.go:151: [debug] CRD serviceimports.networking.kubeslice.io is already present. Skipping.\n    client.go:128: [debug] creating 1 resource(s)\n    install.go:151: [debug] CRD slice.networking.kubeslice.io is already present. Skipping.\n    client.go:128: [debug] creating 1 resource(s)\n    install.go:151: [debug] CRD slicegateways.networking.kubeslice.io is already present. Skipping.\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 44 resource(s)\n    wait.go:48: [debug] beginning wait for 44 resources with timeout of 2m0s\n    ready.go:291: [debug] DaemonSet is not ready: kubeslice-system/kubeslice-netop. 0 out of 1 expected pods have been scheduled\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    install.go:441: [debug] Install failed and atomic is set, uninstalling release\n    uninstall.go:95: [debug] uninstall: Deleting kubeslice-worker\n    client.go:310: [debug] Starting delete for \"kubeslice-webhook-service\" Service\n    client.go:310: [debug] Starting delete for \"jaeger\" Service\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" Service\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-svc\" Service\n    client.go:310: [debug] Starting delete for \"kubeslice-operator\" Deployment\n    client.go:310: [debug] Starting delete for \"prefix-service\" Deployment\n    client.go:310: [debug] Starting delete for \"jaeger\" Deployment\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" Deployment\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook\" Deployment\n    client.go:310: [debug] Starting delete for \"kubeslice-netop\" DaemonSet\n    client.go:310: [debug] Starting delete for \"nsm-kernel-forwarder\" DaemonSet\n    client.go:310: [debug] Starting delete for \"nsmgr\" DaemonSet\n    client.go:310: [debug] Starting delete for \"kubeslice-leader-election-rolebinding\" RoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-leader-election-role\" Role\n    client.go:310: [debug] Starting delete for \"kubeslice-proxy-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"nsm-role-binding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-dns-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-proxy-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"nsm-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-dns-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"aggregate-network-services-view\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-metrics-reader\" ClusterRole\n    client.go:310: [debug] Starting delete for \"networkserviceendpoints.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"networkservices.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"networkservicemanagers.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"nsm-config\" ConfigMap\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-config\" ConfigMap\n    client.go:310: [debug] Starting delete for \"kubeslice-admission-webhook-certs\" Secret\n    client.go:310: [debug] Starting delete for \"kubeslice-hub\" Secret\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-certs\" Secret\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-manager\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"forward-plane-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nse-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nsc-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-netop\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"vpn-gateway-server\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"vpn-gateway-client\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"slice-router\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nsmgr-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-mutating-webhook-configuration\" MutatingWebhookConfiguration\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-cfg\" MutatingWebhookConfiguration\n    uninstall.go:144: [debug] purge requested for kubeslice-worker\n    Error: INSTALLATION FAILED: release kubeslice-worker failed, and has been uninstalled due to atomic being set: timed out waiting for the condition\n    helm.go:84: [debug] timed out waiting for the condition\n    release kubeslice-worker failed, and has been uninstalled due to atomic being set\n    helm.sh/helm/v3/pkg/action.(*Install).failRelease\n    \thelm.sh/helm/v3/pkg/action/install.go:449\n    helm.sh/helm/v3/pkg/action.(*Install).reportToRun\n    \thelm.sh/helm/v3/pkg/action/install.go:433\n    helm.sh/helm/v3/pkg/action.(*Install).performInstall\n    \thelm.sh/helm/v3/pkg/action/install.go:389\n    runtime.goexit\n    \truntime/asm_amd64.s:1581\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:127\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:856\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:974\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:902\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:255\n    runtime.goexit\n    \truntime/asm_amd64.s:1581\noccurred","time":{"start":1661846606000,"stop":1661846828347,"duration":222347}},{"uid":"eda0e197d9ed627e","status":"passed","time":{"start":1661843950000,"stop":1661844169875,"duration":219875}},{"uid":"121f81e9e0d4086b","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc0003527c8>: {\n        Underlying: <*exec.ExitError | 0xc00014a540>{\n            ProcessState: {\n                pid: 12110,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 0, Usec: 192922},\n                    Stime: {Sec: 0, Usec: 92602},\n                    Maxrss: 84188,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 6131,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 0,\n                    Oublock: 13344,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 388,\n                    Nivcsw: 316,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"Error from server (MethodNotAllowed): error when creating \\\"/tmp/3912911542\\\": create not allowed while custom resource definition is terminating\",\n                    ],\n                },\n            },\n            stderr: {\n                Lines: [\n                    \"Error from server (MethodNotAllowed): error when creating \\\"/tmp/3912911542\\\": create not allowed while custom resource definition is terminating\",\n                ],\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"Error from server (MethodNotAllowed): error when creating \\\"/tmp/3912911542\\\": create not allowed while custom resource definition is terminating\",\n                    ],\n                },\n            },\n            merged: {\n                Mutex: {state: 0, sema: 0},\n                Lines: [\n                    \"Error from server (MethodNotAllowed): error when creating \\\"/tmp/3912911542\\\": create not allowed while custom resource definition is terminating\",\n                ],\n            },\n        },\n    }\n    error while running command: exit status 1; Error from server (MethodNotAllowed): error when creating \"/tmp/3912911542\": create not allowed while custom resource definition is terminating\noccurred","time":{"start":1661780555000,"stop":1661780637789,"duration":82789}},{"uid":"46da7833a7443a17","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc0001f0030>: {\n        Underlying: <*exec.ExitError | 0xc00014c000>{\n            ProcessState: {\n                pid: 6060,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 1, Usec: 572490},\n                    Stime: {Sec: 0, Usec: 292457},\n                    Maxrss: 88220,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 3745,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 0,\n                    Oublock: 12840,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 18598,\n                    Nivcsw: 5473,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"install.go:178: [debug] Original chart version: \\\"\\\"\",\n                        \"install.go:195: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-controller-0.2.0.tgz\",\n                        \"\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 26 resource(s)\",\n                        \"wait.go:48: [debug] beginning wait for 26 resources with timeout of 2m0s\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        ...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    install.go:178: [debug] Original chart version: \"\"\n    install.go:195: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-controller-0.2.0.tgz\n    \n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 26 resource(s)\n    wait.go:48: [debug] beginning wait for 26 resources with timeout of 2m0s\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    install.go:441: [debug] Install failed and atomic is set, uninstalling release\n    uninstall.go:95: [debug] uninstall: Deleting kubeslice-controller\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-webhook-service\" Service\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-controller-manager-metrics-service\" Service\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-manager\" Deployment\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-leader-election-rolebinding\" RoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-leader-election-role\" Role\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-proxy-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-controller-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-ovpn-controller-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-proxy-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-controller-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-metrics-reader\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-ovpn-editor-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"workerslicegateways.worker.kubeslice.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"clusters.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"projects.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"serviceexportconfigs.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"sliceconfigs.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"workerserviceimports.worker.kubeslice.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"workersliceconfigs.worker.kubeslice.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-manager-config\" ConfigMap\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-ovpn-manager\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-controller-manager\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-serving-cert\" Certificate\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-selfsigned-issuer\" Issuer\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-mutating-webhook-configuration\" MutatingWebhookConfiguration\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-validating-webhook-configuration\" ValidatingWebhookConfiguration\n    uninstall.go:144: [debug] purge requested for kubeslice-controller\n    Error: INSTALLATION FAILED: release kubeslice-controller failed, and has been uninstalled due to atomic being set: timed out waiting for the condition\n    helm.go:84: [debug] timed out waiting for the condition\n    release kubeslice-controller failed, and has been uninstalled due to atomic being set\n    helm.sh/helm/v3/pkg/action.(*Install).failRelease\n    \thelm.sh/helm/v3/pkg/action/install.go:449\n    helm.sh/helm/v3/pkg/action.(*Install).reportToRun\n    \thelm.sh/helm/v3/pkg/action/install.go:433\n    helm.sh/helm/v3/pkg/action.(*Install).performInstall\n    \thelm.sh/helm/v3/pkg/action/install.go:389\n    runtime.goexit\n    \truntime/asm_amd64.s:1581\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:127\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:856\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:974\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:902\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:255\n    runtime.goexit\n    \truntime/asm_amd64.s:1581\noccurred","time":{"start":1661778238000,"stop":1661778432666,"duration":194666}},{"uid":"49ea5ed850ccd09","status":"passed","time":{"start":1661754632000,"stop":1661754838046,"duration":206046}},{"uid":"990ec1ab7c60d59e","status":"passed","time":{"start":1661611699000,"stop":1661611926158,"duration":227158}},{"uid":"d9b1221cbd65492a","status":"passed","time":{"start":1661584843000,"stop":1661585044812,"duration":201812}},{"uid":"61f07229608313cb","status":"passed","time":{"start":1661579832000,"stop":1661580013765,"duration":181765}},{"uid":"94c2c9c0c903feb8","status":"passed","time":{"start":1661578270000,"stop":1661578471340,"duration":201340}},{"uid":"1cef9b30f58622dd","status":"passed","time":{"start":1661576179000,"stop":1661576360718,"duration":181718}},{"uid":"58b579614fe141e3","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc00000ee58>: {\n        Underlying: <*exec.ExitError | 0xc0003d02c0>{\n            ProcessState: {\n                pid: 6814,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 0, Usec: 63613},\n                    Stime: {Sec: 0, Usec: 8481},\n                    Maxrss: 44092,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 2063,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 0,\n                    Oublock: 96,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 445,\n                    Nivcsw: 261,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"install.go:178: [debug] Original chart version: \\\"\\\"\",\n                        \"install.go:195: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-worker-0.4.3.tgz\",\n                        \"\",\n                        \"Error: INSTALLATION FAILED: Kubernetes cluster unreachable: context \\\"kind-worker1\\\" does not exist\",\n                        \"helm.go:84: [debug] context \\\"kind-worker1\\\" does not exist\",\n                        \"Kubernetes cluster unreachable\",\n                        \"helm.sh/helm/v3/pkg/kube.(*Client).IsReachable\",\n                        \"\\thelm.sh/helm/v3/pkg/kube/client.go:118\",\n                        \"helm.sh/helm/v3/pkg/action.(*Install).RunWithContext\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:192\",\n                        \"main.runInstall\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:264\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:125\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.4.0/command.go:856\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.4.0/command.go:974\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.4.0/command.go:902\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:255\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1581\",\n                        \"INSTALLATION FAILED\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:127\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.4.0/command.go:856\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.4.0/command.go:974\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.4.0/command.go:902\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:255\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1581\",\n                    ],\n                },\n            },\n            stderr: {\n                Lines: [\n                    \"install.go:178: [debug] Original chart version: \\\"\\\"\",\n                    \"install.go:195: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-worker-0.4.3.tgz\",\n                    \"\",\n                    \"Error: INSTALLATION FAILED: Kubernetes cluster unreachable: context \\\"kind-worker1...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; install.go:178: [debug] Original chart version: \"\"\n    install.go:195: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-worker-0.4.3.tgz\n    \n    Error: INSTALLATION FAILED: Kubernetes cluster unreachable: context \"kind-worker1\" does not exist\n    helm.go:84: [debug] context \"kind-worker1\" does not exist\n    Kubernetes cluster unreachable\n    helm.sh/helm/v3/pkg/kube.(*Client).IsReachable\n    \thelm.sh/helm/v3/pkg/kube/client.go:118\n    helm.sh/helm/v3/pkg/action.(*Install).RunWithContext\n    \thelm.sh/helm/v3/pkg/action/install.go:192\n    main.runInstall\n    \thelm.sh/helm/v3/cmd/helm/install.go:264\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:125\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:856\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:974\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:902\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:255\n    runtime.goexit\n    \truntime/asm_amd64.s:1581\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:127\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:856\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:974\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:902\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:255\n    runtime.goexit\n    \truntime/asm_amd64.s:1581\noccurred","time":{"start":1661574251000,"stop":1661574351546,"duration":100546}},{"uid":"586a37d4f8f11b43","status":"passed","time":{"start":1661572237000,"stop":1661572444448,"duration":207448}},{"uid":"3eea109d8bbb4173","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc000350048>: {\n        Underlying: <*exec.ExitError | 0xc000074000>{\n            ProcessState: {\n                pid: 6832,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 2, Usec: 479977},\n                    Stime: {Sec: 0, Usec: 329887},\n                    Maxrss: 87456,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 9833,\n                    Majflt: 5,\n                    Nswap: 0,\n                    Inblock: 576,\n                    Oublock: 14168,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 22707,\n                    Nivcsw: 5610,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"install.go:178: [debug] Original chart version: \\\"\\\"\",\n                        \"install.go:195: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-worker-0.2.0.tgz\",\n                        \"\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:151: [debug] CRD serviceexports.networking.kubeslice.io is already present. Skipping.\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:151: [debug] CRD serviceimports.networking.kubeslice.io is already present. Skipping.\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:151: [debug] CRD slice.networking.kubeslice.io is already present. Skipping.\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"install.go:151: [debug] CRD slicegateways.networking.kubeslice.io is already present. Skipping.\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 44 resource(s)\",\n                        \"wait.go:48: [debug] beginning wait for 44 resources with timeout of 2m0s\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [deb...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    install.go:178: [debug] Original chart version: \"\"\n    install.go:195: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-worker-0.2.0.tgz\n    \n    client.go:128: [debug] creating 1 resource(s)\n    install.go:151: [debug] CRD serviceexports.networking.kubeslice.io is already present. Skipping.\n    client.go:128: [debug] creating 1 resource(s)\n    install.go:151: [debug] CRD serviceimports.networking.kubeslice.io is already present. Skipping.\n    client.go:128: [debug] creating 1 resource(s)\n    install.go:151: [debug] CRD slice.networking.kubeslice.io is already present. Skipping.\n    client.go:128: [debug] creating 1 resource(s)\n    install.go:151: [debug] CRD slicegateways.networking.kubeslice.io is already present. Skipping.\n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 44 resource(s)\n    wait.go:48: [debug] beginning wait for 44 resources with timeout of 2m0s\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/jaeger. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/nsm-admission-webhook. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-system/kubeslice-operator. 0 out of 1 expected pods are ready\n    install.go:441: [debug] Install failed and atomic is set, uninstalling release\n    uninstall.go:95: [debug] uninstall: Deleting kubeslice-worker\n    client.go:310: [debug] Starting delete for \"kubeslice-webhook-service\" Service\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" Service\n    client.go:310: [debug] Starting delete for \"jaeger\" Service\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-svc\" Service\n    client.go:310: [debug] Starting delete for \"kubeslice-operator\" Deployment\n    client.go:310: [debug] Starting delete for \"jaeger\" Deployment\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook\" Deployment\n    client.go:310: [debug] Starting delete for \"prefix-service\" Deployment\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" Deployment\n    client.go:310: [debug] Starting delete for \"kubeslice-netop\" DaemonSet\n    client.go:310: [debug] Starting delete for \"nsm-kernel-forwarder\" DaemonSet\n    client.go:310: [debug] Starting delete for \"nsmgr\" DaemonSet\n    client.go:310: [debug] Starting delete for \"kubeslice-leader-election-rolebinding\" RoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-leader-election-role\" Role\n    client.go:310: [debug] Starting delete for \"kubeslice-proxy-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"nsm-role-binding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-dns-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-proxy-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-dns-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"nsm-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"aggregate-network-services-view\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-metrics-reader\" ClusterRole\n    client.go:310: [debug] Starting delete for \"networkservices.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"networkserviceendpoints.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"networkservicemanagers.networkservicemesh.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"kubeslice-manager-config\" ConfigMap\n    client.go:310: [debug] Starting delete for \"nsm-config\" ConfigMap\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-certs\" Secret\n    client.go:310: [debug] Starting delete for \"kubeslice-hub\" Secret\n    client.go:310: [debug] Starting delete for \"kubeslice-admission-webhook-certs\" Secret\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-manager\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nse-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nsc-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"nsmgr-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-netop\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"forward-plane-acc\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-dns\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"vpn-gateway-server\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"slice-router\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"vpn-gateway-client\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-mutating-webhook-configuration\" MutatingWebhookConfiguration\n    client.go:310: [debug] Starting delete for \"nsm-admission-webhook-cfg\" MutatingWebhookConfiguration\n    uninstall.go:144: [debug] purge requested for kubeslice-worker\n    Error: INSTALLATION FAILED: release kubeslice-worker failed, and has been uninstalled due to atomic being set: timed out waiting for the condition\n    helm.go:84: [debug] timed out waiting for the condition\n    release kubeslice-worker failed, and has been uninstalled due to atomic being set\n    helm.sh/helm/v3/pkg/action.(*Install).failRelease\n    \thelm.sh/helm/v3/pkg/action/install.go:449\n    helm.sh/helm/v3/pkg/action.(*Install).reportToRun\n    \thelm.sh/helm/v3/pkg/action/install.go:433\n    helm.sh/helm/v3/pkg/action.(*Install).performInstall\n    \thelm.sh/helm/v3/pkg/action/install.go:389\n    runtime.goexit\n    \truntime/asm_amd64.s:1581\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:127\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:856\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:974\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:902\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:255\n    runtime.goexit\n    \truntime/asm_amd64.s:1581\noccurred","time":{"start":1661502221000,"stop":1661502449291,"duration":228291}},{"uid":"7aa59def20ffd097","status":"passed","time":{"start":1661435026000,"stop":1661435203827,"duration":177827}},{"uid":"36088bde5ef033c8","status":"passed","time":{"start":1661356858000,"stop":1661357060081,"duration":202081}},{"uid":"12defe42aa7989b3","status":"passed","time":{"start":1661353283000,"stop":1661353504059,"duration":221059}},{"uid":"b29b891cd6d73070","status":"passed","time":{"start":1661353041000,"stop":1661353228424,"duration":187424}},{"uid":"7c06a4e311c11a38","status":"passed","time":{"start":1661352859000,"stop":1661353053449,"duration":194449}},{"uid":"a3b26d4f2311d94a","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc00012e1c8>: {\n        Underlying: <*exec.ExitError | 0xc0003fe180>{\n            ProcessState: {\n                pid: 6087,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 1, Usec: 267401},\n                    Stime: {Sec: 0, Usec: 202611},\n                    Maxrss: 86004,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 5627,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 0,\n                    Oublock: 12840,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 15997,\n                    Nivcsw: 4062,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"install.go:178: [debug] Original chart version: \\\"\\\"\",\n                        \"install.go:195: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-controller-0.2.0.tgz\",\n                        \"\",\n                        \"client.go:128: [debug] creating 1 resource(s)\",\n                        \"client.go:128: [debug] creating 26 resource(s)\",\n                        \"wait.go:48: [debug] beginning wait for 26 resources with timeout of 2m0s\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        ...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    install.go:178: [debug] Original chart version: \"\"\n    install.go:195: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-controller-0.2.0.tgz\n    \n    client.go:128: [debug] creating 1 resource(s)\n    client.go:128: [debug] creating 26 resource(s)\n    wait.go:48: [debug] beginning wait for 26 resources with timeout of 2m0s\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    install.go:441: [debug] Install failed and atomic is set, uninstalling release\n    uninstall.go:95: [debug] uninstall: Deleting kubeslice-controller\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-webhook-service\" Service\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-controller-manager-metrics-service\" Service\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-manager\" Deployment\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-leader-election-rolebinding\" RoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-leader-election-role\" Role\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-proxy-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-controller-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-ovpn-controller-rolebinding\" ClusterRoleBinding\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-proxy-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-controller-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-metrics-reader\" ClusterRole\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-ovpn-editor-role\" ClusterRole\n    client.go:310: [debug] Starting delete for \"workerslicegateways.worker.kubeslice.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"clusters.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"projects.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"serviceexportconfigs.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"sliceconfigs.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"workerserviceimports.worker.kubeslice.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"workersliceconfigs.worker.kubeslice.io\" CustomResourceDefinition\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-manager-config\" ConfigMap\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-ovpn-manager\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-controller-manager\" ServiceAccount\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-serving-cert\" Certificate\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-selfsigned-issuer\" Issuer\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-mutating-webhook-configuration\" MutatingWebhookConfiguration\n    client.go:310: [debug] Starting delete for \"kubeslice-controller-validating-webhook-configuration\" ValidatingWebhookConfiguration\n    uninstall.go:144: [debug] purge requested for kubeslice-controller\n    Error: INSTALLATION FAILED: release kubeslice-controller failed, and has been uninstalled due to atomic being set: timed out waiting for the condition\n    helm.go:84: [debug] timed out waiting for the condition\n    release kubeslice-controller failed, and has been uninstalled due to atomic being set\n    helm.sh/helm/v3/pkg/action.(*Install).failRelease\n    \thelm.sh/helm/v3/pkg/action/install.go:449\n    helm.sh/helm/v3/pkg/action.(*Install).reportToRun\n    \thelm.sh/helm/v3/pkg/action/install.go:433\n    helm.sh/helm/v3/pkg/action.(*Install).performInstall\n    \thelm.sh/helm/v3/pkg/action/install.go:389\n    runtime.goexit\n    \truntime/asm_amd64.s:1581\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:127\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:856\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:974\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.4.0/command.go:902\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:255\n    runtime.goexit\n    \truntime/asm_amd64.s:1581\noccurred","time":{"start":1661354121000,"stop":1661354328649,"duration":207649}}]},"tags":[]},"source":"26dd1cbd56a38d8e.json","parameterValues":[]}