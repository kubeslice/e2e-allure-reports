{"uid":"16747607bcc068e1","name":"[AfterSuite]","historyId":"Worker Suite:Worker Suite#[AfterSuite]","time":{"start":1678886395000,"stop":1678886424994,"duration":29994},"status":"broken","statusMessage":"interrupted","statusTrace":"Interrupted by Timeout\n\nHere's a stack trace of all running goroutines:\n  goroutine 22 [running]:\n  github.com/onsi/ginkgo/v2/internal/interrupt_handler.(*InterruptHandler).InterruptMessageWithStackTraces(0xc000090230)\n  \t/e2e/vendor/github.com/onsi/ginkgo/v2/internal/interrupt_handler/interrupt_handler.go:203 +0x212\n  github.com/onsi/ginkgo/v2/internal.(*Suite).runNode(_, {0x5, 0x800, {0x0, 0x0}, 0x1912a08, {{0x1ebfd91, 0x22}, 0x13, {0x0, ...}, ...}, ...}, ...)\n  \t/e2e/vendor/github.com/onsi/ginkgo/v2/internal/suite.go:618 +0x8f6\n  github.com/onsi/ginkgo/v2/internal.(*Suite).runSuiteNode(0xc0002f6000, {0x5, 0x800, {0x0, 0x0}, 0x1912a08, {{0x1ebfd91, 0x22}, 0x13, {0x0, ...}, ...}, ...}, ...)\n  \t/e2e/vendor/github.com/onsi/ginkgo/v2/internal/suite.go:454 +0x867\n  github.com/onsi/ginkgo/v2/internal.(*Suite).runAfterSuiteCleanup(0xc0002f6000, 0xc0002fd980?)\n  \t/e2e/vendor/github.com/onsi/ginkgo/v2/internal/suite.go:371 +0x2e5\n  github.com/onsi/ginkgo/v2/internal.(*Suite).runSpecs(0xc0002f6000, {0x182eab8, 0xc}, {0x27a23d0, 0x0, 0x0}, {0xc000040840, 0x11}, 0x0, {0xc0002c8000, ...})\n  \t/e2e/vendor/github.com/onsi/ginkgo/v2/internal/suite.go:322 +0x465\n  github.com/onsi/ginkgo/v2/internal.(*Suite).Run(_, {_, _}, {_, _, _}, {_, _}, _, {0x1b422f8, ...}, ...)\n  \t/e2e/vendor/github.com/onsi/ginkgo/v2/internal/suite.go:86 +0x376\n  github.com/onsi/ginkgo/v2.RunSpecs({0x1b2f020, 0xc00053f380}, {0x182eab8, 0xc}, {0x0?, 0x0, 0xf?})\n  \t/e2e/vendor/github.com/onsi/ginkgo/v2/core_dsl.go:280 +0xa13\n  github.com/kubeslice/kubeslice-e2e-automation-ent/tests/worker_test.TestHub(0xc00053f380?)\n  \t/e2e/tests/worker/worker_suite_test.go:45 +0x1ad\n  testing.tRunner(0xc00053f380, 0x1912718)\n  \t/usr/local/go/src/testing/testing.go:1439 +0x102\n  created by testing.(*T).Run\n  \t/usr/local/go/src/testing/testing.go:1486 +0x35f\n\n  goroutine 1 [chan receive, 58 minutes]:\n  testing.(*T).Run(0xc00053eea0, {0x18257b9?, 0x5148a5?}, 0x1912718)\n  \t/usr/local/go/src/testing/testing.go:1487 +0x37a\n  testing.runTests.func1(0xc00053eea0?)\n  \t/usr/local/go/src/testing/testing.go:1839 +0x6e\n  testing.tRunner(0xc00053eea0, 0xc0000b9cd8)\n  \t/usr/local/go/src/testing/testing.go:1439 +0x102\n  testing.runTests(0xc0001e8960?, {0x2736620, 0x1, 0x1}, {0x7f976ea145b8?, 0x40?, 0x0?})\n  \t/usr/local/go/src/testing/testing.go:1837 +0x457\n  testing.(*M).Run(0xc0001e8960)\n  \t/usr/local/go/src/testing/testing.go:1719 +0x5d9\n  main.main()\n  \t_testmain.go:47 +0x1aa\n\n  goroutine 24 [syscall, 58 minutes]:\n  os/signal.signal_recv()\n  \t/usr/local/go/src/runtime/sigqueue.go:151 +0x2f\n  os/signal.loop()\n  \t/usr/local/go/src/os/signal/signal_unix.go:23 +0x19\n  created by os/signal.Notify.func1.1\n  \t/usr/local/go/src/os/signal/signal.go:151 +0x2a\n\n  goroutine 25 [select]:\n  github.com/onsi/ginkgo/v2/internal/interrupt_handler.(*InterruptHandler).registerForInterrupts.func2()\n  \t/e2e/vendor/github.com/onsi/ginkgo/v2/internal/interrupt_handler/interrupt_handler.go:127 +0x11c\n  created by github.com/onsi/ginkgo/v2/internal/interrupt_handler.(*InterruptHandler).registerForInterrupts\n  \t/e2e/vendor/github.com/onsi/ginkgo/v2/internal/interrupt_handler/interrupt_handler.go:122 +0x1ea\n\n  goroutine 88 [sleep]:\n  time.Sleep(0x3b9aca00)\n  \t/usr/local/go/src/runtime/time.go:194 +0x12e\n  github.com/kubeslice/kubeslice-e2e-automation-ent/pkg/utils.Retry(0xc0005c9f68, 0xdf8475800, 0x3b9aca00)\n  \t/e2e/pkg/utils/retry.go:14 +0x45\n  github.com/kubeslice/kubeslice-e2e-automation-ent/tests/worker_test.glob..func2.1.2()\n  \t/e2e/tests/worker/t_node_affinity_test.go:42 +0x48b\n  github.com/onsi/ginkgo/v2/internal.(*Suite).runNode.func2()\n  \t/e2e/vendor/github.com/onsi/ginkgo/v2/internal/suite.go:605 +0x8d\n  created by github.com/onsi/ginkgo/v2/internal.(*Suite).runNode\n  \t/e2e/vendor/github.com/onsi/ginkgo/v2/internal/suite.go:593 +0x60c\n\n  goroutine 5986 [IO wait]:\n  internal/poll.runtime_pollWait(0x7f9744be8eb0, 0x72)\n  \t/usr/local/go/src/runtime/netpoll.go:302 +0x89\n  internal/poll.(*pollDesc).wait(0xc00095a840?, 0xc0000c2000?, 0x1)\n  \t/usr/local/go/src/internal/poll/fd_poll_runtime.go:83 +0x32\n  internal/poll.(*pollDesc).waitRead(...)\n  \t/usr/local/go/src/internal/poll/fd_poll_runtime.go:88\n  internal/poll.(*FD).Read(0xc00095a840, {0xc0000c2000, 0x1000, 0x1000})\n  \t/usr/local/go/src/internal/poll/fd_unix.go:167 +0x25a\n  os.(*File).read(...)\n  \t/usr/local/go/src/os/file_posix.go:31\n  os.(*File).Read(0xc00011ab28, {0xc0000c2000?, 0x203000?, 0xc0002c8800?})\n  \t/usr/local/go/src/os/file.go:119 +0x5e\n  bufio.(*Reader).fill(0xc00095aa20)\n  \t/usr/local/go/src/bufio/bufio.go:106 +0x103\n  bufio.(*Reader).ReadSlice(0xc00095aa20, 0xa5?)\n  \t/usr/local/go/src/bufio/bufio.go:371 +0x2f\n  bufio.(*Reader).collectFragments(0x1249ef4?, 0x0?)\n  \t/usr/local/go/src/bufio/bufio.go:446 +0x74\n  bufio.(*Reader).ReadString(0xc0000461e0?, 0xa0?)\n  \t/usr/local/go/src/bufio/bufio.go:494 +0x2b\n  github.com/gruntwork-io/terratest/modules/shell.readData({0x7f9744ae0470, 0xc00007c180}, 0xa2d99e?, 0xc0008c0d80?, {0x1b2d780, 0xc000478a60})\n  \t/e2e/vendor/github.com/gruntwork-io/terratest/modules/shell/command.go:165 +0x65\n  github.com/gruntwork-io/terratest/modules/shell.readStdoutAndStderr.func2()\n  \t/e2e/vendor/github.com/gruntwork-io/terratest/modules/shell/command.go:147 +0x85\n  created by github.com/gruntwork-io/terratest/modules/shell.readStdoutAndStderr\n  \t/e2e/vendor/github.com/gruntwork-io/terratest/modules/shell/command.go:145 +0x5ea\n\n  goroutine 5953 [IO wait]:\n  internal/poll.runtime_pollWait(0x7f9744be8be0, 0x72)\n  \t/usr/local/go/src/runtime/netpoll.go:302 +0x89\n  internal/poll.(*pollDesc).wait(0xc00095a780?, 0xc0000bc000?, 0x1)\n  \t/usr/local/go/src/internal/poll/fd_poll_runtime.go:83 +0x32\n  internal/poll.(*pollDesc).waitRead(...)\n  \t/usr/local/go/src/internal/poll/fd_poll_runtime.go:88\n  internal/poll.(*FD).Read(0xc00095a780, {0xc0000bc000, 0x1000, 0x1000})\n  \t/usr/local/go/src/internal/poll/fd_unix.go:167 +0x25a\n  os.(*File).read(...)\n  \t/usr/local/go/src/os/file_posix.go:31\n  os.(*File).Read(0xc00011ab00, {0xc0000bc000?, 0x0?, 0x0?})\n  \t/usr/local/go/src/os/file.go:119 +0x5e\n  bufio.(*Reader).fill(0xc00095a9c0)\n  \t/usr/local/go/src/bufio/bufio.go:106 +0x103\n  bufio.(*Reader).ReadSlice(0xc00095a9c0, 0x0?)\n  \t/usr/local/go/src/bufio/bufio.go:371 +0x2f\n  bufio.(*Reader).collectFragments(0x0?, 0x0?)\n  \t/usr/local/go/src/bufio/bufio.go:446 +0x74\n  bufio.(*Reader).ReadString(0x0?, 0x0?)\n  \t/usr/local/go/src/bufio/bufio.go:494 +0x2b\n  github.com/gruntwork-io/terratest/modules/shell.readData({0x7f9744ae0470, 0xc00007c180}, 0x0?, 0x0?, {0x1b2d780, 0xc000478a40})\n  \t/e2e/vendor/github.com/gruntwork-io/terratest/modules/shell/command.go:165 +0x65\n  github.com/gruntwork-io/terratest/modules/shell.readStdoutAndStderr.func1()\n  \t/e2e/vendor/github.com/gruntwork-io/terratest/modules/shell/command.go:143 +0x7f\n  created by github.com/gruntwork-io/terratest/modules/shell.readStdoutAndStderr\n  \t/e2e/vendor/github.com/gruntwork-io/terratest/modules/shell/command.go:141 +0x518\n\n  goroutine 5966 [semacquire]:\n  sync.runtime_Semacquire(0xc00007c300?)\n  \t/usr/local/go/src/runtime/sema.go:56 +0x25\n  sync.(*WaitGroup).Wait(0x20?)\n  \t/usr/local/go/src/sync/waitgroup.go:136 +0x52\n  github.com/gruntwork-io/terratest/modules/shell.readStdoutAndStderr({0x7f9744ae0470?, 0xc00007c180}, 0xc0000461e0, {0x1b35770?, 0xc00011ab00}, {0x1b35770?, 0xc00011ab28})\n  \t/e2e/vendor/github.com/gruntwork-io/terratest/modules/shell/command.go:149 +0x5f4\n  github.com/gruntwork-io/terratest/modules/shell.runCommand({0x7f9744ae0470, 0xc00007c180}, {{0x18209bf, 0x4}, {0xc000186540, 0xa, 0xc}, {0x181f8b0, 0x1}, 0x0, ...})\n  \t/e2e/vendor/github.com/gruntwork-io/terratest/modules/shell/command.go:122 +0x27b\n  github.com/gruntwork-io/terratest/modules/shell.RunCommandAndGetOutputE({0x7f9744ae0470?, 0xc00007c180?}, {{0x18209bf, 0x4}, {0xc000186540, 0xa, 0xc}, {0x181f8b0, 0x1}, 0x0, ...})\n  \t/e2e/vendor/github.com/gruntwork-io/terratest/modules/shell/command.go:58 +0x7b\n  github.com/gruntwork-io/terratest/modules/helm.RunHelmCommandAndGetOutputE({0x7f9744ae0470, 0xc00007c180}, 0x15a8c40?, {0x182a88f?, 0x0?}, {0xc000603c58?, 0x14213e0?, 0xc000603bf8?})\n  \t/e2e/vendor/github.com/gruntwork-io/terratest/modules/helm/cmd.go:56 +0xd0\n  github.com/kubeslice/kubeslice-e2e-automation-ent/pkg/chart.Uninstall({0x7f9744ae0470?, 0xc00007c180?}, 0x27a23d0?, 0x0?)\n  \t/e2e/pkg/chart/chart.go:120 +0x114\n  github.com/kubeslice/kubeslice-e2e-automation-ent/tests/worker_test.glob..func5()\n  \t/e2e/tests/worker/teardown_test.go:43 +0xdcc\n  github.com/onsi/ginkgo/v2/internal.(*Suite).runNode.func2()\n  \t/e2e/vendor/github.com/onsi/ginkgo/v2/internal/suite.go:605 +0x8d\n  created by github.com/onsi/ginkgo/v2/internal.(*Suite).runNode\n  \t/e2e/vendor/github.com/onsi/ginkgo/v2/internal/suite.go:593 +0x60c\n\n  goroutine 5972 [IO wait]:\n  internal/poll.runtime_pollWait(0x7f9744be8dc0, 0x72)\n  \t/usr/local/go/src/runtime/netpoll.go:302 +0x89\n  internal/poll.(*pollDesc).wait(0xc0007f1800?, 0xc000514000?, 0x0)\n  \t/usr/local/go/src/internal/poll/fd_poll_runtime.go:83 +0x32\n  internal/poll.(*pollDesc).waitRead(...)\n  \t/usr/local/go/src/internal/poll/fd_poll_runtime.go:88\n  internal/poll.(*FD).Read(0xc0007f1800, {0xc000514000, 0x5871, 0x5871})\n  \t/usr/local/go/src/internal/poll/fd_unix.go:167 +0x25a\n  net.(*netFD).Read(0xc0007f1800, {0xc000514000?, 0xc00042da60?, 0xc000514047?})\n  \t/usr/local/go/src/net/fd_posix.go:55 +0x29\n  net.(*conn).Read(0xc00011a430, {0xc000514000?, 0x0?, 0x42da60?})\n  \t/usr/local/go/src/net/net.go:183 +0x45\n  crypto/tls.(*atLeastReader).Read(0xc000316060, {0xc000514000?, 0x0?, 0x0?})\n  \t/usr/local/go/src/crypto/tls/conn.go:785 +0x3d\n  bytes.(*Buffer).ReadFrom(0xc0003f05f8, {0x1b293e0, 0xc000316060})\n  \t/usr/local/go/src/bytes/buffer.go:204 +0x98\n  crypto/tls.(*Conn).readFromUntil(0xc0003f0380, {0x1b2eac0?, 0xc00011a430}, 0x582f?)\n  \t/usr/local/go/src/crypto/tls/conn.go:807 +0xe5\n  crypto/tls.(*Conn).readRecordOrCCS(0xc0003f0380, 0x0)\n  \t/usr/local/go/src/crypto/tls/conn.go:614 +0x116\n  crypto/tls.(*Conn).readRecord(...)\n  \t/usr/local/go/src/crypto/tls/conn.go:582\n  crypto/tls.(*Conn).Read(0xc0003f0380, {0xc0004b7000, 0x1000, 0xa27ae0?})\n  \t/usr/local/go/src/crypto/tls/conn.go:1285 +0x16f\n  bufio.(*Reader).Read(0xc00095a120, {0xc0001ea4a0, 0x9, 0xa35ec2?})\n  \t/usr/local/go/src/bufio/bufio.go:236 +0x1b4\n  io.ReadAtLeast({0x1b291e0, 0xc00095a120}, {0xc0001ea4a0, 0x9, 0x9}, 0x9)\n  \t/usr/local/go/src/io/io.go:331 +0x9a\n  io.ReadFull(...)\n  \t/usr/local/go/src/io/io.go:350\n  golang.org/x/net/http2.readFrameHeader({0xc0001ea4a0?, 0x9?, 0xc0017fe0f0?}, {0x1b291e0?, 0xc00095a120?})\n  \t/e2e/vendor/golang.org/x/net/http2/frame.go:237 +0x6e\n  golang.org/x/net/http2.(*Framer).ReadFrame(0xc0001ea460)\n  \t/e2e/vendor/golang.org/x/net/http2/frame.go:498 +0x95\n  golang.org/x/net/http2.(*clientConnReadLoop).run(0xc000068f98)\n  \t/e2e/vendor/golang.org/x/net/http2/transport.go:2123 +0x130\n  golang.org/x/net/http2.(*ClientConn).readLoop(0xc0008c0780)\n  \t/e2e/vendor/golang.org/x/net/http2/transport.go:2019 +0x6f\n  created by golang.org/x/net/http2.(*Transport).newClientConn\n  \t/e2e/vendor/golang.org/x/net/http2/transport.go:726 +0xa65\n","flaky":true,"newFailed":false,"newBroken":true,"newPassed":false,"retriesCount":0,"retriesStatusChange":false,"beforeStages":[],"testStage":{"steps":[{"name":"","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"Report Entries:","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"By Step","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"/e2e/tests/worker/teardown_test.go:29","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"2023-03-15T14:17:45.663300293Z","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false},{"name":"&{Text:Uninstalling worker clusters Duration:0s}","time":{},"steps":[],"attachments":[],"parameters":[],"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":false}],"attachments":[],"parameters":[],"stepsCount":6,"attachmentsCount":0,"shouldDisplayMessage":false,"hasContent":true},"afterStages":[],"labels":[{"name":"resultFormat","value":"junit"},{"name":"suite","value":"Worker Suite"},{"name":"testClass","value":"Worker Suite"},{"name":"package","value":"Worker Suite"}],"parameters":[],"links":[],"hidden":false,"retry":false,"extra":{"severity":"normal","retries":[],"categories":[{"name":"Test defects","matchedStatuses":[],"flaky":false}],"history":{"statistic":{"failed":19,"broken":3,"skipped":0,"passed":48,"unknown":0,"total":70},"items":[{"uid":"ecec20760b0732e8","status":"passed","time":{"start":1678882050000,"stop":1678882075939,"duration":25939}},{"uid":"e7655bdc411071d9","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc000756018>: {\n        Underlying: <*exec.ExitError | 0xc0006b4000>{\n            ProcessState: {\n                pid: 7086,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 5, Usec: 177295},\n                    Stime: {Sec: 1, Usec: 721373},\n                    Maxrss: 105952,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 7683,\n                    Majflt: 460,\n                    Nswap: 0,\n                    Inblock: 76928,\n                    Oublock: 22416,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 150641,\n                    Nivcsw: 41499,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"uninstall.go:95: [debug] uninstall: Deleting kubeslice-worker\",\n                        \"client.go:477: [debug] Starting delete for \\\"nsm-delete-webhooks\\\" ClusterRole\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"nsm-delete-webhooks\\\" rbac.authorization.k8s.io/v1, Kind=ClusterRole: clusterroles.rbac.authorization.k8s.io \\\"nsm-delete-webhooks\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"nsm-delete-webhooks\\\" ClusterRoleBinding\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"nsm-delete-webhooks\\\" rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding: clusterrolebindings.rbac.authorization.k8s.io \\\"nsm-delete-webhooks\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"kubeslice-cleanup\\\" ServiceAccount\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"kubeslice-cleanup\\\" /v1, Kind=ServiceAccount: serviceaccounts \\\"kubeslice-cleanup\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"kubeslice-cleanup\\\" ClusterRole\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"kubeslice-cleanup\\\" rbac.authorization.k8s.io/v1, Kind=ClusterRole: clusterroles.rbac.authorization.k8s.io \\\"kubeslice-cleanup\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"kubeslice-cleanup\\\" ClusterRoleBinding\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"kubeslice-cleanup\\\" rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding: clusterrolebindings.rbac.authorization.k8s.io \\\"kubeslice-cleanup\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"nsm-delete-webhooks\\\" ServiceAccount\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"nsm-delete-webhooks\\\" /v1, Kind=ServiceAccount: serviceaccounts \\\"nsm-delete-webhooks\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"nsm-delete-webhooks\\\" ConfigMap\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"nsm-delete-webhooks\\\" /v1, Kind=ConfigMap: configmaps \\\"nsm-delete-webhooks\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"kubeslice-cleanup\\\" Job\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"kubeslice-cleanup\\\" batch/v1, Kind=Job: jobs.batch \\\"kubeslice-cleanup\\...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; uninstall.go:95: [debug] uninstall: Deleting kubeslice-worker\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ClusterRole\n    client.go:481: [debug] Ignoring delete failure for \"nsm-delete-webhooks\" rbac.authorization.k8s.io/v1, Kind=ClusterRole: clusterroles.rbac.authorization.k8s.io \"nsm-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ClusterRoleBinding\n    client.go:481: [debug] Ignoring delete failure for \"nsm-delete-webhooks\" rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding: clusterrolebindings.rbac.authorization.k8s.io \"nsm-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ServiceAccount\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-cleanup\" /v1, Kind=ServiceAccount: serviceaccounts \"kubeslice-cleanup\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ClusterRole\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-cleanup\" rbac.authorization.k8s.io/v1, Kind=ClusterRole: clusterroles.rbac.authorization.k8s.io \"kubeslice-cleanup\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ClusterRoleBinding\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-cleanup\" rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding: clusterrolebindings.rbac.authorization.k8s.io \"kubeslice-cleanup\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ServiceAccount\n    client.go:481: [debug] Ignoring delete failure for \"nsm-delete-webhooks\" /v1, Kind=ServiceAccount: serviceaccounts \"nsm-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ConfigMap\n    client.go:481: [debug] Ignoring delete failure for \"nsm-delete-webhooks\" /v1, Kind=ConfigMap: configmaps \"nsm-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" Job\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-cleanup\" batch/v1, Kind=Job: jobs.batch \"kubeslice-cleanup\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:703: [debug] Watching for changes to Job kubeslice-cleanup with timeout of 5m0s\n    client.go:731: [debug] Add/Modify event for kubeslice-cleanup: ADDED\n    client.go:770: [debug] kubeslice-cleanup: Jobs active: 0, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for kubeslice-cleanup: MODIFIED\n    client.go:770: [debug] kubeslice-cleanup: Jobs active: 1, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for kubeslice-cleanup: MODIFIED\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" Job\n    client.go:481: [debug] Ignoring delete failure for \"nsm-delete-webhooks\" batch/v1, Kind=Job: jobs.batch \"nsm-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:703: [debug] Watching for changes to Job nsm-delete-webhooks with timeout of 5m0s\n    client.go:731: [debug] Add/Modify event for nsm-delete-webhooks: ADDED\n    client.go:770: [debug] nsm-delete-webhooks: Jobs active: 0, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for nsm-delete-webhooks: MODIFIED\n    client.go:770: [debug] nsm-delete-webhooks: Jobs active: 1, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for nsm-delete-webhooks: MODIFIED\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ClusterRole\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ConfigMap\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" Job\n    client.go:477: [debug] Starting delete for \"kubeslice-webhook-service\" Service\n    client.go:477: [debug] Starting delete for \"admission-webhook-svc\" Service\n    client.go:477: [debug] Starting delete for \"k8s-workload-registrar\" Service\n    client.go:477: [debug] Starting delete for \"spire-server\" Service\n    client.go:477: [debug] Starting delete for \"registry\" Service\n    client.go:477: [debug] Starting delete for \"kubeslice-dns\" Service\n    client.go:477: [debug] Starting delete for \"spire-server\" StatefulSet\n    client.go:477: [debug] Starting delete for \"kubeslice-operator\" Deployment\n    client.go:477: [debug] Starting delete for \"nsm-admission-webhook-k8s\" Deployment\n    client.go:477: [debug] Starting delete for \"registry-k8s\" Deployment\n    client.go:477: [debug] Starting delete for \"kubeslice-dns\" Deployment\n    client.go:477: [debug] Starting delete for \"kubeslice-netop\" DaemonSet\n    client.go:477: [debug] Starting delete for \"spire-agent\" DaemonSet\n    client.go:477: [debug] Starting delete for \"forwarder-kernel\" DaemonSet\n    client.go:477: [debug] Starting delete for \"nsmgr\" DaemonSet\n    client.go:477: [debug] Starting delete for \"kubeslice-leader-election-rolebinding\" RoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-leader-election-role\" Role\n    client.go:477: [debug] Starting delete for \"kubeslice-proxy-rolebinding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"admission-webhook-binding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"nsm-role-binding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"spire-agent-cluster-role-binding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"k8s-workload-registrar-role-binding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"spire-server-trust-role-binding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-dns-rolebinding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-manager-rolebinding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-proxy-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-metrics-reader\" ClusterRole\n    client.go:477: [debug] Starting delete for \"admission-webhook-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"spire-server-trust-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"nsm-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"aggregate-network-services-view\" ClusterRole\n    client.go:477: [debug] Starting delete for \"spire-agent-cluster-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"k8s-workload-registrar-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-dns-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-manager-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-manager-config\" ConfigMap\n    client.go:477: [debug] Starting delete for \"spire-agent\" ConfigMap\n    client.go:477: [debug] Starting delete for \"k8s-workload-registrar\" ConfigMap\n    client.go:477: [debug] Starting delete for \"spire-bundle\" ConfigMap\n    client.go:477: [debug] Starting delete for \"spire-server\" ConfigMap\n    client.go:477: [debug] Starting delete for \"kubeslice-admission-webhook-certs\" Secret\n    client.go:477: [debug] Starting delete for \"kubeslice-kubernetes-dashboard-creds\" Secret\n    client.go:477: [debug] Starting delete for \"kubeslice-hub\" Secret\n    client.go:477: [debug] Starting delete for \"kubeslice-image-pull-secret\" Secret\n    client.go:477: [debug] Starting delete for \"kubeslice-dns\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"kubeslice-controller-manager\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"admission-webhook-sa\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"kubeslice-netop\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"vpn-gateway-server\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"vpn-gateway-client\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"slice-router\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"forward-plane-acc\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"nse-acc\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"nsc-acc\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"nsmgr-acc\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"spire-server\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"spire-agent\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"spire\" Namespace\n    client.go:477: [debug] Starting delete for \"kubeslice-mutating-webhook-configuration\" MutatingWebhookConfiguration\n    client.go:477: [debug] Starting delete for \"nsm-webhook-high-priority\" PriorityClass\n    client.go:477: [debug] Starting delete for \"k8s-workload-registrar\" ValidatingWebhookConfiguration\n    wait.go:66: [debug] beginning wait for 64 resources to be deleted with timeout of 5m0s\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ClusterRole\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-postdelete-job\" rbac.authorization.k8s.io/v1, Kind=ClusterRole: clusterroles.rbac.authorization.k8s.io \"kubeslice-postdelete-job\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ClusterRoleBinding\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-postdelete-job\" rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding: clusterrolebindings.rbac.authorization.k8s.io \"kubeslice-postdelete-job\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ServiceAccount\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-postdelete-job\" /v1, Kind=ServiceAccount: serviceaccounts \"kubeslice-postdelete-job\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ConfigMap\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-postdelete-job\" /v1, Kind=ConfigMap: configmaps \"kubeslice-postdelete-job\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" Job\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-postdelete-job\" batch/v1, Kind=Job: jobs.batch \"kubeslice-postdelete-job\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:703: [debug] Watching for changes to Job kubeslice-postdelete-job with timeout of 5m0s\n    client.go:731: [debug] Add/Modify event for kubeslice-postdelete-job: ADDED\n    client.go:770: [debug] kubeslice-postdelete-job: Jobs active: 0, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for kubeslice-postdelete-job: MODIFIED\n    client.go:770: [debug] kubeslice-postdelete-job: Jobs active: 1, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for kubeslice-postdelete-job: MODIFIED\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ConfigMap\n    uninstall.go:148: [debug] purge requested for kubeslice-worker\n    Error: uninstallation completed with 1 error(s): timed out waiting for the condition\n    helm.go:84: [debug] uninstallation completed with 1 error(s): timed out waiting for the condition\n    helm.sh/helm/v3/pkg/action.(*Uninstall).Run\n    \thelm.sh/helm/v3/pkg/action/uninstall.go:156\n    main.newUninstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/uninstall.go:56\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:916\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:1044\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:968\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\noccurred","time":{"start":1678865098000,"stop":1678865420890,"duration":322890}},{"uid":"7f1c4386dc602349","status":"failed","statusDetails":"Timed out after 500.016s.\nExpected\n    <bool>: false\nto be true","time":{"start":1678776779000,"stop":1678777283533,"duration":504533}},{"uid":"2e3b1329004e6450","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc000882018>: {\n        Underlying: <*exec.ExitError | 0xc000078000>{\n            ProcessState: {\n                pid: 7090,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 5, Usec: 25744},\n                    Stime: {Sec: 1, Usec: 969548},\n                    Maxrss: 113500,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 8659,\n                    Majflt: 451,\n                    Nswap: 0,\n                    Inblock: 75128,\n                    Oublock: 22416,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 147614,\n                    Nivcsw: 38944,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"uninstall.go:95: [debug] uninstall: Deleting kubeslice-worker\",\n                        \"client.go:477: [debug] Starting delete for \\\"nsm-delete-webhooks\\\" ClusterRole\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"nsm-delete-webhooks\\\" rbac.authorization.k8s.io/v1, Kind=ClusterRole: clusterroles.rbac.authorization.k8s.io \\\"nsm-delete-webhooks\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"nsm-delete-webhooks\\\" ClusterRoleBinding\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"nsm-delete-webhooks\\\" rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding: clusterrolebindings.rbac.authorization.k8s.io \\\"nsm-delete-webhooks\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"kubeslice-cleanup\\\" ServiceAccount\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"kubeslice-cleanup\\\" /v1, Kind=ServiceAccount: serviceaccounts \\\"kubeslice-cleanup\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"kubeslice-cleanup\\\" ClusterRole\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"kubeslice-cleanup\\\" rbac.authorization.k8s.io/v1, Kind=ClusterRole: clusterroles.rbac.authorization.k8s.io \\\"kubeslice-cleanup\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"kubeslice-cleanup\\\" ClusterRoleBinding\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"kubeslice-cleanup\\\" rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding: clusterrolebindings.rbac.authorization.k8s.io \\\"kubeslice-cleanup\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"nsm-delete-webhooks\\\" ServiceAccount\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"nsm-delete-webhooks\\\" /v1, Kind=ServiceAccount: serviceaccounts \\\"nsm-delete-webhooks\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"nsm-delete-webhooks\\\" ConfigMap\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"nsm-delete-webhooks\\\" /v1, Kind=ConfigMap: configmaps \\\"nsm-delete-webhooks\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"kubeslice-cleanup\\\" Job\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"kubeslice-cleanup\\\" batch/v1, Kind=Job: jobs.batch \\\"kubeslice-cleanup\\\"...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; uninstall.go:95: [debug] uninstall: Deleting kubeslice-worker\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ClusterRole\n    client.go:481: [debug] Ignoring delete failure for \"nsm-delete-webhooks\" rbac.authorization.k8s.io/v1, Kind=ClusterRole: clusterroles.rbac.authorization.k8s.io \"nsm-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ClusterRoleBinding\n    client.go:481: [debug] Ignoring delete failure for \"nsm-delete-webhooks\" rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding: clusterrolebindings.rbac.authorization.k8s.io \"nsm-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ServiceAccount\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-cleanup\" /v1, Kind=ServiceAccount: serviceaccounts \"kubeslice-cleanup\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ClusterRole\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-cleanup\" rbac.authorization.k8s.io/v1, Kind=ClusterRole: clusterroles.rbac.authorization.k8s.io \"kubeslice-cleanup\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ClusterRoleBinding\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-cleanup\" rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding: clusterrolebindings.rbac.authorization.k8s.io \"kubeslice-cleanup\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ServiceAccount\n    client.go:481: [debug] Ignoring delete failure for \"nsm-delete-webhooks\" /v1, Kind=ServiceAccount: serviceaccounts \"nsm-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ConfigMap\n    client.go:481: [debug] Ignoring delete failure for \"nsm-delete-webhooks\" /v1, Kind=ConfigMap: configmaps \"nsm-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" Job\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-cleanup\" batch/v1, Kind=Job: jobs.batch \"kubeslice-cleanup\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:703: [debug] Watching for changes to Job kubeslice-cleanup with timeout of 5m0s\n    client.go:731: [debug] Add/Modify event for kubeslice-cleanup: ADDED\n    client.go:770: [debug] kubeslice-cleanup: Jobs active: 0, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for kubeslice-cleanup: MODIFIED\n    client.go:770: [debug] kubeslice-cleanup: Jobs active: 1, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for kubeslice-cleanup: MODIFIED\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" Job\n    client.go:481: [debug] Ignoring delete failure for \"nsm-delete-webhooks\" batch/v1, Kind=Job: jobs.batch \"nsm-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:703: [debug] Watching for changes to Job nsm-delete-webhooks with timeout of 5m0s\n    client.go:731: [debug] Add/Modify event for nsm-delete-webhooks: ADDED\n    client.go:770: [debug] nsm-delete-webhooks: Jobs active: 0, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for nsm-delete-webhooks: MODIFIED\n    client.go:770: [debug] nsm-delete-webhooks: Jobs active: 1, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for nsm-delete-webhooks: MODIFIED\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ClusterRole\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ConfigMap\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" Job\n    client.go:477: [debug] Starting delete for \"admission-webhook-svc\" Service\n    client.go:477: [debug] Starting delete for \"kubeslice-webhook-service\" Service\n    client.go:477: [debug] Starting delete for \"k8s-workload-registrar\" Service\n    client.go:477: [debug] Starting delete for \"spire-server\" Service\n    client.go:477: [debug] Starting delete for \"registry\" Service\n    client.go:477: [debug] Starting delete for \"kubeslice-dns\" Service\n    client.go:477: [debug] Starting delete for \"spire-server\" StatefulSet\n    client.go:477: [debug] Starting delete for \"kubeslice-operator\" Deployment\n    client.go:477: [debug] Starting delete for \"nsm-admission-webhook-k8s\" Deployment\n    client.go:477: [debug] Starting delete for \"registry-k8s\" Deployment\n    client.go:477: [debug] Starting delete for \"kubeslice-dns\" Deployment\n    client.go:477: [debug] Starting delete for \"kubeslice-netop\" DaemonSet\n    client.go:477: [debug] Starting delete for \"spire-agent\" DaemonSet\n    client.go:477: [debug] Starting delete for \"forwarder-kernel\" DaemonSet\n    client.go:477: [debug] Starting delete for \"nsmgr\" DaemonSet\n    client.go:477: [debug] Starting delete for \"kubeslice-leader-election-rolebinding\" RoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-leader-election-role\" Role\n    client.go:477: [debug] Starting delete for \"kubeslice-proxy-rolebinding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"admission-webhook-binding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"nsm-role-binding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"spire-agent-cluster-role-binding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"k8s-workload-registrar-role-binding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"spire-server-trust-role-binding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-dns-rolebinding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-manager-rolebinding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-proxy-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"admission-webhook-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"nsm-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"aggregate-network-services-view\" ClusterRole\n    client.go:477: [debug] Starting delete for \"spire-agent-cluster-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"k8s-workload-registrar-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"spire-server-trust-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-dns-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-manager-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-metrics-reader\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-manager-config\" ConfigMap\n    client.go:477: [debug] Starting delete for \"spire-agent\" ConfigMap\n    client.go:477: [debug] Starting delete for \"k8s-workload-registrar\" ConfigMap\n    client.go:477: [debug] Starting delete for \"spire-bundle\" ConfigMap\n    client.go:477: [debug] Starting delete for \"spire-server\" ConfigMap\n    client.go:477: [debug] Starting delete for \"kubeslice-kubernetes-dashboard-creds\" Secret\n    client.go:477: [debug] Starting delete for \"kubeslice-hub\" Secret\n    client.go:477: [debug] Starting delete for \"kubeslice-image-pull-secret\" Secret\n    client.go:477: [debug] Starting delete for \"kubeslice-admission-webhook-certs\" Secret\n    client.go:477: [debug] Starting delete for \"kubeslice-controller-manager\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"admission-webhook-sa\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"kubeslice-netop\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"vpn-gateway-server\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"vpn-gateway-client\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"slice-router\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"forward-plane-acc\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"nsc-acc\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"nsmgr-acc\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"nse-acc\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"kubeslice-dns\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"spire-agent\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"spire-server\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"spire\" Namespace\n    client.go:477: [debug] Starting delete for \"kubeslice-mutating-webhook-configuration\" MutatingWebhookConfiguration\n    client.go:477: [debug] Starting delete for \"nsm-webhook-high-priority\" PriorityClass\n    client.go:477: [debug] Starting delete for \"k8s-workload-registrar\" ValidatingWebhookConfiguration\n    wait.go:66: [debug] beginning wait for 64 resources to be deleted with timeout of 5m0s\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ClusterRole\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-postdelete-job\" rbac.authorization.k8s.io/v1, Kind=ClusterRole: clusterroles.rbac.authorization.k8s.io \"kubeslice-postdelete-job\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ClusterRoleBinding\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-postdelete-job\" rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding: clusterrolebindings.rbac.authorization.k8s.io \"kubeslice-postdelete-job\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ServiceAccount\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-postdelete-job\" /v1, Kind=ServiceAccount: serviceaccounts \"kubeslice-postdelete-job\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ConfigMap\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-postdelete-job\" /v1, Kind=ConfigMap: configmaps \"kubeslice-postdelete-job\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" Job\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-postdelete-job\" batch/v1, Kind=Job: jobs.batch \"kubeslice-postdelete-job\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:703: [debug] Watching for changes to Job kubeslice-postdelete-job with timeout of 5m0s\n    client.go:731: [debug] Add/Modify event for kubeslice-postdelete-job: ADDED\n    client.go:770: [debug] kubeslice-postdelete-job: Jobs active: 0, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for kubeslice-postdelete-job: MODIFIED\n    client.go:770: [debug] kubeslice-postdelete-job: Jobs active: 1, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for kubeslice-postdelete-job: MODIFIED\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ConfigMap\n    uninstall.go:148: [debug] purge requested for kubeslice-worker\n    Error: uninstallation completed with 1 error(s): timed out waiting for the condition\n    helm.go:84: [debug] uninstallation completed with 1 error(s): timed out waiting for the condition\n    helm.sh/helm/v3/pkg/action.(*Uninstall).Run\n    \thelm.sh/helm/v3/pkg/action/uninstall.go:156\n    main.newUninstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/uninstall.go:56\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:916\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:1044\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:968\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\noccurred","time":{"start":1678717196000,"stop":1678717518406,"duration":322406}},{"uid":"186ef332cee6642f","status":"failed","statusDetails":"Timed out after 500.017s.\nExpected\n    <bool>: false\nto be true","time":{"start":1678714057000,"stop":1678714559869,"duration":502869}},{"uid":"bca934df5c526e18","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc0007b2018>: {\n        Underlying: <*exec.ExitError | 0xc0003c2000>{\n            ProcessState: {\n                pid: 7109,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 4, Usec: 657515},\n                    Stime: {Sec: 1, Usec: 477702},\n                    Maxrss: 141328,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 6452,\n                    Majflt: 453,\n                    Nswap: 0,\n                    Inblock: 75504,\n                    Oublock: 22416,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 142815,\n                    Nivcsw: 37270,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"uninstall.go:95: [debug] uninstall: Deleting kubeslice-worker\",\n                        \"client.go:477: [debug] Starting delete for \\\"nsm-delete-webhooks\\\" ClusterRole\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"nsm-delete-webhooks\\\" rbac.authorization.k8s.io/v1, Kind=ClusterRole: clusterroles.rbac.authorization.k8s.io \\\"nsm-delete-webhooks\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"nsm-delete-webhooks\\\" ClusterRoleBinding\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"nsm-delete-webhooks\\\" rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding: clusterrolebindings.rbac.authorization.k8s.io \\\"nsm-delete-webhooks\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"kubeslice-cleanup\\\" ServiceAccount\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"kubeslice-cleanup\\\" /v1, Kind=ServiceAccount: serviceaccounts \\\"kubeslice-cleanup\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"kubeslice-cleanup\\\" ClusterRole\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"kubeslice-cleanup\\\" rbac.authorization.k8s.io/v1, Kind=ClusterRole: clusterroles.rbac.authorization.k8s.io \\\"kubeslice-cleanup\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"kubeslice-cleanup\\\" ClusterRoleBinding\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"kubeslice-cleanup\\\" rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding: clusterrolebindings.rbac.authorization.k8s.io \\\"kubeslice-cleanup\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"nsm-delete-webhooks\\\" ServiceAccount\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"nsm-delete-webhooks\\\" /v1, Kind=ServiceAccount: serviceaccounts \\\"nsm-delete-webhooks\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"nsm-delete-webhooks\\\" ConfigMap\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"nsm-delete-webhooks\\\" /v1, Kind=ConfigMap: configmaps \\\"nsm-delete-webhooks\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"kubeslice-cleanup\\\" Job\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"kubeslice-cleanup\\\" batch/v1, Kind=Job: jobs.batch \\\"kubeslice-cleanup\\...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; uninstall.go:95: [debug] uninstall: Deleting kubeslice-worker\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ClusterRole\n    client.go:481: [debug] Ignoring delete failure for \"nsm-delete-webhooks\" rbac.authorization.k8s.io/v1, Kind=ClusterRole: clusterroles.rbac.authorization.k8s.io \"nsm-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ClusterRoleBinding\n    client.go:481: [debug] Ignoring delete failure for \"nsm-delete-webhooks\" rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding: clusterrolebindings.rbac.authorization.k8s.io \"nsm-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ServiceAccount\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-cleanup\" /v1, Kind=ServiceAccount: serviceaccounts \"kubeslice-cleanup\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ClusterRole\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-cleanup\" rbac.authorization.k8s.io/v1, Kind=ClusterRole: clusterroles.rbac.authorization.k8s.io \"kubeslice-cleanup\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ClusterRoleBinding\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-cleanup\" rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding: clusterrolebindings.rbac.authorization.k8s.io \"kubeslice-cleanup\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ServiceAccount\n    client.go:481: [debug] Ignoring delete failure for \"nsm-delete-webhooks\" /v1, Kind=ServiceAccount: serviceaccounts \"nsm-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ConfigMap\n    client.go:481: [debug] Ignoring delete failure for \"nsm-delete-webhooks\" /v1, Kind=ConfigMap: configmaps \"nsm-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" Job\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-cleanup\" batch/v1, Kind=Job: jobs.batch \"kubeslice-cleanup\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:703: [debug] Watching for changes to Job kubeslice-cleanup with timeout of 5m0s\n    client.go:731: [debug] Add/Modify event for kubeslice-cleanup: ADDED\n    client.go:770: [debug] kubeslice-cleanup: Jobs active: 0, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for kubeslice-cleanup: MODIFIED\n    client.go:770: [debug] kubeslice-cleanup: Jobs active: 1, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for kubeslice-cleanup: MODIFIED\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" Job\n    client.go:481: [debug] Ignoring delete failure for \"nsm-delete-webhooks\" batch/v1, Kind=Job: jobs.batch \"nsm-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:703: [debug] Watching for changes to Job nsm-delete-webhooks with timeout of 5m0s\n    client.go:731: [debug] Add/Modify event for nsm-delete-webhooks: ADDED\n    client.go:770: [debug] nsm-delete-webhooks: Jobs active: 0, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for nsm-delete-webhooks: MODIFIED\n    client.go:770: [debug] nsm-delete-webhooks: Jobs active: 1, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for nsm-delete-webhooks: MODIFIED\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ClusterRole\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ConfigMap\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" Job\n    client.go:477: [debug] Starting delete for \"kubeslice-webhook-service\" Service\n    client.go:477: [debug] Starting delete for \"spire-server\" Service\n    client.go:477: [debug] Starting delete for \"admission-webhook-svc\" Service\n    client.go:477: [debug] Starting delete for \"k8s-workload-registrar\" Service\n    client.go:477: [debug] Starting delete for \"registry\" Service\n    client.go:477: [debug] Starting delete for \"kubeslice-dns\" Service\n    client.go:477: [debug] Starting delete for \"spire-server\" StatefulSet\n    client.go:477: [debug] Starting delete for \"kubeslice-operator\" Deployment\n    client.go:477: [debug] Starting delete for \"nsm-admission-webhook-k8s\" Deployment\n    client.go:477: [debug] Starting delete for \"registry-k8s\" Deployment\n    client.go:477: [debug] Starting delete for \"kubeslice-dns\" Deployment\n    client.go:477: [debug] Starting delete for \"kubeslice-netop\" DaemonSet\n    client.go:477: [debug] Starting delete for \"spire-agent\" DaemonSet\n    client.go:477: [debug] Starting delete for \"forwarder-kernel\" DaemonSet\n    client.go:477: [debug] Starting delete for \"nsmgr\" DaemonSet\n    client.go:477: [debug] Starting delete for \"kubeslice-leader-election-rolebinding\" RoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-leader-election-role\" Role\n    client.go:477: [debug] Starting delete for \"kubeslice-proxy-rolebinding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"admission-webhook-binding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"nsm-role-binding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"spire-agent-cluster-role-binding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"k8s-workload-registrar-role-binding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"spire-server-trust-role-binding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-dns-rolebinding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-manager-rolebinding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-proxy-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"k8s-workload-registrar-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"spire-server-trust-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-dns-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"admission-webhook-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-manager-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"nsm-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-metrics-reader\" ClusterRole\n    client.go:477: [debug] Starting delete for \"aggregate-network-services-view\" ClusterRole\n    client.go:477: [debug] Starting delete for \"spire-agent-cluster-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"spire-agent\" ConfigMap\n    client.go:477: [debug] Starting delete for \"k8s-workload-registrar\" ConfigMap\n    client.go:477: [debug] Starting delete for \"kubeslice-manager-config\" ConfigMap\n    client.go:477: [debug] Starting delete for \"spire-bundle\" ConfigMap\n    client.go:477: [debug] Starting delete for \"spire-server\" ConfigMap\n    client.go:477: [debug] Starting delete for \"kubeslice-admission-webhook-certs\" Secret\n    client.go:477: [debug] Starting delete for \"kubeslice-kubernetes-dashboard-creds\" Secret\n    client.go:477: [debug] Starting delete for \"kubeslice-hub\" Secret\n    client.go:477: [debug] Starting delete for \"kubeslice-image-pull-secret\" Secret\n    client.go:477: [debug] Starting delete for \"kubeslice-dns\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"kubeslice-controller-manager\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"admission-webhook-sa\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"kubeslice-netop\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"vpn-gateway-server\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"vpn-gateway-client\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"slice-router\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"forward-plane-acc\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"nse-acc\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"nsc-acc\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"nsmgr-acc\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"spire-server\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"spire-agent\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"spire\" Namespace\n    client.go:477: [debug] Starting delete for \"kubeslice-mutating-webhook-configuration\" MutatingWebhookConfiguration\n    client.go:477: [debug] Starting delete for \"nsm-webhook-high-priority\" PriorityClass\n    client.go:477: [debug] Starting delete for \"k8s-workload-registrar\" ValidatingWebhookConfiguration\n    wait.go:66: [debug] beginning wait for 64 resources to be deleted with timeout of 5m0s\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ClusterRole\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-postdelete-job\" rbac.authorization.k8s.io/v1, Kind=ClusterRole: clusterroles.rbac.authorization.k8s.io \"kubeslice-postdelete-job\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ClusterRoleBinding\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-postdelete-job\" rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding: clusterrolebindings.rbac.authorization.k8s.io \"kubeslice-postdelete-job\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ServiceAccount\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-postdelete-job\" /v1, Kind=ServiceAccount: serviceaccounts \"kubeslice-postdelete-job\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ConfigMap\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-postdelete-job\" /v1, Kind=ConfigMap: configmaps \"kubeslice-postdelete-job\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" Job\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-postdelete-job\" batch/v1, Kind=Job: jobs.batch \"kubeslice-postdelete-job\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:703: [debug] Watching for changes to Job kubeslice-postdelete-job with timeout of 5m0s\n    client.go:731: [debug] Add/Modify event for kubeslice-postdelete-job: ADDED\n    client.go:770: [debug] kubeslice-postdelete-job: Jobs active: 0, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for kubeslice-postdelete-job: MODIFIED\n    client.go:770: [debug] kubeslice-postdelete-job: Jobs active: 1, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for kubeslice-postdelete-job: MODIFIED\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"kubeslice-postdelete-job\" ConfigMap\n    uninstall.go:148: [debug] purge requested for kubeslice-worker\n    Error: uninstallation completed with 1 error(s): timed out waiting for the condition\n    helm.go:84: [debug] uninstallation completed with 1 error(s): timed out waiting for the condition\n    helm.sh/helm/v3/pkg/action.(*Uninstall).Run\n    \thelm.sh/helm/v3/pkg/action/uninstall.go:156\n    main.newUninstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/uninstall.go:56\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:916\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:1044\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:968\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\noccurred","time":{"start":1678710904000,"stop":1678711223297,"duration":319297}},{"uid":"e8a6cd6959c96b25","status":"broken","statusDetails":"interrupted","time":{"start":1678092810000,"stop":1678092840001,"duration":30001}},{"uid":"f431ddc28f18c459","status":"broken","statusDetails":"interrupted","time":{"start":1678076739000,"stop":1678076768996,"duration":29996}},{"uid":"2d0da037388a3bcc","status":"passed","time":{"start":1675163335000,"stop":1675163413365,"duration":78365}},{"uid":"b969ab8773187c30","status":"passed","time":{"start":1675072262000,"stop":1675072366786,"duration":104786}},{"uid":"de5a971f5e0f2aaf","status":"passed","time":{"start":1675065745000,"stop":1675065824577,"duration":79577}},{"uid":"e89b55fde3732632","status":"passed","time":{"start":1674820261000,"stop":1674820375149,"duration":114149}},{"uid":"ff4ab20a46fd0791","status":"passed","time":{"start":1674817948000,"stop":1674818035412,"duration":87412}},{"uid":"fedce7d2dce89c58","status":"passed","time":{"start":1674812394000,"stop":1674812558038,"duration":164038}},{"uid":"701ec3517ff0513a","status":"passed","time":{"start":1674809357000,"stop":1674809456455,"duration":99455}},{"uid":"76740c405d81ba61","status":"passed","time":{"start":1674806753000,"stop":1674806873012,"duration":120012}},{"uid":"fb5d3c49f2548c7d","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc00000e078>: {\n        Underlying: <*exec.ExitError | 0xc00089e000>{\n            ProcessState: {\n                pid: 7590,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 4, Usec: 356089},\n                    Stime: {Sec: 1, Usec: 853655},\n                    Maxrss: 108512,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 6887,\n                    Majflt: 5,\n                    Nswap: 0,\n                    Inblock: 4760,\n                    Oublock: 19120,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 97566,\n                    Nivcsw: 30963,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"uninstall.go:95: [debug] uninstall: Deleting kubeslice-worker\",\n                        \"client.go:477: [debug] Starting delete for \\\"kubeslice-delete-webhooks\\\" ClusterRole\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"kubeslice-delete-webhooks\\\" rbac.authorization.k8s.io/v1, Kind=ClusterRole: clusterroles.rbac.authorization.k8s.io \\\"kubeslice-delete-webhooks\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"kubeslice-delete-webhooks\\\" ClusterRoleBinding\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"kubeslice-delete-webhooks\\\" rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding: clusterrolebindings.rbac.authorization.k8s.io \\\"kubeslice-delete-webhooks\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"nsm-delete-webhooks\\\" ClusterRole\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"nsm-delete-webhooks\\\" rbac.authorization.k8s.io/v1, Kind=ClusterRole: clusterroles.rbac.authorization.k8s.io \\\"nsm-delete-webhooks\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"nsm-delete-webhooks\\\" ClusterRoleBinding\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"nsm-delete-webhooks\\\" rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding: clusterrolebindings.rbac.authorization.k8s.io \\\"nsm-delete-webhooks\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"kubeslice-cleanup\\\" ServiceAccount\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"kubeslice-cleanup\\\" /v1, Kind=ServiceAccount: serviceaccounts \\\"kubeslice-cleanup\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"kubeslice-cleanup\\\" ClusterRole\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"kubeslice-cleanup\\\" rbac.authorization.k8s.io/v1, Kind=ClusterRole: clusterroles.rbac.authorization.k8s.io \\\"kubeslice-cleanup\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"kubeslice-cleanup\\\" ClusterRoleBinding\",\n                        \"client.go:481: [debug] Ignoring delete failure for \\\"kubeslice-cleanup\\\" rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding: clusterrolebindings.rbac.authorization.k8s.io \\\"kubeslice-cleanup\\\" not found\",\n                        \"client.go:133: [debug] creating 1 resource(s)\",\n                        \"client.go:477: [debug] Starting delete for \\\"kubeslice-delete-webhoo...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; uninstall.go:95: [debug] uninstall: Deleting kubeslice-worker\n    client.go:477: [debug] Starting delete for \"kubeslice-delete-webhooks\" ClusterRole\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-delete-webhooks\" rbac.authorization.k8s.io/v1, Kind=ClusterRole: clusterroles.rbac.authorization.k8s.io \"kubeslice-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-delete-webhooks\" ClusterRoleBinding\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-delete-webhooks\" rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding: clusterrolebindings.rbac.authorization.k8s.io \"kubeslice-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ClusterRole\n    client.go:481: [debug] Ignoring delete failure for \"nsm-delete-webhooks\" rbac.authorization.k8s.io/v1, Kind=ClusterRole: clusterroles.rbac.authorization.k8s.io \"nsm-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ClusterRoleBinding\n    client.go:481: [debug] Ignoring delete failure for \"nsm-delete-webhooks\" rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding: clusterrolebindings.rbac.authorization.k8s.io \"nsm-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ServiceAccount\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-cleanup\" /v1, Kind=ServiceAccount: serviceaccounts \"kubeslice-cleanup\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ClusterRole\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-cleanup\" rbac.authorization.k8s.io/v1, Kind=ClusterRole: clusterroles.rbac.authorization.k8s.io \"kubeslice-cleanup\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ClusterRoleBinding\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-cleanup\" rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding: clusterrolebindings.rbac.authorization.k8s.io \"kubeslice-cleanup\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-delete-webhooks\" ServiceAccount\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-delete-webhooks\" /v1, Kind=ServiceAccount: serviceaccounts \"kubeslice-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-delete-webhooks\" ConfigMap\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-delete-webhooks\" /v1, Kind=ConfigMap: configmaps \"kubeslice-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ServiceAccount\n    client.go:481: [debug] Ignoring delete failure for \"nsm-delete-webhooks\" /v1, Kind=ServiceAccount: serviceaccounts \"nsm-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ConfigMap\n    client.go:481: [debug] Ignoring delete failure for \"nsm-delete-webhooks\" /v1, Kind=ConfigMap: configmaps \"nsm-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" Job\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-cleanup\" batch/v1, Kind=Job: jobs.batch \"kubeslice-cleanup\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:703: [debug] Watching for changes to Job kubeslice-cleanup with timeout of 5m0s\n    client.go:731: [debug] Add/Modify event for kubeslice-cleanup: ADDED\n    client.go:770: [debug] kubeslice-cleanup: Jobs active: 0, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for kubeslice-cleanup: MODIFIED\n    client.go:770: [debug] kubeslice-cleanup: Jobs active: 1, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for kubeslice-cleanup: MODIFIED\n    client.go:477: [debug] Starting delete for \"kubeslice-delete-webhooks\" Job\n    client.go:481: [debug] Ignoring delete failure for \"kubeslice-delete-webhooks\" batch/v1, Kind=Job: jobs.batch \"kubeslice-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:703: [debug] Watching for changes to Job kubeslice-delete-webhooks with timeout of 5m0s\n    client.go:731: [debug] Add/Modify event for kubeslice-delete-webhooks: ADDED\n    client.go:770: [debug] kubeslice-delete-webhooks: Jobs active: 0, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for kubeslice-delete-webhooks: MODIFIED\n    client.go:770: [debug] kubeslice-delete-webhooks: Jobs active: 1, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for kubeslice-delete-webhooks: MODIFIED\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" Job\n    client.go:481: [debug] Ignoring delete failure for \"nsm-delete-webhooks\" batch/v1, Kind=Job: jobs.batch \"nsm-delete-webhooks\" not found\n    client.go:133: [debug] creating 1 resource(s)\n    client.go:703: [debug] Watching for changes to Job nsm-delete-webhooks with timeout of 5m0s\n    client.go:731: [debug] Add/Modify event for nsm-delete-webhooks: ADDED\n    client.go:770: [debug] nsm-delete-webhooks: Jobs active: 0, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for nsm-delete-webhooks: MODIFIED\n    client.go:770: [debug] nsm-delete-webhooks: Jobs active: 1, jobs failed: 0, jobs succeeded: 0\n    client.go:731: [debug] Add/Modify event for nsm-delete-webhooks: MODIFIED\n    client.go:477: [debug] Starting delete for \"kubeslice-delete-webhooks\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-delete-webhooks\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ClusterRole\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-delete-webhooks\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"kubeslice-delete-webhooks\" ConfigMap\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"nsm-delete-webhooks\" ConfigMap\n    client.go:477: [debug] Starting delete for \"kubeslice-cleanup\" Job\n    client.go:477: [debug] Starting delete for \"kubeslice-webhook-service\" Service\n    client.go:477: [debug] Starting delete for \"spire-server\" Service\n    client.go:477: [debug] Starting delete for \"admission-webhook-svc\" Service\n    client.go:477: [debug] Starting delete for \"k8s-workload-registrar\" Service\n    client.go:477: [debug] Starting delete for \"registry\" Service\n    client.go:477: [debug] Starting delete for \"kubeslice-dns\" Service\n    client.go:477: [debug] Starting delete for \"spire-server\" StatefulSet\n    client.go:477: [debug] Starting delete for \"kubeslice-operator\" Deployment\n    client.go:477: [debug] Starting delete for \"nsm-admission-webhook-k8s\" Deployment\n    client.go:477: [debug] Starting delete for \"registry-k8s\" Deployment\n    client.go:477: [debug] Starting delete for \"kubeslice-dns\" Deployment\n    client.go:477: [debug] Starting delete for \"spire-agent\" DaemonSet\n    client.go:477: [debug] Starting delete for \"kubeslice-netop\" DaemonSet\n    client.go:477: [debug] Starting delete for \"forwarder-kernel\" DaemonSet\n    client.go:477: [debug] Starting delete for \"nsmgr\" DaemonSet\n    client.go:477: [debug] Starting delete for \"kubeslice-leader-election-rolebinding\" RoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-leader-election-role\" Role\n    client.go:477: [debug] Starting delete for \"k8s-workload-registrar-role-binding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"admission-webhook-binding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"nsm-role-binding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"spire-agent-cluster-role-binding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"spire-server-trust-role-binding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-dns-rolebinding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-manager-rolebinding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-proxy-rolebinding\" ClusterRoleBinding\n    client.go:477: [debug] Starting delete for \"kubeslice-proxy-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"admission-webhook-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"nsm-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"aggregate-network-services-view\" ClusterRole\n    client.go:477: [debug] Starting delete for \"spire-agent-cluster-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"k8s-workload-registrar-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"spire-server-trust-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-dns-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-manager-role\" ClusterRole\n    client.go:477: [debug] Starting delete for \"kubeslice-metrics-reader\" ClusterRole\n    client.go:477: [debug] Starting delete for \"spiffeids.spiffeid.spiffe.io\" CustomResourceDefinition\n    client.go:477: [debug] Starting delete for \"spire-agent\" ConfigMap\n    client.go:477: [debug] Starting delete for \"k8s-workload-registrar\" ConfigMap\n    client.go:477: [debug] Starting delete for \"spire-bundle\" ConfigMap\n    client.go:477: [debug] Starting delete for \"spire-server\" ConfigMap\n    client.go:477: [debug] Starting delete for \"kubeslice-manager-config\" ConfigMap\n    client.go:477: [debug] Starting delete for \"kubeslice-admission-webhook-certs\" Secret\n    client.go:477: [debug] Starting delete for \"kubeslice-kubernetes-dashboard-creds\" Secret\n    client.go:477: [debug] Starting delete for \"kubeslice-hub\" Secret\n    client.go:477: [debug] Starting delete for \"kubeslice-image-pull-secret\" Secret\n    client.go:477: [debug] Starting delete for \"kubeslice-dns\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"kubeslice-netop\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"admission-webhook-sa\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"nsc-acc\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"vpn-gateway-server\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"vpn-gateway-client\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"slice-router\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"kubeslice-controller-manager\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"nse-acc\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"spire-agent\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"nsmgr-acc\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"forward-plane-acc\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"spire-server\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"kubeslice-kubernetes-dashboard\" ServiceAccount\n    client.go:477: [debug] Starting delete for \"spire\" Namespace\n    client.go:477: [debug] Starting delete for \"kubeslice-mutating-webhook-configuration\" MutatingWebhookConfiguration\n    client.go:477: [debug] Starting delete for \"nsm-webhook-high-priority\" PriorityClass\n    client.go:477: [debug] Starting delete for \"k8s-workload-registrar\" ValidatingWebhookConfiguration\n    wait.go:66: [debug] beginning wait for 65 resources to be deleted with timeout of 5m0s\n    uninstall.go:148: [debug] purge requested for kubeslice-worker\n    Error: uninstallation completed with 1 error(s): timed out waiting for the condition\n    helm.go:84: [debug] uninstallation completed with 1 error(s): timed out waiting for the condition\n    helm.sh/helm/v3/pkg/action.(*Uninstall).Run\n    \thelm.sh/helm/v3/pkg/action/uninstall.go:156\n    main.newUninstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/uninstall.go:56\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:916\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:1044\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:968\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1571\noccurred","time":{"start":1674805966000,"stop":1674806353166,"duration":387166}},{"uid":"5df55a42c1e64c40","status":"passed","time":{"start":1674800857000,"stop":1674800940024,"duration":83024}},{"uid":"5d84663594f9ae9b","status":"passed","time":{"start":1674797357000,"stop":1674797446395,"duration":89395}},{"uid":"9f6064f7430a3c12","status":"passed","time":{"start":1674795632000,"stop":1674795754596,"duration":122596}}]},"tags":[]},"source":"16747607bcc068e1.json","parameterValues":[]}