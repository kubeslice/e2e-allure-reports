{"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - negative pod cound":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"93fae744327fffa8","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Validate License Tests License Validate tests should fail CRUD in case someone tampered license.key":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"377f8a0b70fb5617","status":"passed","time":{"start":1693828311000,"stop":1693828315242,"duration":4242}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests SliceRoleTemplate Tests Create SliceRoleTempalate successful test: Creating SliceRoleTempalate read-only-role":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"3c9f0dd45accf71e","status":"passed","time":{"start":1693828311000,"stop":1693828336247,"duration":25247}}]},"Intracluster Suite:Intracluster Suite#[It] Intracluster slice tests Iperf connectivity should have vl3 router running":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"b63200323e7576b3","status":"passed","time":{"start":1688025155000,"stop":1688025155006,"duration":6}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - namespace.DefaultRequestPerContainer.CPU > namespace.Limit.CPU":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"65f306f3c0addf23","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests RBAC Common Tests WorkerSliceRoleBinding generation test: WorkerSliceRoleBinding with kubernetes role should be generated automatically when forcefully deleted":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"e8b402d760792414","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Intracluster Suite:Intracluster Suite#[BeforeSuite]":{"statistic":{"failed":2,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":3},"items":[{"uid":"c229893beaa509e8","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc0004b1350>: {\n        Underlying: <*exec.ExitError | 0xc00013a2a0>{\n            ProcessState: {\n                pid: 6358,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 0, Usec: 97224},\n                    Stime: {Sec: 0, Usec: 28357},\n                    Maxrss: 50484,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 2337,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 0,\n                    Oublock: 168,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 541,\n                    Nivcsw: 344,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"install.go:200: [debug] Original chart version: \\\"\\\"\",\n                        \"install.go:217: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-controller-1.2.0.tgz\",\n                        \"\",\n                        \"Error: INSTALLATION FAILED: cannot re-use a name that is still in use\",\n                        \"helm.go:84: [debug] cannot re-use a name that is still in use\",\n                        \"helm.sh/helm/v3/pkg/action.(*Install).availableName\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:512\",\n                        \"helm.sh/helm/v3/pkg/action.(*Install).RunWithContext\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:222\",\n                        \"main.runInstall\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:286\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:145\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:916\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:1044\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:968\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:250\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1598\",\n                        \"INSTALLATION FAILED\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:147\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:916\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:1044\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:968\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:250\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1598\",\n                    ],\n                },\n            },\n            stderr: {\n                Lines: [\n                    \"WARNING: Kubernetes configuration file is group-readable. This is ins...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    install.go:200: [debug] Original chart version: \"\"\n    install.go:217: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-controller-1.2.0.tgz\n    \n    Error: INSTALLATION FAILED: cannot re-use a name that is still in use\n    helm.go:84: [debug] cannot re-use a name that is still in use\n    helm.sh/helm/v3/pkg/action.(*Install).availableName\n    \thelm.sh/helm/v3/pkg/action/install.go:512\n    helm.sh/helm/v3/pkg/action.(*Install).RunWithContext\n    \thelm.sh/helm/v3/pkg/action/install.go:222\n    main.runInstall\n    \thelm.sh/helm/v3/cmd/helm/install.go:286\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:145\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:916\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:1044\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:968\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1598\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:147\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:916\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:1044\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:968\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1598\noccurred","time":{"start":1689751062000,"stop":1689751062403,"duration":403}},{"uid":"8cd686f2467a5451","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc00000f098>: {\n        Underlying: <*exec.ExitError | 0xc00049e880>{\n            ProcessState: {\n                pid: 6336,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 0, Usec: 103164},\n                    Stime: {Sec: 0, Usec: 19104},\n                    Maxrss: 48060,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 2379,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 0,\n                    Oublock: 168,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 609,\n                    Nivcsw: 335,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"install.go:200: [debug] Original chart version: \\\"\\\"\",\n                        \"install.go:217: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-controller-1.2.0.tgz\",\n                        \"\",\n                        \"Error: INSTALLATION FAILED: cannot re-use a name that is still in use\",\n                        \"helm.go:84: [debug] cannot re-use a name that is still in use\",\n                        \"helm.sh/helm/v3/pkg/action.(*Install).availableName\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:512\",\n                        \"helm.sh/helm/v3/pkg/action.(*Install).RunWithContext\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:222\",\n                        \"main.runInstall\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:286\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:145\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:916\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:1044\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:968\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:250\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1598\",\n                        \"INSTALLATION FAILED\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:147\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:916\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:1044\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:968\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:250\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1598\",\n                    ],\n                },\n            },\n            stderr: {\n                Lines: [\n                    \"WARNING: Kubernetes configuration file is group-readable. This is in...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    install.go:200: [debug] Original chart version: \"\"\n    install.go:217: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-controller-1.2.0.tgz\n    \n    Error: INSTALLATION FAILED: cannot re-use a name that is still in use\n    helm.go:84: [debug] cannot re-use a name that is still in use\n    helm.sh/helm/v3/pkg/action.(*Install).availableName\n    \thelm.sh/helm/v3/pkg/action/install.go:512\n    helm.sh/helm/v3/pkg/action.(*Install).RunWithContext\n    \thelm.sh/helm/v3/pkg/action/install.go:222\n    main.runInstall\n    \thelm.sh/helm/v3/cmd/helm/install.go:286\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:145\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:916\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:1044\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:968\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1598\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:147\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:916\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:1044\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:968\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1598\noccurred","time":{"start":1688627854000,"stop":1688627854455,"duration":455}},{"uid":"7e4c5bfa62c44c00","status":"passed","time":{"start":1688025155000,"stop":1688025328626,"duration":173626}}]},"Controller Suite:Controller Suite#[It] Events Test Events get recorded for slice resource quota deletion Validating events for worker slice resource quotas deletion":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"3984e10358cc890a","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests RBAC Common Tests WorkerSliceRoleBinding generation test: Creation of SliceRoleBinding with custom roles should generate WorkerSliceRoleBinding":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"55e085e80e88904c","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] E2E tests for license job > when license config is tampered with should eventually record appropiate event":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"45a80bec720e7d75","status":"passed","time":{"start":1693828311000,"stop":1693828324174,"duration":13174}}]},"Controller Suite:Controller Suite#[It] Validate License Tests License Validate tests should update the license to expired but grace period not expired - should not fail CRUD":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"70ff515933d500b5","status":"passed","time":{"start":1693828311000,"stop":1693828318439,"duration":7439}}]},"Controller Suite:Controller Suite#[It] Events Test Events get recorded for slice resource quota deletion Validating events for slice resource quota recreation after forceful deletion":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"3e796b363568bd48","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"SliceHealth Suite:SliceHealth Suite#[It] Slice Health Check tests Test Slice Health Check Should have slice health status Normal in controller slice CR":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"75fbb8615c4d5c73","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1688026084000,"stop":1688026084000,"duration":0}}]},"Controller Suite:Controller Suite#[It] E2E tests for license job > when controller is installed with default options should record appropiate event":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"4cd58a812330d28d","status":"passed","time":{"start":1693828311000,"stop":1693828320963,"duration":9963}}]},"Hub Suite:Hub Suite#[It] Project CR test Project Update Should fail when Project is applied with service account name as blank in Write users":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"7e12b059c021b5b0","status":"passed","time":{"start":1688022039000,"stop":1688022043894,"duration":4894}}]},"Controller Suite:Controller Suite#[It] Events Test Events get recorded for slice role binding creation and deletion Events get recorded for slice role binding deletion Validating events for worker slice role bindings deletion":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"ab4ef2e67acf0d36","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Project CR test Project Deletion Should fail when deleting a project that does not exist":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"c9838ac3f5a19546","status":"passed","time":{"start":1688022039000,"stop":1688022046764,"duration":7764}}]},"Controller Suite:Controller Suite#[It] Events Test Events get recorded for slice node affinity creation and deletion Events get recorded for slice node affinity creation Validating events for worker slice node affinities creation":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"a909bb2ef158f6ec","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Validate License Tests License Validate tests Should have all the fields populated in secret":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"ba9fe0c6c4c2cca3","status":"passed","time":{"start":1693828311000,"stop":1693828311275,"duration":275}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - namespace.DefaultRequestPerContainer.Mem > namespace.Limit.Mem":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"8a6e77ad43b29cdd","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Project CR test Project Update Should fail when Project is Applied with service account name as combination of special characters in Write users":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"1861f732ec019a8c","status":"passed","time":{"start":1688022039000,"stop":1688022044879,"duration":5879}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - namespace.DefaultRequestPerContainer.EphemeralStorage > namespace.Limit.EphemeralStorage":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"62ef8e944a89e774","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice node affinity Tests SliceNodeAffinity tests - includes creation and deletion testcase to check node selector labels for expanded namespaces":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"fd9e47d44777c74b","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests SliceRoleBinding Tests Create SliceRoleBinding failure test: Creating SliceRoleBinding slice-red with empty namespace":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"da45641e1b545e81","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice node affinity Tests SliceNodeAffinity tests - includes creation and deletion slice node affinity Passing - deletion of sliceconfig deletes the slicenodeaffinity":{"statistic":{"failed":1,"broken":0,"skipped":0,"passed":0,"unknown":0,"total":1},"items":[{"uid":"d8d18b8893975dab","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc0009073f8>: {\n        Underlying: <*exec.ExitError | 0xc000623be0>{\n            ProcessState: {\n                pid: 6536,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 0, Usec: 300735},\n                    Stime: {Sec: 0, Usec: 138496},\n                    Maxrss: 103640,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 6539,\n                    Majflt: 679,\n                    Nswap: 0,\n                    Inblock: 28600,\n                    Oublock: 20592,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 1896,\n                    Nivcsw: 1554,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"Error from server (InternalError): error when creating \\\"/e2e/assets/controller/nodeaffinity/slicenodeaffinity_red_success.yaml\\\": Internal error occurred: failed calling webhook \\\"vslicenodeaffinity.kb.io\\\": failed to call webhook: Post \\\"https://kubeslice-controller-webhook-service.kubeslice-controller.svc:443/validate-controller-kubeslice-io-v1alpha1-slicenodeaffinity?timeout=10s\\\": dial tcp 10.96.60.138:443: connect: connection refused\",\n                    ],\n                },\n            },\n            stderr: {\n                Lines: [\n                    \"Error from server (InternalError): error when creating \\\"/e2e/assets/controller/nodeaffinity/slicenodeaffinity_red_success.yaml\\\": Internal error occurred: failed calling webhook \\\"vslicenodeaffinity.kb.io\\\": failed to call webhook: Post \\\"https://kubeslice-controller-webhook-service.kubeslice-controller.svc:443/validate-controller-kubeslice-io-v1alpha1-slicenodeaffinity?timeout=10s\\\": dial tcp 10.96.60.138:443: connect: connection refused\",\n                ],\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"Error from server (InternalError): error when creating \\\"/e2e/assets/controller/nodeaffinity/slicenodeaffinity_red_success.yaml\\\": Internal error occurred: failed calling webhook \\\"vslicenodeaffinity.kb.io\\\": failed to call webhook: Post \\\"https://kubeslice-controller-webhook-service.kubeslice-controller.svc:443/validate-controller-kubeslice-io-v1alpha1-slicenodeaffinity?timeout=10s\\\": dial tcp 10.96.60.138:443: connect: connection refused\",\n                    ],\n                },\n            },\n            merged: {\n                Mutex: {state: 0, sema: 0},\n                Lines: [\n                    \"Error from server (InternalError): error when creating \\\"/e2e/assets/controller/nodeaffinity/slicenodeaffinity_red_success.yaml\\\": Internal error occurred: failed calling webhook \\\"vslicenodeaffinity.kb.io\\\": failed to call webhook: Post \\\"https://kubeslice-controller-webhook-service.kubeslice-controller.svc:443/validate-controller-kubeslice-io-v1alpha1-slicenodeaffinity?timeout=10s\\\": dial tcp 10.96.60.138:443: connect: connection refused\",\n                ],\n            },\n        },\n    }\n    error while running command: exit status 1; Error from server (InternalError): error when creating \"/e2e/assets/controller/nodeaffinity/slicenodeaffinity_red_success.yaml\": Internal error occurred: failed calling webhook \"vslicenodeaffinity.kb.io\": failed to call webhook: Post \"https://kubeslice-controller-webhook-service.kubeslice-controller.svc:443/validate-controller-kubeslice-io-v1alpha1-slicenodeaffinity?timeout=10s\": dial tcp 10.96.60.138:443: connect: connection refused\noccurred","time":{"start":1693828311000,"stop":1693828387472,"duration":76472}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - namespace.DefaultLimitPerContainer.Memory is negative":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"161ab71dbc12c99","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests RBAC Common Tests WorkerSliceRoleBinding data propagation test: Checking successful propagation of ApplyTo":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"7f3b76d1fcf6c61b","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests RBAC Common Tests SliceRoleBinding status test: SliceRoleBinding should have error status for invalid namespace for k8s roles":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"8d993fceb2ed05c0","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test- Request.Mem > Limit.Mem at slice level":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"969d825ac35cacd8","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests SliceRoleTemplate Tests Create SliceRoleTempalate failure test: Creating SliceRoleTempalate read-only-role, missing resources field":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"ea657b0e989e14d2","status":"passed","time":{"start":1693828311000,"stop":1693828316024,"duration":5024}}]},"Hub Suite:Hub Suite#[It] Cluster negative tests Worker Cluster Registration with Wrong endpoint":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"4b5e4d54fe849d4d","status":"passed","time":{"start":1688022039000,"stop":1688022184601,"duration":145601}}]},"Hub Suite:Hub Suite#[It] Project CR test Project Creation Should update Project while applying valid manifest with existing Project name":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"1133a4bc9de0e0a4","status":"passed","time":{"start":1688022039000,"stop":1688022043764,"duration":4764}}]},"Worker Suite:Worker Suite#[BeforeSuite]":{"statistic":{"failed":1,"broken":0,"skipped":0,"passed":0,"unknown":0,"total":1},"items":[{"uid":"3fcd4274e0a85d49","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc0001f1e60>: {\n        Underlying: <*exec.ExitError | 0xc000462b00>{\n            ProcessState: {\n                pid: 6392,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 0, Usec: 42165},\n                    Stime: {Sec: 0, Usec: 16866},\n                    Maxrss: 43264,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 1507,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 0,\n                    Oublock: 0,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 189,\n                    Nivcsw: 39,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"error: error executing jsonpath \\\"\\\\\\\"{.clusters[?(@.name==\\\\\\\"kind-controller\\\\\\\")].cluster.server}\\\\\\\"\\\": Error executing template: <nil> is not array or slice and cannot be filtered. Printing more information for debugging the template:\",\n                        \"\\ttemplate was:\",\n                        \"\\t\\t\\\"{.clusters[?(@.name==\\\"kind-controller\\\")].cluster.server}\\\"\",\n                        \"\\tobject given to jsonpath engine was:\",\n                        \"\\t\\tmap[string]interface {}{\\\"apiVersion\\\":\\\"v1\\\", \\\"clusters\\\":interface {}(nil), \\\"contexts\\\":interface {}(nil), \\\"current-context\\\":\\\"\\\", \\\"kind\\\":\\\"Config\\\", \\\"preferences\\\":map[string]interface {}{}, \\\"users\\\":interface {}(nil)}\",\n                        \"\",\n                        \"\",\n                    ],\n                },\n            },\n            stderr: {\n                Lines: [\n                    \"error: error executing jsonpath \\\"\\\\\\\"{.clusters[?(@.name==\\\\\\\"kind-controller\\\\\\\")].cluster.server}\\\\\\\"\\\": Error executing template: <nil> is not array or slice and cannot be filtered. Printing more information for debugging the template:\",\n                    \"\\ttemplate was:\",\n                    \"\\t\\t\\\"{.clusters[?(@.name==\\\"kind-controller\\\")].cluster.server}\\\"\",\n                    \"\\tobject given to jsonpath engine was:\",\n                    \"\\t\\tmap[string]interface {}{\\\"apiVersion\\\":\\\"v1\\\", \\\"clusters\\\":interface {}(nil), \\\"contexts\\\":interface {}(nil), \\\"current-context\\\":\\\"\\\", \\\"kind\\\":\\\"Config\\\", \\\"preferences\\\":map[string]interface {}{}, \\\"users\\\":interface {}(nil)}\",\n                    \"\",\n                    \"\",\n                ],\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"error: error executing jsonpath \\\"\\\\\\\"{.clusters[?(@.name==\\\\\\\"kind-controller\\\\\\\")].cluster.server}\\\\\\\"\\\": Error executing template: <nil> is not array or slice and cannot be filtered. Printing more information for debugging the template:\",\n                        \"\\ttemplate was:\",\n                        \"\\t\\t\\\"{.clusters[?(@.name==\\\"kind-controller\\\")].cluster.server}\\\"\",\n                        \"\\tobject given to jsonpath engine was:\",\n                        \"\\t\\tmap[string]interface {}{\\\"apiVersion\\\":\\\"v1\\\", \\\"clusters\\\":interface {}(nil), \\\"contexts\\\":interface {}(nil), \\\"current-context\\\":\\\"\\\", \\\"kind\\\":\\\"Config\\\", \\\"preferences\\\":map[string]interface {}{}, \\\"users\\\":interface {}(nil)}\",\n                        \"\",\n                        \"\",\n                    ],\n                },\n            },\n            merged: {\n                Mutex: {state: 0, sema: 0},\n                Lines: [\n                    \"error: error executing jsonpath \\\"\\\\\\\"{.clusters[?(@.name==\\\\\\\"kind-controller\\\\\\\")].cluster.server}\\\\\\\"\\\": Error executing template: <nil> is not array or slice and cannot be filtered. Printing more information for debugging the template:\",\n                    \"\\ttemplate was:\",\n                    \"\\t\\t\\\"{.clusters[?(@...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; error: error executing jsonpath \"\\\"{.clusters[?(@.name==\\\"kind-controller\\\")].cluster.server}\\\"\": Error executing template: <nil> is not array or slice and cannot be filtered. Printing more information for debugging the template:\n    \ttemplate was:\n    \t\t\"{.clusters[?(@.name==\"kind-controller\")].cluster.server}\"\n    \tobject given to jsonpath engine was:\n    \t\tmap[string]interface {}{\"apiVersion\":\"v1\", \"clusters\":interface {}(nil), \"contexts\":interface {}(nil), \"current-context\":\"\", \"kind\":\"Config\", \"preferences\":map[string]interface {}{}, \"users\":interface {}(nil)}\n    \n    \noccurred","time":{"start":1688018439000,"stop":1688018439058,"duration":58}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - sum(cluster.request.CPU) > slice.CPU":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"d26d139fecff45b9","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Project CR test Project Update Should update successfully when Project Applied while removing a service account name in Read users":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"dcf349d50124e020","status":"passed","time":{"start":1688022039000,"stop":1688022043750,"duration":4750}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - slice.DefaultRequestPerContainer.mem > slice.Request.mem":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"5e45ec706ccb733d","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - sum(namespace.limit.mem) > slice.mem":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"844e88152bb40417","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"SliceHealth Suite:SliceHealth Suite#[It] Verify gw redundancy wrt health check when atleast one gateway is down should have tunnel status in warning state":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"7f6ac5d60b0552b7","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1688026084000,"stop":1688026084000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Delete resource quota should recreate the resource quota test":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"f6af246d20d45bb0","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests RBAC Common Tests WorkerSliceRoleBinding data propagation test: Checking successful propagation of rules with namespace as asterisk":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"b520a27f24f971af","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[BeforeSuite]":{"statistic":{"failed":4,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":5},"items":[{"uid":"22b93747f889e367","status":"passed","time":{"start":1693828311000,"stop":1693829071086,"duration":760086}},{"uid":"1e7336d0b014177e","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc000618018>: {\n        Underlying: <*exec.ExitError | 0xc000476000>{\n            ProcessState: {\n                pid: 5863,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 8, Usec: 446202},\n                    Stime: {Sec: 1, Usec: 281797},\n                    Maxrss: 115848,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 26522,\n                    Majflt: 470,\n                    Nswap: 0,\n                    Inblock: 66896,\n                    Oublock: 23312,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 81699,\n                    Nivcsw: 37723,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: [\n                    \"Release \\\"kubeslice-controller\\\" does not exist. Installing it now.\",\n                ],\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"history.go:56: [debug] getting history for release kubeslice-controller\",\n                        \"Release \\\"kubeslice-controller\\\" does not exist. Installing it now.\",\n                        \"install.go:200: [debug] Original chart version: \\\"\\\"\",\n                        \"install.go:217: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-controller-1.3.4.tgz\",\n                        \"\",\n                        \"client.go:134: [debug] creating 1 resource(s)\",\n                        \"client.go:134: [debug] creating 47 resource(s)\",\n                        \"wait.go:48: [debug] beginning wait for 47 resources with timeout of 5m0s\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n            ...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; history.go:56: [debug] getting history for release kubeslice-controller\n    install.go:200: [debug] Original chart version: \"\"\n    install.go:217: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-controller-1.3.4.tgz\n    \n    client.go:134: [debug] creating 1 resource(s)\n    client.go:134: [debug] creating 47 resource(s)\n    wait.go:48: [debug] beginning wait for 47 resources with timeout of 5m0s\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    install.go:475: [debug] Install failed and atomic is set, uninstalling release\n    uninstall.go:97: [debug] uninstall: Deleting kubeslice-controller\n    client.go:134: [debug] creating 1 resource(s)\n    client.go:706: [debug] Watching for changes to Job kubeslice-controller-cleanup with timeout of 5m0s\n    client.go:734: [debug] Add/Modify event for kubeslice-controller-cleanup: ADDED\n    client.go:773: [debug] kubeslice-controller-cleanup: Jobs active: 0, jobs failed: 0, jobs succeeded: 0\n    client.go:734: [debug] Add/Modify event for kubeslice-controller-cleanup: MODIFIED\n    client.go:773: [debug] kubeslice-controller-cleanup: Jobs active: 1, jobs failed: 0, jobs succeeded: 0\n    client.go:734: [debug] Add/Modify event for kubeslice-controller-cleanup: MODIFIED\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-cleanup\" Job\n    uninstall.go:243: [debug] uninstall: given cascade value: , defaulting to delete propagation background\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-prometheus-service\" Service\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-controller-manager-metrics-service\" Service\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-webhook-service\" Service\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-prometheus\" Deployment\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-manager\" Deployment\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-leader-election-rolebinding\" RoleBinding\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-leader-election-role\" Role\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-kube-state-metrics\" ClusterRoleBinding\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-manager-rolebinding\" ClusterRoleBinding\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-ovpn-controller-rolebinding\" ClusterRoleBinding\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-proxy-rolebinding\" ClusterRoleBinding\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-license-job-rolebinding\" ClusterRoleBinding\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-prometheus\" ClusterRoleBinding\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-prometheus\" ClusterRole\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-metrics-reader\" ClusterRole\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-controller-role\" ClusterRole\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-kube-state-metrics\" ClusterRole\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-proxy-role\" ClusterRole\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-ovpn-editor-role\" ClusterRole\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-license-job-role\" ClusterRole\n    client.go:478: [debug] Starting delete for \"slicenodeaffinities.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"projects.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"serviceexportconfigs.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"sliceconfigs.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"clusters.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"workersliceconfigs.worker.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"workerslicegateways.worker.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"workerslicegwrecyclers.worker.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"sliceqosconfigs.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"sliceresourcequotaconfigs.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"slicerolebindings.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"sliceroletemplates.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"workerserviceimports.worker.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"workersliceresourcequotas.worker.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"workerslicenodeaffinities.worker.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"workerslicerolebindings.worker.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-event-schema-conf\" ConfigMap\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-manager-config\" ConfigMap\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-prometheus-server-conf\" ConfigMap\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-license-config\" ConfigMap\n    client.go:478: [debug] Starting delete for \"kubeslice-image-pull-secret\" Secret\n    client.go:478: [debug] Starting delete for \"webhook-server-cert-secret\" Secret\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-license-job-manager\" ServiceAccount\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-controller-manager\" ServiceAccount\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-ovpn-manager\" ServiceAccount\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-mutating-webhook-configuration\" MutatingWebhookConfiguration\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-validating-webhook-configuration\" ValidatingWebhookConfiguration\n    uninstall.go:150: [debug] purge requested for kubeslice-controller\n    Error: release kubeslice-controller failed, and has been uninstalled due to atomic being set: context deadline exceeded\n    helm.go:84: [debug] context deadline exceeded\n    release kubeslice-controller failed, and has been uninstalled due to atomic being set\n    helm.sh/helm/v3/pkg/action.(*Install).failRelease\n    \thelm.sh/helm/v3/pkg/action/install.go:483\n    helm.sh/helm/v3/pkg/action.(*Install).reportToRun\n    \thelm.sh/helm/v3/pkg/action/install.go:467\n    helm.sh/helm/v3/pkg/action.(*Install).performInstall\n    \thelm.sh/helm/v3/pkg/action/install.go:423\n    runtime.goexit\n    \truntime/asm_amd64.s:1598\noccurred","time":{"start":1690377721000,"stop":1690378045280,"duration":324280}},{"uid":"384eb503b78e6fe6","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc0003b8078>: {\n        Underlying: <*exec.ExitError | 0xc000472000>{\n            ProcessState: {\n                pid: 5872,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 7, Usec: 71892},\n                    Stime: {Sec: 0, Usec: 925219},\n                    Maxrss: 111732,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 11068,\n                    Majflt: 124,\n                    Nswap: 0,\n                    Inblock: 18976,\n                    Oublock: 23312,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 73922,\n                    Nivcsw: 32035,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: [\n                    \"Release \\\"kubeslice-controller\\\" does not exist. Installing it now.\",\n                ],\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"history.go:56: [debug] getting history for release kubeslice-controller\",\n                        \"Release \\\"kubeslice-controller\\\" does not exist. Installing it now.\",\n                        \"install.go:200: [debug] Original chart version: \\\"\\\"\",\n                        \"install.go:217: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-controller-1.3.4.tgz\",\n                        \"\",\n                        \"client.go:134: [debug] creating 1 resource(s)\",\n                        \"client.go:134: [debug] creating 47 resource(s)\",\n                        \"wait.go:48: [debug] beginning wait for 47 resources with timeout of 5m0s\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n             ...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; history.go:56: [debug] getting history for release kubeslice-controller\n    install.go:200: [debug] Original chart version: \"\"\n    install.go:217: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-controller-1.3.4.tgz\n    \n    client.go:134: [debug] creating 1 resource(s)\n    client.go:134: [debug] creating 47 resource(s)\n    wait.go:48: [debug] beginning wait for 47 resources with timeout of 5m0s\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    install.go:475: [debug] Install failed and atomic is set, uninstalling release\n    uninstall.go:97: [debug] uninstall: Deleting kubeslice-controller\n    client.go:134: [debug] creating 1 resource(s)\n    client.go:706: [debug] Watching for changes to Job kubeslice-controller-cleanup with timeout of 5m0s\n    client.go:734: [debug] Add/Modify event for kubeslice-controller-cleanup: ADDED\n    client.go:773: [debug] kubeslice-controller-cleanup: Jobs active: 0, jobs failed: 0, jobs succeeded: 0\n    client.go:734: [debug] Add/Modify event for kubeslice-controller-cleanup: MODIFIED\n    client.go:773: [debug] kubeslice-controller-cleanup: Jobs active: 1, jobs failed: 0, jobs succeeded: 0\n    client.go:734: [debug] Add/Modify event for kubeslice-controller-cleanup: MODIFIED\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-cleanup\" Job\n    uninstall.go:243: [debug] uninstall: given cascade value: , defaulting to delete propagation background\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-prometheus-service\" Service\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-controller-manager-metrics-service\" Service\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-webhook-service\" Service\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-prometheus\" Deployment\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-manager\" Deployment\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-leader-election-rolebinding\" RoleBinding\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-leader-election-role\" Role\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-kube-state-metrics\" ClusterRoleBinding\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-manager-rolebinding\" ClusterRoleBinding\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-ovpn-controller-rolebinding\" ClusterRoleBinding\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-proxy-rolebinding\" ClusterRoleBinding\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-license-job-rolebinding\" ClusterRoleBinding\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-prometheus\" ClusterRoleBinding\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-prometheus\" ClusterRole\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-controller-role\" ClusterRole\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-kube-state-metrics\" ClusterRole\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-metrics-reader\" ClusterRole\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-ovpn-editor-role\" ClusterRole\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-proxy-role\" ClusterRole\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-license-job-role\" ClusterRole\n    client.go:478: [debug] Starting delete for \"clusters.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"projects.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"serviceexportconfigs.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"sliceconfigs.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"slicenodeaffinities.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"sliceqosconfigs.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"sliceresourcequotaconfigs.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"slicerolebindings.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"sliceroletemplates.controller.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"workerserviceimports.worker.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"workersliceconfigs.worker.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"workerslicegateways.worker.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"workerslicegwrecyclers.worker.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"workerslicenodeaffinities.worker.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"workersliceresourcequotas.worker.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"workerslicerolebindings.worker.kubeslice.io\" CustomResourceDefinition\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-prometheus-server-conf\" ConfigMap\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-event-schema-conf\" ConfigMap\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-manager-config\" ConfigMap\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-license-config\" ConfigMap\n    client.go:478: [debug] Starting delete for \"kubeslice-image-pull-secret\" Secret\n    client.go:478: [debug] Starting delete for \"webhook-server-cert-secret\" Secret\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-license-job-manager\" ServiceAccount\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-controller-manager\" ServiceAccount\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-ovpn-manager\" ServiceAccount\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-mutating-webhook-configuration\" MutatingWebhookConfiguration\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-validating-webhook-configuration\" ValidatingWebhookConfiguration\n    uninstall.go:150: [debug] purge requested for kubeslice-controller\n    Error: release kubeslice-controller failed, and has been uninstalled due to atomic being set: context deadline exceeded\n    helm.go:84: [debug] context deadline exceeded\n    release kubeslice-controller failed, and has been uninstalled due to atomic being set\n    helm.sh/helm/v3/pkg/action.(*Install).failRelease\n    \thelm.sh/helm/v3/pkg/action/install.go:483\n    helm.sh/helm/v3/pkg/action.(*Install).reportToRun\n    \thelm.sh/helm/v3/pkg/action/install.go:467\n    helm.sh/helm/v3/pkg/action.(*Install).performInstall\n    \thelm.sh/helm/v3/pkg/action/install.go:423\n    runtime.goexit\n    \truntime/asm_amd64.s:1598\noccurred","time":{"start":1690371125000,"stop":1690371443749,"duration":318749}},{"uid":"85e12f821cb61827","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc000496168>: {\n        Underlying: <*exec.ExitError | 0xc0004ac120>{\n            ProcessState: {\n                pid: 5957,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 0, Usec: 54926},\n                    Stime: {Sec: 0, Usec: 11769},\n                    Maxrss: 42128,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 1518,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 8,\n                    Oublock: 0,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 251,\n                    Nivcsw: 200,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"error: error executing jsonpath \\\"\\\\\\\"{.clusters[?(@.name==\\\\\\\"kind-controller\\\\\\\")].cluster.server}\\\\\\\"\\\": Error executing template: <nil> is not array or slice and cannot be filtered. Printing more information for debugging the template:\",\n                        \"\\ttemplate was:\",\n                        \"\\t\\t\\\"{.clusters[?(@.name==\\\"kind-controller\\\")].cluster.server}\\\"\",\n                        \"\\tobject given to jsonpath engine was:\",\n                        \"\\t\\tmap[string]interface {}{\\\"apiVersion\\\":\\\"v1\\\", \\\"clusters\\\":interface {}(nil), \\\"contexts\\\":interface {}(nil), \\\"current-context\\\":\\\"\\\", \\\"kind\\\":\\\"Config\\\", \\\"preferences\\\":map[string]interface {}{}, \\\"users\\\":interface {}(nil)}\",\n                        \"\",\n                        \"\",\n                    ],\n                },\n            },\n            stderr: {\n                Lines: [\n                    \"error: error executing jsonpath \\\"\\\\\\\"{.clusters[?(@.name==\\\\\\\"kind-controller\\\\\\\")].cluster.server}\\\\\\\"\\\": Error executing template: <nil> is not array or slice and cannot be filtered. Printing more information for debugging the template:\",\n                    \"\\ttemplate was:\",\n                    \"\\t\\t\\\"{.clusters[?(@.name==\\\"kind-controller\\\")].cluster.server}\\\"\",\n                    \"\\tobject given to jsonpath engine was:\",\n                    \"\\t\\tmap[string]interface {}{\\\"apiVersion\\\":\\\"v1\\\", \\\"clusters\\\":interface {}(nil), \\\"contexts\\\":interface {}(nil), \\\"current-context\\\":\\\"\\\", \\\"kind\\\":\\\"Config\\\", \\\"preferences\\\":map[string]interface {}{}, \\\"users\\\":interface {}(nil)}\",\n                    \"\",\n                    \"\",\n                ],\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"error: error executing jsonpath \\\"\\\\\\\"{.clusters[?(@.name==\\\\\\\"kind-controller\\\\\\\")].cluster.server}\\\\\\\"\\\": Error executing template: <nil> is not array or slice and cannot be filtered. Printing more information for debugging the template:\",\n                        \"\\ttemplate was:\",\n                        \"\\t\\t\\\"{.clusters[?(@.name==\\\"kind-controller\\\")].cluster.server}\\\"\",\n                        \"\\tobject given to jsonpath engine was:\",\n                        \"\\t\\tmap[string]interface {}{\\\"apiVersion\\\":\\\"v1\\\", \\\"clusters\\\":interface {}(nil), \\\"contexts\\\":interface {}(nil), \\\"current-context\\\":\\\"\\\", \\\"kind\\\":\\\"Config\\\", \\\"preferences\\\":map[string]interface {}{}, \\\"users\\\":interface {}(nil)}\",\n                        \"\",\n                        \"\",\n                    ],\n                },\n            },\n            merged: {\n                Mutex: {state: 0, sema: 0},\n                Lines: [\n                    \"error: error executing jsonpath \\\"\\\\\\\"{.clusters[?(@.name==\\\\\\\"kind-controller\\\\\\\")].cluster.server}\\\\\\\"\\\": Error executing template: <nil> is not array or slice and cannot be filtered. Printing more information for debugging the template:\",\n                    \"\\ttemplate was:\",\n                    \"\\t\\t\\\"{.clusters[?(...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; error: error executing jsonpath \"\\\"{.clusters[?(@.name==\\\"kind-controller\\\")].cluster.server}\\\"\": Error executing template: <nil> is not array or slice and cannot be filtered. Printing more information for debugging the template:\n    \ttemplate was:\n    \t\t\"{.clusters[?(@.name==\"kind-controller\")].cluster.server}\"\n    \tobject given to jsonpath engine was:\n    \t\tmap[string]interface {}{\"apiVersion\":\"v1\", \"clusters\":interface {}(nil), \"contexts\":interface {}(nil), \"current-context\":\"\", \"kind\":\"Config\", \"preferences\":map[string]interface {}{}, \"users\":interface {}(nil)}\n    \n    \noccurred","time":{"start":1689758771000,"stop":1689758771075,"duration":75}},{"uid":"14893ac9a70379c8","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc000463368>: {\n        Underlying: <*exec.ExitError | 0xc0003db720>{\n            ProcessState: {\n                pid: 5944,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 0, Usec: 39703},\n                    Stime: {Sec: 0, Usec: 11911},\n                    Maxrss: 42048,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 2006,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 8,\n                    Oublock: 0,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 222,\n                    Nivcsw: 64,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"error: error executing jsonpath \\\"\\\\\\\"{.clusters[?(@.name==\\\\\\\"kind-controller\\\\\\\")].cluster.server}\\\\\\\"\\\": Error executing template: <nil> is not array or slice and cannot be filtered. Printing more information for debugging the template:\",\n                        \"\\ttemplate was:\",\n                        \"\\t\\t\\\"{.clusters[?(@.name==\\\"kind-controller\\\")].cluster.server}\\\"\",\n                        \"\\tobject given to jsonpath engine was:\",\n                        \"\\t\\tmap[string]interface {}{\\\"apiVersion\\\":\\\"v1\\\", \\\"clusters\\\":interface {}(nil), \\\"contexts\\\":interface {}(nil), \\\"current-context\\\":\\\"\\\", \\\"kind\\\":\\\"Config\\\", \\\"preferences\\\":map[string]interface {}{}, \\\"users\\\":interface {}(nil)}\",\n                        \"\",\n                        \"\",\n                    ],\n                },\n            },\n            stderr: {\n                Lines: [\n                    \"error: error executing jsonpath \\\"\\\\\\\"{.clusters[?(@.name==\\\\\\\"kind-controller\\\\\\\")].cluster.server}\\\\\\\"\\\": Error executing template: <nil> is not array or slice and cannot be filtered. Printing more information for debugging the template:\",\n                    \"\\ttemplate was:\",\n                    \"\\t\\t\\\"{.clusters[?(@.name==\\\"kind-controller\\\")].cluster.server}\\\"\",\n                    \"\\tobject given to jsonpath engine was:\",\n                    \"\\t\\tmap[string]interface {}{\\\"apiVersion\\\":\\\"v1\\\", \\\"clusters\\\":interface {}(nil), \\\"contexts\\\":interface {}(nil), \\\"current-context\\\":\\\"\\\", \\\"kind\\\":\\\"Config\\\", \\\"preferences\\\":map[string]interface {}{}, \\\"users\\\":interface {}(nil)}\",\n                    \"\",\n                    \"\",\n                ],\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"error: error executing jsonpath \\\"\\\\\\\"{.clusters[?(@.name==\\\\\\\"kind-controller\\\\\\\")].cluster.server}\\\\\\\"\\\": Error executing template: <nil> is not array or slice and cannot be filtered. Printing more information for debugging the template:\",\n                        \"\\ttemplate was:\",\n                        \"\\t\\t\\\"{.clusters[?(@.name==\\\"kind-controller\\\")].cluster.server}\\\"\",\n                        \"\\tobject given to jsonpath engine was:\",\n                        \"\\t\\tmap[string]interface {}{\\\"apiVersion\\\":\\\"v1\\\", \\\"clusters\\\":interface {}(nil), \\\"contexts\\\":interface {}(nil), \\\"current-context\\\":\\\"\\\", \\\"kind\\\":\\\"Config\\\", \\\"preferences\\\":map[string]interface {}{}, \\\"users\\\":interface {}(nil)}\",\n                        \"\",\n                        \"\",\n                    ],\n                },\n            },\n            merged: {\n                Mutex: {state: 0, sema: 0},\n                Lines: [\n                    \"error: error executing jsonpath \\\"\\\\\\\"{.clusters[?(@.name==\\\\\\\"kind-controller\\\\\\\")].cluster.server}\\\\\\\"\\\": Error executing template: <nil> is not array or slice and cannot be filtered. Printing more information for debugging the template:\",\n                    \"\\ttemplate was:\",\n                    \"\\t\\t\\\"{.clusters[?(@...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; error: error executing jsonpath \"\\\"{.clusters[?(@.name==\\\"kind-controller\\\")].cluster.server}\\\"\": Error executing template: <nil> is not array or slice and cannot be filtered. Printing more information for debugging the template:\n    \ttemplate was:\n    \t\t\"{.clusters[?(@.name==\"kind-controller\")].cluster.server}\"\n    \tobject given to jsonpath engine was:\n    \t\tmap[string]interface {}{\"apiVersion\":\"v1\", \"clusters\":interface {}(nil), \"contexts\":interface {}(nil), \"current-context\":\"\", \"kind\":\"Config\", \"preferences\":map[string]interface {}{}, \"users\":interface {}(nil)}\n    \n    \noccurred","time":{"start":1689755137000,"stop":1689755137061,"duration":61}}]},"Hub Suite:Hub Suite#[AfterSuite]":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":3,"unknown":0,"total":3},"items":[{"uid":"11d49aa167c5eda3","status":"passed","time":{"start":1689750156000,"stop":1689750457095,"duration":301095}},{"uid":"a882604afc922415","status":"passed","time":{"start":1688626949000,"stop":1688627250054,"duration":301054}},{"uid":"bceb9263bdb76971","status":"passed","time":{"start":1688022039000,"stop":1688022041714,"duration":2714}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - namespace.DefaultLimitPerContainer.Mem > namespace.Limit.Mem":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"fe44ac7d5cfe6ae3","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Cluster auto deregister validation tests Cluster auto deregister Creates cluster secrets":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"ea0e3430c423df0d","status":"passed","time":{"start":1688022039000,"stop":1688022165816,"duration":126816}}]},"Hub Suite:Hub Suite#[It] Cluster CR tests Cluster CR validation Creates cluster secrets":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"69cbafba9535dfd1","status":"passed","time":{"start":1688022039000,"stop":1688022042600,"duration":3600}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests RBAC Common Tests SliceRoleBinding status test: SliceRoleBinding should have empty status for successful WorkerSliceRoleBinding generation":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"ef9765649b54f383","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Project CR test Project Creation Should fail while creating Project with  project name as blank":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"2a9831abbaf03a03","status":"passed","time":{"start":1688022039000,"stop":1688022039236,"duration":236}}]},"Hub Suite:Hub Suite#[It] Project CR test Project Update Should Update successfully when Project is Applied with valid service account name in Read users":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"16b1ec889e7da2cd","status":"passed","time":{"start":1688022039000,"stop":1688022047393,"duration":8393}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - slice.limit.podcount > sum(namespace.limit.podcount)":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"91252f787e7d04a9","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] E2E tests for license job > when Controller is upgraded license mode = auto apply helm upgrade":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"b45d5d6515e69def","status":"passed","time":{"start":1693828311000,"stop":1693828528773,"duration":217773}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test- Request.EphemeralStorage > Limit.EphemeralStorage at namespace level":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"948508453739b119","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Project and Cluster Events Test Events get recorded for project creation and deletion Events get recorded for project creation Validating events for role binding creation":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"e4e20991e629a9eb","status":"passed","time":{"start":1688022039000,"stop":1688022045250,"duration":6250}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test-cluster.limit.cpu negative":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"e8c20c79fa3f996f","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - namespace.DefaultRequestPerContainer.Mem > namespace.Request.Mem":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"384427dd993b0daa","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Cluster negative tests Worker Cluster Registration with Wrong token":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"46630b4f5c462de0","status":"passed","time":{"start":1688022039000,"stop":1688022040359,"duration":1359}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests SliceRoleBinding Tests Create SliceRoleBinding failure test: Creating SliceRoleBinding slice-red with invalid subject kind":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"270b283585ca99f7","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Project and Cluster Events Test Events get recorded for cluster creation and deletion Events get recorded for cluster creation Validating events for cluster service account secret creation":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"ec16e01047a2bf56","status":"passed","time":{"start":1688022039000,"stop":1688022039077,"duration":77}}]},"Controller Suite:Controller Suite#[It] E2E tests for license job > when controller is installed with default options Kubeslice license configuration should exist":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"6128cca6e333c3d7","status":"passed","time":{"start":1693828311000,"stop":1693828315233,"duration":4233}}]},"Hub Suite:Hub Suite#[It] Cluster CR tests Cluster CR validation Verify NodeIPs are updated in cluster CR after worker installation":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"2fbf708ee1369e53","status":"passed","time":{"start":1688022039000,"stop":1688022683620,"duration":644620}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests SliceRoleBinding Tests Create SliceRoleBinding failure test: Creating SliceRoleBinding slice-red with empty subject name":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"f0bce53aea0e8534","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Project and Cluster Events Test Events get recorded for cluster creation and deletion Events get recorded for cluster deletion Validating events for cluster role binding deletion":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"722939c78fbaeb3","status":"passed","time":{"start":1688022039000,"stop":1688022043255,"duration":4255}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - namespace.DefaultLimitPerContainer.CPU is negative":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"84fbd4a98af9a42f","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests RBAC Common Tests WorkerSliceRoleBinding generation test: Creation of SliceRoleBinding with custom roles and k8s roles should generate two WorkerSliceRoleBindings":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"f454019a45eb7eb7","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"SliceHealth Suite:SliceHealth Suite#[It] Slice Health Check tests Test Slice Health Check Should have slice egress unavailable when egress is unavailable":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"d7f680e6614d9a1d","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1688026084000,"stop":1688026084000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - sum(namespace.limit.cpu) > cluster.cpu":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"5247ef14714c43d8","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - namespace.DefaultRequestPerContainer.Memory is negative":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"a107f6e0e282f2fc","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - No provision of defaultRequestPerContainer for the slice":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"343e3df51932c7ca","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Cluster negative tests Worker Cluster Registration with Wrong ca.cert":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"d2046d516febc28d","status":"passed","time":{"start":1688022039000,"stop":1688022040200,"duration":1200}}]},"Controller Suite:Controller Suite#[It] E2E tests for license job > when Controller is upgraded license mode = auto Should eventually create new controller pod":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"eebe107f9a7bc363","status":"passed","time":{"start":1693828311000,"stop":1693828311799,"duration":799}}]},"Hub Suite:Hub Suite#[It] Project CR test Project Creation Should fail while creating Project with project name as combination of special characters":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"96b3318a8936baad","status":"passed","time":{"start":1688022039000,"stop":1688022039250,"duration":250}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests RBAC Common Tests WorkerSliceRoleBinding data propagation test: Checking successful creation of labels":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"55c1166e32b7d9e1","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Validate License Tests License Validate tests should update the license to expired and grace period also expired and fail CRUD":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"8bff13c3d03b4e78","status":"passed","time":{"start":1693828311000,"stop":1693828314657,"duration":3657}}]},"Controller Suite:Controller Suite#[It] E2E tests for license job > when Controller is upgraded license mode = auto should launch a `job` for fetching license data":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"5c3152c3886ce9f7","status":"passed","time":{"start":1693828311000,"stop":1693828426761,"duration":115761}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test- Request.CPU > Limit.CPU at slice level":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"f61c72dc3f9f9540","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice node affinity Tests SliceNodeAffinity tests - includes creation and deletion slice node affinity creation -failed case if clusters are repeated":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"713efc1f3b412e70","status":"passed","time":{"start":1693828311000,"stop":1693828321416,"duration":10416}}]},"Intracluster Suite:Intracluster Suite#[AfterSuite]":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":3,"unknown":0,"total":3},"items":[{"uid":"2cb9a9f4c124fa69","status":"passed","time":{"start":1689751062000,"stop":1689751362625,"duration":300625}},{"uid":"3e6772abec027ef8","status":"passed","time":{"start":1688627854000,"stop":1688628154532,"duration":300532}},{"uid":"98e58dbfa523cd34","status":"passed","time":{"start":1688025155000,"stop":1688025787097,"duration":632097}}]},"Hub Suite:Hub Suite#[It] Project and Cluster Events Test Events get recorded for cluster creation and deletion Events get recorded for cluster deletion Validating events for cluster service account deletion":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"55a0a54c49bfec58","status":"passed","time":{"start":1688022039000,"stop":1688022039065,"duration":65}}]},"Controller Suite:Controller Suite#[It] Slice node affinity Tests SliceNodeAffinity tests - includes creation and deletion slice node affinity creation -failed case if namespace is not among the application namespaces for the respective cluster":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"a1159f9e16531b9a","status":"passed","time":{"start":1693828311000,"stop":1693828315186,"duration":4186}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests SliceRoleTemplate Tests Delete SliceRoleTemplate failure test: Deleting SliceRoleTempalate read-only-role participating in a SliceRoleBinding":{"statistic":{"failed":1,"broken":0,"skipped":0,"passed":0,"unknown":0,"total":1},"items":[{"uid":"b07869b300245a50","status":"failed","statusDetails":"Timed out after 30.304s.\nUnexpected error:\n    <*json.SyntaxError | 0xc0009067c8>: {\n        msg: \"invalid character 'E' looking for beginning of value\",\n        Offset: 1,\n    }\n    invalid character 'E' looking for beginning of value\noccurred","time":{"start":1693828311000,"stop":1693828410017,"duration":99017}}]},"Hub Suite:Hub Suite#[It] Project CR test Project Update Should fail when Project is Applied with service account name as blank in Read users":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"9fcdc3beeff34617","status":"passed","time":{"start":1688022039000,"stop":1688022043868,"duration":4868}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - namespace.DefaultLimitPerContainer.CPU > namespace.Request.CPU":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"5ce076d0b9b2a220","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - sum(cluster.request.mem) > slice.mem":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"84669de7fd92638a","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Intracluster Suite:Intracluster Suite#[It] Intracluster slice tests Slice with netpol should remove network policy resource from application namespace once the isolationEnabled is set to false":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"7bdf9383408e6153","status":"passed","time":{"start":1688025155000,"stop":1688025164148,"duration":9148}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - sum(namespace.request.cpu) > cluster.cpu":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"c4cb384b78d771b7","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] E2E tests for license job > when controller is installed with default options should evntually create license secret":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"375a1e7c8756bb19","status":"passed","time":{"start":1693828311000,"stop":1693828315873,"duration":4873}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests SliceRoleBinding Tests Create SliceRoleBinding failure test: Creating SliceRoleBinding slice-red with unsupported K8s Role":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"cf0bdf0583af2a5c","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests RBAC Common Tests SliceRoleBinding status test: SliceRoleBinding should have error status for role-ref not found":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"4a98a7840f9accb3","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Intracluster Suite:Intracluster Suite#[It] Intracluster slice tests Slice with netpol should reconcile netpol config":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"961fc174052b2654","status":"passed","time":{"start":1688025155000,"stop":1688025155205,"duration":205}}]},"Controller Suite:Controller Suite#[It] Events Test Events get recorded for slice role binding creation and deletion Events get recorded for slice role binding creation Validating events for worker slice role bindings creation":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"89808ecac04e1293","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Events Test Events get recorded for slice config creation Validating events for slice resource quota config creation":{"statistic":{"failed":1,"broken":0,"skipped":0,"passed":0,"unknown":0,"total":1},"items":[{"uid":"ea71192651769640","status":"failed","statusDetails":"Timed out after 41.604s.\nExpected\n    <bool>: false\nto be true","time":{"start":1693828311000,"stop":1693828443533,"duration":132533}}]},"Controller Suite:Controller Suite#[It] Slice node affinity Tests SliceNodeAffinity tests - includes creation and deletion slice node affinity creation -failed case if wild card * for application namespaces is repeated":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"32348490f79b6c87","status":"passed","time":{"start":1693828311000,"stop":1693828321433,"duration":10433}}]},"Controller Suite:Controller Suite#[It] Events Test Events get recorded for slice role template deletion Events get recorded for slice role template Validating events for slice role template deletion":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"2c055676217f7227","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Cluster health check tests Cluster health check - without istio should contain node IP & cni subnet status information":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"a9b7672b02dc4b87","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1688022039000,"stop":1688022039000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test- Request.EphemeralStorage > Limit.EphemeralStorage at cluster level":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"70e7e0b54b42741f","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Project CR test Project Creation Should create Project while using valid manifest":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"2d64d088b0950f1f","status":"passed","time":{"start":1688022039000,"stop":1688022047590,"duration":8590}}]},"SliceHealth Suite:SliceHealth Suite#[It] Slice Health Check tests Test Slice Health Check Should have slicegateway in Error state when both slicegateways are unavailable":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"e1872fd168cbec5a","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1688026084000,"stop":1688026084000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Events Test Events get recorded for slice config creation Validating events for setting slice config as owner of slice resource quota":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"4f4a2f342873ddf0","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice node affinity Tests SliceNodeAffinity tests - includes creation and deletion slice node affinity creation -failed case if cluster is not participating in given slice":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"e1e1c28f0a292643","status":"passed","time":{"start":1693828311000,"stop":1693828320451,"duration":9451}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests ResourceQuota should be created once SliceConfig gets created":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"14cf0243475ed3f1","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice node affinity Tests SliceNodeAffinity tests - includes creation and deletion slice node affinity creation -failed case if application namespaces are repeated":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"6dd744cfb286dbc2","status":"passed","time":{"start":1693828311000,"stop":1693828323228,"duration":12228}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test-namespace.limit.cpu negative":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"14fa6d7b137763fa","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - namespace.DefaultLimitPerContainer.Mem > namespace.Request.Mem":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"1d3f5f8c06a3dff","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests RBAC Common Tests SliceRoleBinding status test: SliceRoleBinding should have error status for invalid namespace and invalid roles":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"ca9f2c898ac37111","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - slice.limit.CPU negative  ":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"526dd8c43ebd28be","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - sum(namespace.limit.cpu) > slice.cpu":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"1643f1e5b1cdbeda","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Project and Cluster Events Test Events get recorded for project creation and deletion Events get recorded for project deletion Validating events for project deletion":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"ff2582d0c39b16eb","status":"passed","time":{"start":1688022039000,"stop":1688022043472,"duration":4472}}]},"SliceHealth Suite:SliceHealth Suite#[It] Verify gw redundancy wrt health check when both gateways are down should have gw in error state":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"6fc4174623ac6d9c","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1688026084000,"stop":1688026084000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Project and Cluster Events Test Events get recorded for cluster creation and deletion Events get recorded for cluster creation Validating events for cluster role binding creation":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"7e6fbb774b4090f5","status":"passed","time":{"start":1688022039000,"stop":1688022043461,"duration":4461}}]},"Controller Suite:Controller Suite#[It] Slice node affinity Tests SliceNodeAffinity tests - includes creation and deletion slice node affinity creation -failed case if node selctor label is not among - In, NotIn, Exists, DoesNotExist, Gt and Lt.":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"417522b485a8e668","status":"passed","time":{"start":1693828311000,"stop":1693828322276,"duration":11276}}]},"Controller Suite:Controller Suite#[It] E2E tests for license job > when controller is installed with default options should trigger a job":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"e6ce67fcdd04f62b","status":"passed","time":{"start":1693828311000,"stop":1693828317455,"duration":6455}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - sum(cluster.limit.podcount) > slice.podcount":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"f8e89b9f87d0f951","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Project and Cluster Events Test Events get recorded for project creation and deletion Events get recorded for project creation Validating events for namespace creation":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"2e9abc5384f69bc7","status":"passed","time":{"start":1688022039000,"stop":1688022040287,"duration":1287}}]},"Controller Suite:Controller Suite#[It] Validate License Tests License Validate tests Should revert back the fields in secret,in case someone tampered":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"66a2018d4e8853bf","status":"passed","time":{"start":1693828311000,"stop":1693828323265,"duration":12265}}]},"SliceHealth Suite:SliceHealth Suite#[It] Verify gw redundancy wrt health check when slice is installed should eventually have slicehealth status normal":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"e2272610a02e3389","status":"passed","time":{"start":1688026084000,"stop":1688026206536,"duration":122536}}]},"Controller Suite:Controller Suite#[It] Events Test Events get recorded for slice node affinity creation and deletion Events get recorded for slice node affinity deletion Validating events for worker slice node affinities deletion":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"7257dcce86dfcd46","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Project and Cluster Events Test Events get recorded for project creation and deletion Events get recorded for project creation Validating events for cluster role creation":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"f776d2c86c0d0f74","status":"passed","time":{"start":1688022039000,"stop":1688022039075,"duration":75}}]},"Controller Suite:Controller Suite#[It] Events Test Events get recorded for slice role binding creation and deletion Events get recorded for slice role binding creation Validating events for setting slice config as owner of slice role binding":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"96845eb732ce62ad","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests RBAC Common Tests WorkerSliceRoleBinding generation test: WorkerSliceRoleBinding with custom role should be generated automatically when forcefully deleted":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"141e6bb6c75c7461","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - sum(namespace.limit.mem) > cluster.mem":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"5e60796835100ede","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests SliceRoleBinding Tests Create SliceRoleBinding failure test: Creating SliceRoleBinding slice-red with empty RoleRef Name":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"984a69b51aff008f","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests SliceRoleBinding Tests Create SliceRoleBinding failure test: Creating SliceRoleBinding slice-red with empty subject":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"de95dee3e865ffa3","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Project and Cluster Events Test Events get recorded for project creation and deletion Events get recorded for project deletion Validating events for namespace deletion":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"f5edc60a22f99f6d","status":"passed","time":{"start":1688022039000,"stop":1688022039066,"duration":66}}]},"Intracluster Suite:Intracluster Suite#[It] Intracluster slice tests Iperf connectivity Verify Iperf traffic":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"7f4c01e3b8611ef1","status":"passed","time":{"start":1688025155000,"stop":1688025223538,"duration":68538}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test-cluster.limit.mem negative":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"61f31b3e095ee79e","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - cluster.limit.podcount > sum(namespace.limit.podcount)":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"25395bea57958267","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Project and Cluster Events Test Events get recorded for project creation and deletion Events get recorded for project creation Validating events for role creation":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"edeac29fbdf55e7f","status":"passed","time":{"start":1688022039000,"stop":1688022039128,"duration":128}}]},"Controller Suite:Controller Suite#[It] Events Test Events get recorded for slice node affinity creation and deletion Events get recorded for slice node affinity deletion Validating events for slice node affinity deletion":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"36c25b0df47ec152","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests SliceRoleBinding Tests Create SliceRoleBinding successful test: Creating SliceRoleBinding slice-red with Kubernetes Roles":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"2cca47ea298a2683","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests SliceRoleBinding Tests Create SliceRoleBinding failure test: Creating SliceRoleBinding slice-red with invalid ApiVersion in Role":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"d1f1f2eed57beef6","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"ee0b519660c1149c","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Project CR test Project Creation Should create Multiple Projects in controller using valid manifest":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"d5ab998bd8be6bac","status":"passed","time":{"start":1688022039000,"stop":1688022046883,"duration":7883}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - sum(namespace.request.EphemeralStorage) > slice.request.EphemeralStorage":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"5632863f520105fa","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] E2E tests for license job > when Controller is upgraded license mode = manual should not launch a new license job":{"statistic":{"failed":1,"broken":0,"skipped":0,"passed":0,"unknown":0,"total":1},"items":[{"uid":"4fc1e94988e259b0","status":"failed","statusDetails":"Timed out after 200.002s.\nExpected\n    <int>: 1\nto be zero-valued","time":{"start":1693828311000,"stop":1693828669599,"duration":358599}}]},"Controller Suite:Controller Suite#[It] Slice node affinity Tests SliceNodeAffinity tests - includes creation and deletion slice node affinity creation -failed case if owner sliceconfig is not present":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"4cbf97ff1ade5a62","status":"passed","time":{"start":1693828311000,"stop":1693828314605,"duration":3605}}]},"Intracluster Suite:Intracluster Suite#[It] Intracluster slice tests Slice with netpol should reconcile netpol in app NS":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"67fdae79f6020848","status":"passed","time":{"start":1688025155000,"stop":1688025155138,"duration":138}}]},"Hub Suite:Hub Suite#[It] Project CR test Project Deletion Should Delete an existing project successfully":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"c185478d50b7a6cd","status":"passed","time":{"start":1688022039000,"stop":1688022043737,"duration":4737}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests RBAC Common Tests WorkerSliceRoleBinding generation test: Creation of SliceRoleBinding with k8s roles should generate WorkerSliceRoleBinding":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"297160d379ae3c9b","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Worker Suite:Worker Suite#[AfterSuite]":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"504dbb660704473e","status":"passed","time":{"start":1688018439000,"stop":1688018439339,"duration":339}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - namespace.DefaultRequestPerContainer.ES is negative":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"5a420b21dda49689","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"SliceHealth Suite:SliceHealth Suite#[It] Verify gw redundancy wrt health check when both gateways are down should have tunnel status in error state":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"b0b095a62705926c","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1688026084000,"stop":1688026084000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - sum(cluster.limit.CPU) > slice.CPU":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"23bab09d1e2799a4","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"SliceHealth Suite:SliceHealth Suite#[It] Verify gw redundancy wrt health check when atleast one gateway is down should have gw health in warning state":{"statistic":{"failed":1,"broken":0,"skipped":0,"passed":0,"unknown":0,"total":1},"items":[{"uid":"2bfefdbdf57455f6","status":"failed","statusDetails":"Timed out after 720.005s.\nExpected\n    <bool>: false\nto be true","time":{"start":1688026084000,"stop":1688026807757,"duration":723757}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - namespace.DefaultLimitPerContainer.EphemeralStorage > namespace.Limit.EphemeralStorage":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"6a9d56b0616e55b8","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"SliceHealth Suite:SliceHealth Suite#[It] Verify gw redundancy wrt health check when both gateways are up should have gw in normal state":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"17abb4d4e3be499e","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1688026084000,"stop":1688026084000,"duration":0}}]},"SliceHealth Suite:SliceHealth Suite#[It] Verify gw redundancy wrt health check when both gateways are up should have tunnel status in normal state":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"ec999425d007f8f1","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1688026084000,"stop":1688026084000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test- Request.Mem > Limit.Mem at cluster level":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"562f2a3b10b1c9c9","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests SliceRoleBinding Tests Create SliceRoleBinding successful test: Checking Owner Reference set to SliceConfig":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"6a355641d87da0a8","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Project and Cluster Events Test Events get recorded for cluster creation and deletion Events get recorded for cluster deletion Validating events for cluster deletion":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"1d961e876d295d6a","status":"passed","time":{"start":1688022039000,"stop":1688022040711,"duration":1711}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - sum(namespace.request.mem) > slice.mem":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"19e9d49cf848d37c","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests SliceRoleTemplate Tests Create SliceRoleTempalate failure test: Creating SliceRoleTempalate read-only-role, missing apiGroups field":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"c63181013188cf8f","status":"passed","time":{"start":1693828311000,"stop":1693828317889,"duration":6889}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests SliceRoleBinding Tests Create SliceRoleBinding failure test: Creating SliceRoleBinding slice-red with invalid RoleRef Name":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"9800d3e812341212","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - sum(namespace.request.mem) > cluster.mem":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"b091501ac9525a0d","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - namespace.DefaultRequestPerContainer.CPU > namespace.Request.CPU":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"16ff371d3a8d2406","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] E2E tests for license job > when Controller is upgraded license mode = manual apply helm upgrade":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"3073219b362bf503","status":"passed","time":{"start":1693828311000,"stop":1693828427732,"duration":116732}}]},"Hub Suite:Hub Suite#[It] Project and Cluster Events Test Events get recorded for cluster creation and deletion Events get recorded for cluster creation Validating events for cluster service account creation":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"d078a813a0ab6580","status":"passed","time":{"start":1688022039000,"stop":1688022040519,"duration":1519}}]},"Intracluster Suite:Intracluster Suite#[It] Intracluster slice tests Iperf connectivity Verify Connectivity between iperf-server and iperf-client":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"2fe1a9b41bfc6310","status":"passed","time":{"start":1688025155000,"stop":1688025161670,"duration":6670}}]},"SliceHealth Suite:SliceHealth Suite#[AfterSuite]":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":4,"unknown":0,"total":4},"items":[{"uid":"e2c5662393ec82b2","status":"passed","time":{"start":1689751363000,"stop":1689751663695,"duration":300695}},{"uid":"1b5884fae2692ec5","status":"passed","time":{"start":1688628155000,"stop":1688628455676,"duration":300676}},{"uid":"11093e3bbac876a3","status":"passed","time":{"start":1688026084000,"stop":1688027359364,"duration":1275364}},{"uid":"64d1f57a0920b48d","status":"passed","time":{"start":1688018435000,"stop":1688018435448,"duration":448}}]},"Hub Suite:Hub Suite#[It] Project and Cluster Events Test Events get recorded for project creation and deletion Events get recorded for project creation Validating events for service account creation":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"84eceefdc700e89d","status":"passed","time":{"start":1688022039000,"stop":1688022039075,"duration":75}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests SliceRoleBinding Tests Create SliceRoleBinding failure test: Creating SliceRoleBinding slice-red with invalid subject name":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"1ca999ae3f621575","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - sum(cluster.limit.mem) > slice.mem":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"9b4dab4627e1cd7d","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota successful test":{"statistic":{"failed":1,"broken":0,"skipped":0,"passed":0,"unknown":0,"total":1},"items":[{"uid":"ec22768c66be932f","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc000906018>: {\n        Underlying: <*exec.ExitError | 0xc000622040>{\n            ProcessState: {\n                pid: 6553,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 0, Usec: 419542},\n                    Stime: {Sec: 0, Usec: 183073},\n                    Maxrss: 118684,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 6549,\n                    Majflt: 172,\n                    Nswap: 0,\n                    Inblock: 30728,\n                    Oublock: 20624,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 1893,\n                    Nivcsw: 2810,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"Error from server (InternalError): error when creating \\\"/tmp/Slice%20resource%20quota%20Tests%20ResourceQuota%20creation%20tests%20Create%20ResourceQuota%20successful%20test877885790\\\": Internal error occurred: failed calling webhook \\\"msliceconfig.kb.io\\\": failed to call webhook: Post \\\"https://kubeslice-controller-webhook-service.kubeslice-controller.svc:443/mutate-controller-kubeslice-io-v1alpha1-sliceconfig?timeout=10s\\\": dial tcp 10.96.60.138:443: connect: connection refused\",\n                    ],\n                },\n            },\n            stderr: {\n                Lines: [\n                    \"Error from server (InternalError): error when creating \\\"/tmp/Slice%20resource%20quota%20Tests%20ResourceQuota%20creation%20tests%20Create%20ResourceQuota%20successful%20test877885790\\\": Internal error occurred: failed calling webhook \\\"msliceconfig.kb.io\\\": failed to call webhook: Post \\\"https://kubeslice-controller-webhook-service.kubeslice-controller.svc:443/mutate-controller-kubeslice-io-v1alpha1-sliceconfig?timeout=10s\\\": dial tcp 10.96.60.138:443: connect: connection refused\",\n                ],\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"Error from server (InternalError): error when creating \\\"/tmp/Slice%20resource%20quota%20Tests%20ResourceQuota%20creation%20tests%20Create%20ResourceQuota%20successful%20test877885790\\\": Internal error occurred: failed calling webhook \\\"msliceconfig.kb.io\\\": failed to call webhook: Post \\\"https://kubeslice-controller-webhook-service.kubeslice-controller.svc:443/mutate-controller-kubeslice-io-v1alpha1-sliceconfig?timeout=10s\\\": dial tcp 10.96.60.138:443: connect: connection refused\",\n                    ],\n                },\n            },\n            merged: {\n                Mutex: {state: 0, sema: 0},\n                Lines: [\n                    \"Error from server (InternalError): error when creating \\\"/tmp/Slice%20resource%20quota%20Tests%20ResourceQuota%20creation%20tests%20Create%20ResourceQuota%20successful%20test877885790\\\": Internal error occurred: failed calling webhook \\\"msliceconfig.kb.io\\\": failed to call webhook: Post \\\"https://kubeslice-controller-webhook-service.kubeslice-controller.svc:443/mutate-controller-kubeslice-io-v1alpha1-sliceconfig?timeout=10s\\\": dial tcp 10.96.60.138:443: connect: connection refused\",\n                ],\n            },\n        },\n    }\n    error while running command: exit status 1; Error from server (InternalError): error when creating \"/tmp/Slice%20resource%20quota%20Tests%20ResourceQuota%20creation%20tests%20Create%20ResourceQuota%20successful%20test877885790\": Internal error occurred: failed calling webhook \"msliceconfig.kb.io\": failed to call webhook: Post \"https://kubeslice-controller-webhook-service.kubeslice-controller.svc:443/mutate-controller-kubeslice-io-v1alpha1-sliceconfig?timeout=10s\": dial tcp 10.96.60.138:443: connect: connection refused\noccurred","time":{"start":1693828311000,"stop":1693828321536,"duration":10536}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - namespace.DefaultLimitPerContainer.ES is negative":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"4e83ad1d80fa79ae","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Events Test Events get recorded for slice resource quota deletion Validating events for worker slice resource quota creation":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"83a566b0227f29ee","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Events Test Events get recorded for slice resource quota deletion Validating events for setting slice config as owner of slice resource quota":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"3a20d0800047d05c","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Validate License Tests License Validate tests Should have license secret installed":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"4e75dc0af4f8be4e","status":"passed","time":{"start":1693828311000,"stop":1693828311318,"duration":318}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - slice.DefaultRequestPerContainer.EphemeralStorage > slice.Request.EphemeralStorage":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"6d249dc5ac7fbcd3","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests RBAC Common Tests WorkerSliceRoleBinding data propagation test: Checking successful propagation of rules":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"b6fce01440b2b894","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests SliceRoleBinding Tests Create SliceRoleBinding failure test: Creating SliceRoleBinding slice-red with duplicate SliceRoleTemplate":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"1ce18ea7cd9734c1","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - namespace.DefaultLimitPerContainer.CPU > namespace.Limit.CPU":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"702b280213db5a3f","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test- Request.CPU > Limit.CPU at cluster level":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"289d41c731b78ba","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Intracluster Suite:Intracluster Suite#[It] Intracluster slice tests Slice with netpol should have vl3 router running":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"5abd7a6e040f698d","status":"passed","time":{"start":1688025155000,"stop":1688025160301,"duration":5301}}]},"Controller Suite:Controller Suite#[It] E2E tests for license job > when Controller is upgraded license mode = manual Should not create a new secret":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"3a44bac29ea7243","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"SliceHealth Suite:SliceHealth Suite#[It] Slice Health Check tests Test Slice Health Check Should not have slice ingress status when ingress is unavailable":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"56d2f5707dae7974","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1688026084000,"stop":1688026084000,"duration":0}}]},"Hub Suite:Hub Suite#[BeforeSuite]":{"statistic":{"failed":2,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":3},"items":[{"uid":"e772e0f7ef6c311","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc000498528>: {\n        Underlying: <*exec.ExitError | 0xc000116000>{\n            ProcessState: {\n                pid: 6165,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 3, Usec: 965017},\n                    Stime: {Sec: 0, Usec: 692834},\n                    Maxrss: 93440,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 8942,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 2248,\n                    Oublock: 17384,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 43008,\n                    Nivcsw: 13396,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"install.go:200: [debug] Original chart version: \\\"\\\"\",\n                        \"install.go:217: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-controller-1.2.0.tgz\",\n                        \"\",\n                        \"client.go:134: [debug] creating 1 resource(s)\",\n                        \"client.go:134: [debug] creating 29 resource(s)\",\n                        \"wait.go:48: [debug] beginning wait for 29 resources with timeout of 5m0s\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                    ...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    install.go:200: [debug] Original chart version: \"\"\n    install.go:217: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-controller-1.2.0.tgz\n    \n    client.go:134: [debug] creating 1 resource(s)\n    client.go:134: [debug] creating 29 resource(s)\n    wait.go:48: [debug] beginning wait for 29 resources with timeout of 5m0s\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    install.go:470: [debug] Install failed and atomic is set, uninstalling release\n    uninstall.go:97: [debug] uninstall: Deleting kubeslice-controller\n    client.go:134: [debug] creating 1 resource(s)\n    client.go:706: [debug] Watching for changes to Job kubeslice-controller-cleanup with timeout of 5m0s\n    client.go:734: [debug] Add/Modify event for kubeslice-controller-cleanup: ADDED\n    client.go:773: [debug] kubeslice-controller-cleanup: Jobs active: 0, jobs failed: 0, jobs succeeded: 0\n    client.go:734: [debug] Add/Modify event for kubeslice-controller-cleanup: MODIFIED\n    client.go:773: [debug] kubeslice-controller-cleanup: Jobs active: 1, jobs failed: 0, jobs succeeded: 0\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-cleanup\" Job\n    Error: INSTALLATION FAILED: an error occurred while uninstalling the release. original install error: context deadline exceeded: 1 error occurred:\n    \t* timed out waiting for the condition\n    \n    \n    helm.go:84: [debug] 1 error occurred:\n    \t* timed out waiting for the condition\n    \n    \n    an error occurred while uninstalling the release. original install error: context deadline exceeded\n    helm.sh/helm/v3/pkg/action.(*Install).failRelease\n    \thelm.sh/helm/v3/pkg/action/install.go:476\n    helm.sh/helm/v3/pkg/action.(*Install).reportToRun\n    \thelm.sh/helm/v3/pkg/action/install.go:462\n    helm.sh/helm/v3/pkg/action.(*Install).performInstall\n    \thelm.sh/helm/v3/pkg/action/install.go:418\n    runtime.goexit\n    \truntime/asm_amd64.s:1598\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:147\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:916\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:1044\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:968\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1598\noccurred","time":{"start":1689750156000,"stop":1689750760905,"duration":604905}},{"uid":"e6c71bdd9c8771fa","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc0004a4060>: {\n        Underlying: <*exec.ExitError | 0xc000078020>{\n            ProcessState: {\n                pid: 6147,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 3, Usec: 485829},\n                    Stime: {Sec: 0, Usec: 501499},\n                    Maxrss: 82224,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 5270,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 1088,\n                    Oublock: 11584,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 41386,\n                    Nivcsw: 11774,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"install.go:200: [debug] Original chart version: \\\"\\\"\",\n                        \"install.go:217: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-controller-1.2.0.tgz\",\n                        \"\",\n                        \"client.go:134: [debug] creating 1 resource(s)\",\n                        \"client.go:134: [debug] creating 29 resource(s)\",\n                        \"wait.go:48: [debug] beginning wait for 29 resources with timeout of 5m0s\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\",\n                    ...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    install.go:200: [debug] Original chart version: \"\"\n    install.go:217: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-controller-1.2.0.tgz\n    \n    client.go:134: [debug] creating 1 resource(s)\n    client.go:134: [debug] creating 29 resource(s)\n    wait.go:48: [debug] beginning wait for 29 resources with timeout of 5m0s\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: kubeslice-controller/kubeslice-controller-manager. 0 out of 1 expected pods are ready\n    install.go:470: [debug] Install failed and atomic is set, uninstalling release\n    uninstall.go:97: [debug] uninstall: Deleting kubeslice-controller\n    client.go:134: [debug] creating 1 resource(s)\n    client.go:706: [debug] Watching for changes to Job kubeslice-controller-cleanup with timeout of 5m0s\n    client.go:734: [debug] Add/Modify event for kubeslice-controller-cleanup: ADDED\n    client.go:773: [debug] kubeslice-controller-cleanup: Jobs active: 0, jobs failed: 0, jobs succeeded: 0\n    client.go:734: [debug] Add/Modify event for kubeslice-controller-cleanup: MODIFIED\n    client.go:773: [debug] kubeslice-controller-cleanup: Jobs active: 1, jobs failed: 0, jobs succeeded: 0\n    client.go:478: [debug] Starting delete for \"kubeslice-controller-cleanup\" Job\n    Error: INSTALLATION FAILED: an error occurred while uninstalling the release. original install error: context deadline exceeded: 1 error occurred:\n    \t* timed out waiting for the condition\n    \n    \n    helm.go:84: [debug] 1 error occurred:\n    \t* timed out waiting for the condition\n    \n    \n    an error occurred while uninstalling the release. original install error: context deadline exceeded\n    helm.sh/helm/v3/pkg/action.(*Install).failRelease\n    \thelm.sh/helm/v3/pkg/action/install.go:476\n    helm.sh/helm/v3/pkg/action.(*Install).reportToRun\n    \thelm.sh/helm/v3/pkg/action/install.go:462\n    helm.sh/helm/v3/pkg/action.(*Install).performInstall\n    \thelm.sh/helm/v3/pkg/action/install.go:418\n    runtime.goexit\n    \truntime/asm_amd64.s:1598\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:147\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:916\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:1044\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:968\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1598\noccurred","time":{"start":1688626949000,"stop":1688627552804,"duration":603804}},{"uid":"5948718af3daf0e9","status":"passed","time":{"start":1688022039000,"stop":1688022053084,"duration":14084}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - not applied in project namespace  ":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"579a6f075e86498b","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - slice.limit.mem negative  ":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"52ee4d5ba1e8facd","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Events Test Events get recorded for slice node affinity creation and deletion Events get recorded for slice node affinity creation Validating events for setting slice config as owner of slice node affinity":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"d670052518a9215","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Cluster health check tests Cluster health check - without istio Has health status normal":{"statistic":{"failed":1,"broken":0,"skipped":0,"passed":0,"unknown":0,"total":1},"items":[{"uid":"b0c3eea5e4f82850","status":"failed","statusDetails":"Timed out after 120.000s.\nExpected\n    <bool>: false\nto be true","time":{"start":1688022039000,"stop":1688022812843,"duration":773843}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests SliceRoleBinding Tests Create SliceRoleBinding failure test: Creating SliceRoleBinding slice-red with duplicate Kubernetes Roles":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"f49a4063943b0c22","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - namespace.DefaultRequestPerContainer.EphemeralStorage > namespace.Request.EphemeralStorage":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"5199fb2a2ebcffb","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests SliceRoleBinding Tests Create SliceRoleBinding successful test: Creating SliceRoleBinding slice-red with both SliceRoleTemplate and Kubernetes Roles":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"3ee796991b364bdb","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Validate License Tests License Validate tests should fail CRUD in case someone tampered machine.file":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"16187bd7ead03b8e","status":"passed","time":{"start":1693828311000,"stop":1693828316052,"duration":5052}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - sum(namespace.request.cpu) > slice.cpu":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"6aa87da4d3bb010f","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Project CR test Project Creation Should fail while creating service accounts as combination of special characters":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"15ac33d822fe389e","status":"passed","time":{"start":1688022039000,"stop":1688022039271,"duration":271}}]},"Intracluster Suite:Intracluster Suite#[It] Intracluster slice tests Slice with netpol should create & label app ns with kubeslice label":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"407908df22066657","status":"passed","time":{"start":1688025155000,"stop":1688025155111,"duration":111}}]},"Controller Suite:Controller Suite#[It] Events Test Events get recorded for slice config creation Validating events for worker slice resource quota creation":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"6386a34105998cf0","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - namespace.DefaultRequestPerContainer.CPU is negative":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"e29f277c4a9804f9","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - sum(cluster.request.EphemeralStorage) > slice.request.EphemeralStorage":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"e30a101f9d0e201","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"SliceHealth Suite:SliceHealth Suite#[It] Slice Health Check tests Test Slice Health Check Should have slice slicerouter status Error when slicerouter is unavailable":{"statistic":{"failed":1,"broken":0,"skipped":0,"passed":0,"unknown":0,"total":1},"items":[{"uid":"6e010f9729d521a","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc00080c018>: {\n        Underlying: <*exec.ExitError | 0xc0003d4000>{\n            ProcessState: {\n                pid: 8860,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 1, Usec: 328430},\n                    Stime: {Sec: 0, Usec: 227981},\n                    Maxrss: 92140,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 22839,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 0,\n                    Oublock: 16368,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 11478,\n                    Nivcsw: 4670,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"install.go:200: [debug] Original chart version: \\\"\\\"\",\n                        \"install.go:217: [debug] CHART PATH: /root/.cache/helm/repository/istio-discovery-1.16.0.tgz\",\n                        \"\",\n                        \"client.go:134: [debug] creating 1 resource(s)\",\n                        \"client.go:134: [debug] creating 24 resource(s)\",\n                        \"wait.go:48: [debug] beginning wait for 24 resources with timeout of 5m0s\",\n                        \"ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\",\n                        \"ready.go:277: [debug] Deployment...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    install.go:200: [debug] Original chart version: \"\"\n    install.go:217: [debug] CHART PATH: /root/.cache/helm/repository/istio-discovery-1.16.0.tgz\n    \n    client.go:134: [debug] creating 1 resource(s)\n    client.go:134: [debug] creating 24 resource(s)\n    wait.go:48: [debug] beginning wait for 24 resources with timeout of 5m0s\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    ready.go:277: [debug] Deployment is not ready: istio-system/istiod. 0 out of 1 expected pods are ready\n    install.go:470: [debug] Install failed and atomic is set, uninstalling release\n    uninstall.go:97: [debug] uninstall: Deleting istiod\n    uninstall.go:243: [debug] uninstall: given cascade value: , defaulting to delete propagation background\n    client.go:478: [debug] Starting delete for \"istiod\" Service\n    client.go:478: [debug] Starting delete for \"istiod\" HorizontalPodAutoscaler\n    client.go:478: [debug] Starting delete for \"istiod\" Deployment\n    client.go:478: [debug] Starting delete for \"istiod\" RoleBinding\n    client.go:478: [debug] Starting delete for \"istiod\" Role\n    client.go:478: [debug] Starting delete for \"istio-reader-clusterrole-istio-system\" ClusterRoleBinding\n    client.go:478: [debug] Starting delete for \"istiod-clusterrole-istio-system\" ClusterRoleBinding\n    client.go:478: [debug] Starting delete for \"istiod-gateway-controller-istio-system\" ClusterRoleBinding\n    client.go:478: [debug] Starting delete for \"istio-reader-clusterrole-istio-system\" ClusterRole\n    client.go:478: [debug] Starting delete for \"istiod-clusterrole-istio-system\" ClusterRole\n    client.go:478: [debug] Starting delete for \"istiod-gateway-controller-istio-system\" ClusterRole\n    client.go:478: [debug] Starting delete for \"istio-sidecar-injector\" ConfigMap\n    client.go:478: [debug] Starting delete for \"istio\" ConfigMap\n    client.go:478: [debug] Starting delete for \"istiod\" ServiceAccount\n    client.go:478: [debug] Starting delete for \"istiod\" PodDisruptionBudget\n    client.go:478: [debug] Starting delete for \"tcp-stats-filter-1.16\" EnvoyFilter\n    client.go:478: [debug] Starting delete for \"stats-filter-1.13\" EnvoyFilter\n    client.go:478: [debug] Starting delete for \"tcp-stats-filter-1.13\" EnvoyFilter\n    client.go:478: [debug] Starting delete for \"stats-filter-1.14\" EnvoyFilter\n    client.go:478: [debug] Starting delete for \"tcp-stats-filter-1.14\" EnvoyFilter\n    client.go:478: [debug] Starting delete for \"stats-filter-1.15\" EnvoyFilter\n    client.go:478: [debug] Starting delete for \"tcp-stats-filter-1.15\" EnvoyFilter\n    client.go:478: [debug] Starting delete for \"stats-filter-1.16\" EnvoyFilter\n    client.go:478: [debug] Starting delete for \"istio-sidecar-injector\" MutatingWebhookConfiguration\n    uninstall.go:150: [debug] purge requested for istiod\n    Error: INSTALLATION FAILED: release istiod failed, and has been uninstalled due to atomic being set: context deadline exceeded\n    helm.go:84: [debug] context deadline exceeded\n    release istiod failed, and has been uninstalled due to atomic being set\n    helm.sh/helm/v3/pkg/action.(*Install).failRelease\n    \thelm.sh/helm/v3/pkg/action/install.go:478\n    helm.sh/helm/v3/pkg/action.(*Install).reportToRun\n    \thelm.sh/helm/v3/pkg/action/install.go:462\n    helm.sh/helm/v3/pkg/action.(*Install).performInstall\n    \thelm.sh/helm/v3/pkg/action/install.go:418\n    runtime.goexit\n    \truntime/asm_amd64.s:1598\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:147\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:916\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:1044\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:968\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1598\noccurred","time":{"start":1688026084000,"stop":1688026400126,"duration":316126}}]},"Hub Suite:Hub Suite#[It] Project and Cluster Events Test Events get recorded for project creation and deletion Events get recorded for project creation Validating events for service account secret creation":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"1bf1fdfe76c65847","status":"passed","time":{"start":1688022039000,"stop":1688022039085,"duration":85}}]},"Hub Suite:Hub Suite#[It] Cluster CR tests Cluster CR validation Register worker cluster (with minimal values in cluster CR)":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"2d26f60d8b34d04a","status":"passed","time":{"start":1688022039000,"stop":1688022682877,"duration":643877}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests SliceRoleTemplate Tests Create SliceRoleTempalate failure test: Creating SliceRoleTempalate read-only-role, missing verbs field":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"f462cb88ba35fcd3","status":"passed","time":{"start":1693828311000,"stop":1693828314265,"duration":3265}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests SliceRoleBinding Tests Delete SliceRoleBinding success test: Deletion of SliceConfig should delete SliceRoleBinding":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"6db2ee6c8af18e05","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"SliceHealth Suite:SliceHealth Suite#[It] Slice Health Check tests Test Slice Health Check Should have component status Normal when services are available":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"d497d0c2ec0af0f9","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1688026084000,"stop":1688026084000,"duration":0}}]},"Intracluster Suite:Intracluster Suite#[It] Intracluster slice tests Iperf connectivity should create all application namespaces":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"c92d3a7459ec60a9","status":"passed","time":{"start":1688025155000,"stop":1688025157434,"duration":2434}}]},"Controller Suite:Controller Suite#[It] Events Test Events get recorded for project creation Validating events for project creation":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"7169737bae886fa9","status":"passed","time":{"start":1693828311000,"stop":1693828311544,"duration":544}}]},"Controller Suite:Controller Suite#[It] E2E tests for license job > when license config is tampered with Apply tampered cm":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"fffcb38d860e7a60","status":"passed","time":{"start":1693828311000,"stop":1693828325209,"duration":14209}}]},"Controller Suite:Controller Suite#[It] Slice node affinity Tests SliceNodeAffinity tests - includes creation and deletion slice node affinity creation -failed case if not applied in project namespace":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"abcfe6b8e6ac76f3","status":"passed","time":{"start":1693828311000,"stop":1693828314705,"duration":3705}}]},"Hub Suite:Hub Suite#[It] Cluster negative tests Worker Cluster Registration with Wrong clustername":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"42655503d36c6d8e","status":"passed","time":{"start":1688022039000,"stop":1688022046816,"duration":7816}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests SliceRoleBinding Tests Create SliceRoleBinding failure test: Creating SliceRoleBinding slice-green with name not same as Slice slice-red":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"3339c17984382abc","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"SliceHealth Suite:SliceHealth Suite#[BeforeSuite]":{"statistic":{"failed":3,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":4},"items":[{"uid":"1f38bf34b0805f26","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc000014e88>: {\n        Underlying: <*exec.ExitError | 0xc000476540>{\n            ProcessState: {\n                pid: 6405,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 0, Usec: 89072},\n                    Stime: {Sec: 0, Usec: 32390},\n                    Maxrss: 48120,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 2149,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 0,\n                    Oublock: 168,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 542,\n                    Nivcsw: 277,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"install.go:200: [debug] Original chart version: \\\"\\\"\",\n                        \"install.go:217: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-controller-1.2.0.tgz\",\n                        \"\",\n                        \"Error: INSTALLATION FAILED: cannot re-use a name that is still in use\",\n                        \"helm.go:84: [debug] cannot re-use a name that is still in use\",\n                        \"helm.sh/helm/v3/pkg/action.(*Install).availableName\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:512\",\n                        \"helm.sh/helm/v3/pkg/action.(*Install).RunWithContext\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:222\",\n                        \"main.runInstall\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:286\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:145\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:916\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:1044\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:968\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:250\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1598\",\n                        \"INSTALLATION FAILED\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:147\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:916\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:1044\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:968\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:250\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1598\",\n                    ],\n                },\n            },\n            stderr: {\n                Lines: [\n                    \"WARNING: Kubernetes configuration file is group-readable. This is ins...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    install.go:200: [debug] Original chart version: \"\"\n    install.go:217: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-controller-1.2.0.tgz\n    \n    Error: INSTALLATION FAILED: cannot re-use a name that is still in use\n    helm.go:84: [debug] cannot re-use a name that is still in use\n    helm.sh/helm/v3/pkg/action.(*Install).availableName\n    \thelm.sh/helm/v3/pkg/action/install.go:512\n    helm.sh/helm/v3/pkg/action.(*Install).RunWithContext\n    \thelm.sh/helm/v3/pkg/action/install.go:222\n    main.runInstall\n    \thelm.sh/helm/v3/cmd/helm/install.go:286\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:145\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:916\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:1044\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:968\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1598\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:147\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:916\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:1044\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:968\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1598\noccurred","time":{"start":1689751363000,"stop":1689751363398,"duration":398}},{"uid":"627308c2e51d2e47","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc000128d50>: {\n        Underlying: <*exec.ExitError | 0xc0003fbf60>{\n            ProcessState: {\n                pid: 6379,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 0, Usec: 103836},\n                    Stime: {Sec: 0, Usec: 23962},\n                    Maxrss: 48128,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 2302,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 0,\n                    Oublock: 168,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 517,\n                    Nivcsw: 278,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\",\n                        \"install.go:200: [debug] Original chart version: \\\"\\\"\",\n                        \"install.go:217: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-controller-1.2.0.tgz\",\n                        \"\",\n                        \"Error: INSTALLATION FAILED: cannot re-use a name that is still in use\",\n                        \"helm.go:84: [debug] cannot re-use a name that is still in use\",\n                        \"helm.sh/helm/v3/pkg/action.(*Install).availableName\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:512\",\n                        \"helm.sh/helm/v3/pkg/action.(*Install).RunWithContext\",\n                        \"\\thelm.sh/helm/v3/pkg/action/install.go:222\",\n                        \"main.runInstall\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:286\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:145\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:916\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:1044\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:968\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:250\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1598\",\n                        \"INSTALLATION FAILED\",\n                        \"main.newInstallCmd.func2\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/install.go:147\",\n                        \"github.com/spf13/cobra.(*Command).execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:916\",\n                        \"github.com/spf13/cobra.(*Command).ExecuteC\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:1044\",\n                        \"github.com/spf13/cobra.(*Command).Execute\",\n                        \"\\tgithub.com/spf13/cobra@v1.6.1/command.go:968\",\n                        \"main.main\",\n                        \"\\thelm.sh/helm/v3/cmd/helm/helm.go:83\",\n                        \"runtime.main\",\n                        \"\\truntime/proc.go:250\",\n                        \"runtime.goexit\",\n                        \"\\truntime/asm_amd64.s:1598\",\n                    ],\n                },\n            },\n            stderr: {\n                Lines: [\n                    \"WARNING: Kubernetes configuration file is group-readable. This is in...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /e2e/assets/kubeconfig/kinde2e.yaml\n    install.go:200: [debug] Original chart version: \"\"\n    install.go:217: [debug] CHART PATH: /root/.cache/helm/repository/kubeslice-controller-1.2.0.tgz\n    \n    Error: INSTALLATION FAILED: cannot re-use a name that is still in use\n    helm.go:84: [debug] cannot re-use a name that is still in use\n    helm.sh/helm/v3/pkg/action.(*Install).availableName\n    \thelm.sh/helm/v3/pkg/action/install.go:512\n    helm.sh/helm/v3/pkg/action.(*Install).RunWithContext\n    \thelm.sh/helm/v3/pkg/action/install.go:222\n    main.runInstall\n    \thelm.sh/helm/v3/cmd/helm/install.go:286\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:145\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:916\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:1044\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:968\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1598\n    INSTALLATION FAILED\n    main.newInstallCmd.func2\n    \thelm.sh/helm/v3/cmd/helm/install.go:147\n    github.com/spf13/cobra.(*Command).execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:916\n    github.com/spf13/cobra.(*Command).ExecuteC\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:1044\n    github.com/spf13/cobra.(*Command).Execute\n    \tgithub.com/spf13/cobra@v1.6.1/command.go:968\n    main.main\n    \thelm.sh/helm/v3/cmd/helm/helm.go:83\n    runtime.main\n    \truntime/proc.go:250\n    runtime.goexit\n    \truntime/asm_amd64.s:1598\noccurred","time":{"start":1688628155000,"stop":1688628155543,"duration":543}},{"uid":"ca2ade5904afb48e","status":"passed","time":{"start":1688026084000,"stop":1688026304701,"duration":220701}},{"uid":"61d09ccb032bdb72","status":"failed","statusDetails":"Unexpected error:\n    <*shell.ErrWithCmdOutput | 0xc0004a4558>: {\n        Underlying: <*exec.ExitError | 0xc0004b01a0>{\n            ProcessState: {\n                pid: 6319,\n                status: 256,\n                rusage: {\n                    Utime: {Sec: 0, Usec: 69266},\n                    Stime: {Sec: 0, Usec: 4329},\n                    Maxrss: 43880,\n                    Ixrss: 0,\n                    Idrss: 0,\n                    Isrss: 0,\n                    Minflt: 2030,\n                    Majflt: 0,\n                    Nswap: 0,\n                    Inblock: 0,\n                    Oublock: 0,\n                    Msgsnd: 0,\n                    Msgrcv: 0,\n                    Nsignals: 0,\n                    Nvcsw: 351,\n                    Nivcsw: 293,\n                },\n            },\n            Stderr: nil,\n        },\n        Output: {\n            stdout: {\n                Lines: nil,\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"error: error executing jsonpath \\\"\\\\\\\"{.clusters[?(@.name==\\\\\\\"kind-controller\\\\\\\")].cluster.server}\\\\\\\"\\\": Error executing template: <nil> is not array or slice and cannot be filtered. Printing more information for debugging the template:\",\n                        \"\\ttemplate was:\",\n                        \"\\t\\t\\\"{.clusters[?(@.name==\\\"kind-controller\\\")].cluster.server}\\\"\",\n                        \"\\tobject given to jsonpath engine was:\",\n                        \"\\t\\tmap[string]interface {}{\\\"apiVersion\\\":\\\"v1\\\", \\\"clusters\\\":interface {}(nil), \\\"contexts\\\":interface {}(nil), \\\"current-context\\\":\\\"\\\", \\\"kind\\\":\\\"Config\\\", \\\"preferences\\\":map[string]interface {}{}, \\\"users\\\":interface {}(nil)}\",\n                        \"\",\n                        \"\",\n                    ],\n                },\n            },\n            stderr: {\n                Lines: [\n                    \"error: error executing jsonpath \\\"\\\\\\\"{.clusters[?(@.name==\\\\\\\"kind-controller\\\\\\\")].cluster.server}\\\\\\\"\\\": Error executing template: <nil> is not array or slice and cannot be filtered. Printing more information for debugging the template:\",\n                    \"\\ttemplate was:\",\n                    \"\\t\\t\\\"{.clusters[?(@.name==\\\"kind-controller\\\")].cluster.server}\\\"\",\n                    \"\\tobject given to jsonpath engine was:\",\n                    \"\\t\\tmap[string]interface {}{\\\"apiVersion\\\":\\\"v1\\\", \\\"clusters\\\":interface {}(nil), \\\"contexts\\\":interface {}(nil), \\\"current-context\\\":\\\"\\\", \\\"kind\\\":\\\"Config\\\", \\\"preferences\\\":map[string]interface {}{}, \\\"users\\\":interface {}(nil)}\",\n                    \"\",\n                    \"\",\n                ],\n                merged: {\n                    Mutex: {state: 0, sema: 0},\n                    Lines: [\n                        \"error: error executing jsonpath \\\"\\\\\\\"{.clusters[?(@.name==\\\\\\\"kind-controller\\\\\\\")].cluster.server}\\\\\\\"\\\": Error executing template: <nil> is not array or slice and cannot be filtered. Printing more information for debugging the template:\",\n                        \"\\ttemplate was:\",\n                        \"\\t\\t\\\"{.clusters[?(@.name==\\\"kind-controller\\\")].cluster.server}\\\"\",\n                        \"\\tobject given to jsonpath engine was:\",\n                        \"\\t\\tmap[string]interface {}{\\\"apiVersion\\\":\\\"v1\\\", \\\"clusters\\\":interface {}(nil), \\\"contexts\\\":interface {}(nil), \\\"current-context\\\":\\\"\\\", \\\"kind\\\":\\\"Config\\\", \\\"preferences\\\":map[string]interface {}{}, \\\"users\\\":interface {}(nil)}\",\n                        \"\",\n                        \"\",\n                    ],\n                },\n            },\n            merged: {\n                Mutex: {state: 0, sema: 0},\n                Lines: [\n                    \"error: error executing jsonpath \\\"\\\\\\\"{.clusters[?(@.name==\\\\\\\"kind-controller\\\\\\\")].cluster.server}\\\\\\\"\\\": Error executing template: <nil> is not array or slice and cannot be filtered. Printing more information for debugging the template:\",\n                    \"\\ttemplate was:\",\n                    \"\\t\\t\\\"{.clusters[?(@...\n\nGomega truncated this representation as it exceeds 'format.MaxLength'.\nConsider having the object provide a custom 'GomegaStringer' representation\nor adjust the parameters in Gomega's 'format' package.\n\nLearn more here: https://onsi.github.io/gomega/#adjusting-output\n\n    error while running command: exit status 1; error: error executing jsonpath \"\\\"{.clusters[?(@.name==\\\"kind-controller\\\")].cluster.server}\\\"\": Error executing template: <nil> is not array or slice and cannot be filtered. Printing more information for debugging the template:\n    \ttemplate was:\n    \t\t\"{.clusters[?(@.name==\"kind-controller\")].cluster.server}\"\n    \tobject given to jsonpath engine was:\n    \t\tmap[string]interface {}{\"apiVersion\":\"v1\", \"clusters\":interface {}(nil), \"contexts\":interface {}(nil), \"current-context\":\"\", \"kind\":\"Config\", \"preferences\":map[string]interface {}{}, \"users\":interface {}(nil)}\n    \n    \noccurred","time":{"start":1688018435000,"stop":1688018435086,"duration":86}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests RBAC Common Tests WorkerSliceRoleBinding removal test: If roles are removed from SliceRolebinding, WorkerSliceRoleBinding should be removed":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"5ecf96e1cc024463","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[AfterSuite]":{"statistic":{"failed":5,"broken":0,"skipped":0,"passed":0,"unknown":0,"total":5},"items":[{"uid":"1f6d30ab5086eaff","status":"failed","statusDetails":"Timed out after 500.031s.\nExpected\n    <bool>: false\nto be true","time":{"start":1693828311000,"stop":1693828850406,"duration":539406}},{"uid":"e5bc5e2fe607b923","status":"failed","statusDetails":"Timed out after 500.014s.\nExpected\n    <bool>: false\nto be true","time":{"start":1690377721000,"stop":1690378221496,"duration":500496}},{"uid":"3298ab024528031c","status":"failed","statusDetails":"Timed out after 500.015s.\nExpected\n    <bool>: false\nto be true","time":{"start":1690371125000,"stop":1690371625278,"duration":500278}},{"uid":"cdcc37c6ecf1f84f","status":"failed","statusDetails":"Timed out after 500.017s.\nExpected\n    <bool>: false\nto be true","time":{"start":1689758771000,"stop":1689759271018,"duration":500018}},{"uid":"4b58394970be3af6","status":"failed","statusDetails":"Timed out after 500.000s.\nExpected\n    <bool>: false\nto be true","time":{"start":1689755137000,"stop":1689755637001,"duration":500001}}]},"Controller Suite:Controller Suite#[It] Slice node affinity Tests SliceNodeAffinity tests - includes creation and deletion slice node affinity creation -failed case if wild card * for cluster is repeated":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"572164c87adf18b0","status":"passed","time":{"start":1693828311000,"stop":1693828319829,"duration":8829}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test-namespace.limit.mem negative":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"89af0e9d9b49a9c","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - slice.limit.podcount negative  ":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"e1f3c338224c14d0","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Intracluster Suite:Intracluster Suite#[It] Intracluster slice tests Iperf connectivity should onboard deployment in application Namespaces without slice annotations":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"f345adf86187f0f9","status":"passed","time":{"start":1688025155000,"stop":1688025185414,"duration":30414}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - namespace.DefaultLimitPerContainer.EphemeralStorage > namespace.Request.EphemeralStorage":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"720927e16fc90c0c","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test- Request.CPU > Limit.CPU at namespace level":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"40cad49419fd216f","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test - slice.DefaultRequestPerContainer.cpu > slice.Request.cpu":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"7a7fe46f5f8d4cc5","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] E2E tests for license job > when license config is tampered with should not create new secret upon restart":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"6c4c9318bfd16ecc","status":"passed","time":{"start":1693828311000,"stop":1693828462922,"duration":151922}}]},"Hub Suite:Hub Suite#[It] Project CR test Project Update Should update successfully when Project applied with valid service account name in Write users":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"863e7fd9c4f182ef","status":"passed","time":{"start":1688022039000,"stop":1688022044245,"duration":5245}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test-namespace not part of application namespaces":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"ebbd60bb6639db0d","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test-cluster not part":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"2e86578764a9a78c","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Project CR test Project Update Should fail when Project is Applied with service account name as combination of special characters in Read users":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"fce4b1cc82ddb816","status":"passed","time":{"start":1688022039000,"stop":1688022043868,"duration":4868}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test- Request.EphemeralStorage > Limit.EphemeralStorage at slice level":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"7dbd5cfd3ba08e17","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests SliceRoleBinding Tests Create SliceRoleBinding successful test: Creating SliceRoleBinding slice-red with SliceRoleTemplate":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"7874216c5d81a162","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Events Test Events get recorded for slice resource quota deletion Validating events for slice resource quota deletion":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"fafd0c859c24975e","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice resource quota Tests ResourceQuota creation tests Create ResourceQuota fail test- Request.Mem > Limit.Mem at namespace level":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"7d5195d7306b1ce","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Events Test Events get recorded for slice role binding creation and deletion Events get recorded for slice role binding deletion Validating events for slice role binding deletion":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"9123d4f4c65cc420","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice node affinity Tests SliceNodeAffinity tests - includes creation and deletion slice node affinity creation success test":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"198ca866a5f2163a","status":"passed","time":{"start":1693828311000,"stop":1693828333629,"duration":22629}}]},"Hub Suite:Hub Suite#[It] Project CR test Project Update Should update successfully when Project Applied while removing a service account name in Write users":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"498044a4e2996b8a","status":"passed","time":{"start":1688022039000,"stop":1688022044696,"duration":5696}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests RBAC Common Tests SliceRoleBinding status test: SliceRoleBinding should have error status for invalid namespace for custom roles":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"2093522b37843479","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Cluster health check tests Cluster health check - without istio Updates health status when dns is not working":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"3b10059df4284c38","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1688022039000,"stop":1688022039000,"duration":0}}]},"Controller Suite:Controller Suite#[It] Slice RBAC Tests RBAC Common Tests WorkerSliceRoleBinding removal test: WorkerSliceRoleBinding should not be generated if SliceRoleTempate does not exit.":{"statistic":{"failed":0,"broken":0,"skipped":1,"passed":0,"unknown":0,"total":1},"items":[{"uid":"2fa78dbf6f7dc8ae","status":"skipped","statusDetails":"skipped - Spec skipped because an earlier spec in an ordered container failed","time":{"start":1693828311000,"stop":1693828311000,"duration":0}}]},"Hub Suite:Hub Suite#[It] Cluster CR tests Cluster CR validation Register worker cluster":{"statistic":{"failed":0,"broken":0,"skipped":0,"passed":1,"unknown":0,"total":1},"items":[{"uid":"428bdf1bca524381","status":"passed","time":{"start":1688022039000,"stop":1688022686534,"duration":647534}}]}}